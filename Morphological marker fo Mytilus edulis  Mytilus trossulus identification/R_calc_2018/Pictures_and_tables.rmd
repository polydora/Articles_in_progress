---
title: ""
author: ""
date: ""
output:
  word_document:
    reference_docx: article_template.docx
    fig_width: 8
    fig_height: 8
bibliography: 
csl: marine-biology.csl

---

```{r setup, include=FALSE, echo=FALSE}
library(knitr)

opts_chunk$set(echo = FALSE, cache = FALSE, fig.align ="center", warning = FALSE, message = FALSE)

# set pander table-layout options
library(pander)
panderOptions('table.alignment.default', function(df)
    ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)

```



```{r}

library(lme4)
library(ggplot2)
library(reshape2)
library(sjstats)
library(dplyr)
library(car)
library(doBy)
library(pROC)
library(betareg)
library(lmtest)
library(broom)
library(MuMIn)
library(gridExtra)





#### Data reading and initial preparation #####

myt <- read.table("data_salinity3.csv", header = T, sep = ";")


myt_overseas <- myt[myt$dataset == "overseas", ]

myt <- myt[myt$dataset != "overseas", ]



myt$Sp [myt$str > 0.5] <- "M.trossulus" #Лучше обозначать так!
myt$Sp [myt$str <= 0.5] <- "M.edulis"
myt$Sp <- factor(myt$Sp)

# Оставляем только мидий, у которых есть оценка морфотипа
myt2 <- myt[!is.na(myt$ind), ]


# Вводим обозначения для морфотипов
myt2$morph <- ifelse(myt2$ind == 1, "T_m", "E_m")
myt2$morph <- factor(myt2$morph)



# Бинарное обозначение видов
myt2$Sp2 <- ifelse(myt2$Sp == "M.trossulus", 1, 0)


#Correct identification
myt2$congr <- ifelse((myt2$ind == 1 & myt2$Sp == "M.trossulus") | (myt2$ind == 0 & myt2$Sp == "M.edulis"), 1, 0   )


# Частота M.trossulus в популяции

freq_MT <- myt2 %>% group_by(pop) %>% summarise(freq_MT = mean(Sp2))

myt2 <- merge(myt2, freq_MT)


# Частота T-морфотипа в популяции

Prop_T <- myt2 %>% group_by(pop) %>% summarise(Prop_T = mean(ind))

myt2 <- merge(myt2, Prop_T)


# Подразделяем данные на три сабсета

myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "fresh"] <- "BL" 
myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "normal"] <- "BH" 
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "normal"] <- "W" 
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "fresh"] <- "W" 

myt2$Subset <- factor(myt2$Subset, levels = c("W", "BL", "BH"))


#Оставляем только данные, на основе, которых строится модель
myt3 <- myt2[myt2$dataset == "testing", ]
myt2 <- myt2[myt2$dataset == "training", ]



```



```{r}

# Функция для вычисления P_T_MT и P_T_ME в заданном датасете (БУБЛИК) ####
donat <- function(df){
  P_MT <- sum(df$Sp == "M.trossulus")
  P_T_MT <- sum(df$Sp == "M.trossulus" & df$morph == "T_m")/P_MT
  
  P_ME <- sum(df$Sp == "M.edulis")
  P_T_ME <- sum(df$Sp == "M.edulis" & df$morph == "T_m")/P_ME
  c(P_T_MT, P_T_ME)
}




########################################3

#Функция для "ленивого" калькулятора №1 который строит зависимость Ptros от P_T  

# На входе параметры бублика

calc1 <- function(P_T_MT, P_T_ME){
  result <- data.frame(P_T = seq(0, 1, 0.01))
  result$Ptros <- (result$P_T - P_T_ME)/(P_T_MT - P_T_ME)
  result <- result[result$P_T <= P_T_MT & result$P_T >= P_T_ME, ]
  result
}



# Функция для вычисления баесовских вероятностей по данным из бублика

calc2 <- function(P_T_MT, P_T_ME){
  result <- data.frame(freq_MT = seq(0, 1, 0.01))
  result$P_MT_T <- (P_T_MT * result$freq_MT)/(P_T_MT * result$freq_MT + P_T_ME*(1-result$freq_MT))
  result$P_ME_E <- ((1 - P_T_ME) * (1 - result$freq_MT))/(1 - P_T_ME + result$freq_MT * (P_T_ME - P_T_MT))
  result
}


########################################3


# Фунция для определения похожести между эмпирическим и теоретическими моделями для МОДЕЛИ 5 (Ptros vs P_T)



perms2 <- function(df = myt2[myt2$Subset == "W", ], ...) {
  require(dplyr)
  df$pop <- as.character(df$pop)
  perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
  perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
  perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
  
  perm_pairs$First <- as.character(perm_pairs$First)
  perm_pairs$Second <- as.character(perm_pairs$Second)
  perm_pairs$Delta <- NA
  for(i in 1:nrow(perm_pairs)){
    df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),] 
    
    means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
    
    perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
    W <- donat(df_selected)
    
    calc1_predict_W <- calc1(W[1], W[2])
    
    names(calc1_predict_W) <- c("Prop_T", "Ptros_predicted" )
    
    Model_prediction <- expand.grid(Subset = unique(df_selected$Subset), Prop_T = seq(0, 1, 0.01))
    
    Model_prediction$Predict <- predict(Model_5_final, newdata = Model_prediction, type = "response")
    
    all_prediction <- merge(calc1_predict_W, Model_prediction, by = c("Prop_T"))
    
    perm_pairs$Goodness[i] <- 1/(mean((all_prediction$Predict - all_prediction$Ptros_predicted)^2))
    
  }
  perm_pairs
}





# Фунция для определения похожести между эмпирическими и теоретическими моделями для МОДЕЛИ 4 (Congr vs Ptros; Morph)
perms4 <- function(df = myt2[myt2$Subset == "W", ], ...) {
  require(dplyr)
  df$pop <- as.character(df$pop)
  perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
  perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
  perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]  
  
  perm_pairs$First <- as.character(perm_pairs$First)
  perm_pairs$Second <- as.character(perm_pairs$Second)
  perm_pairs$Delta <- NA
  for(i in 1:nrow(perm_pairs)){
    df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),] 
    
    means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
    # perm_pairs$Delta[i] <- abs(means$freq_MT[1] - means$freq_MT[2])
    perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
    W <- donat(df_selected)
    
    calc2_predict_W <- calc2(W[1], W[2])
    names(calc2_predict_W) <- c("freq_MT", "T_m",  "E_m")
    
    calc2_predict_W <- melt(calc2_predict_W, id.vars = "freq_MT" )
    names(calc2_predict_W) <- c("freq_MT", "morph", "Bayes_predict") 
    
    Model_prediction <- expand.grid(Subset = unique(df_selected$Subset),  morph = levels(df_selected$morph), freq_MT = seq(0, 1, 0.01))
    
    Model_prediction$Predict <- predict(Model_4_final, newdata = Model_prediction, type = "response",  re.form = NA )
    
    all_prediction <- merge(calc2_predict_W, Model_prediction, by = c("freq_MT", "morph"))
    
    
    perm_pairs$Goodness[i] <- 1/mean((all_prediction$Bayes_predict - all_prediction$Predict)^2, na.rm = T)
    perm_pairs$pop[i] <- unique(as.character(df_selected$pop))
    
  }
  perm_pairs
}




## Функция для поиска ниболее различающихся выборок
max_dif <- function(Subset = "W", ...) {
  require(dplyr)
  df = myt2[myt2$Subset == Subset, ]
  df$pop <- as.character(df$pop)
  perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
  perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
  perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]  
  
  perm_pairs$First <- as.character(perm_pairs$First)
  perm_pairs$Second <- as.character(perm_pairs$Second)
  perm_pairs$Delta <- NA

  for(i in 1:nrow(perm_pairs)){
    df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),] 
    
    means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
    perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
  }
  max_dif <- perm_pairs[which.max(perm_pairs$Delta), ]
  c(max_dif$First, max_dif$Second)
}




max_mix <- function(Subset = "W", ...) {
  require(dplyr)
  df = myt2[myt2$Subset == Subset, ]
  df$pop <- as.character(df$pop)
  perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
  perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
  perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
    
  perm_pairs$First <- as.character(perm_pairs$First)
  perm_pairs$Second <- as.character(perm_pairs$Second)
  perm_pairs$Delta <- NA

  for(i in 1:nrow(perm_pairs)){
    df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),] 
    
    means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
    perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
  }
  
  max_mix <- perm_pairs[which.min(abs(perm_pairs$Delta - 0.25)), ]
  c(max_mix$First, max_mix$Second)
}







########################################

# Функция для обратной трансформации логитов
logit_back <- function(x) exp(x)/(1 + exp(x)) # обратная логит-трансформация



# Функция для оценки сверхдисперсии в моделях GLM

overdisp_fun <- function(model) {
  rdf <- df.residual(model)  # Число степеней свободы N - p
  if (inherits(model, 'negbin')) rdf <- rdf - 1 ## учитываем k в NegBin GLMM
  rp <- residuals(model,type='pearson') # Пирсоновские остатки
  Pearson.chisq <- sum(rp^2) # Сумма квадратов остатков, подчиняется Хи-квадрат распределению
  prat <- Pearson.chisq/rdf  # Отношение суммы квадратов остатков к числу степеней свободы
  pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE) # Уровень значимости
  c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)        # Вывод результатов
}





```


```{r}
##### Theme for ggplot ######
theme_set(theme_bw() + theme(axis.title.x = element_text(size = 10), axis.title.y = element_text(size = 10), axis.text= element_text(size = 10), legend.position = "none" )  )

```


# Regression models parameters

NB! Предлагаю убрать слово "Subset" и заменить его на "Region". Пока оставляю так как было

In all models outcome variables were supposed as binomialy disributed ($y_i \sim Binomial(n = 1, \pi_i)$). Logit was used as a linck function in all models. In all cases full models including all terms and their inteactions were constructed. After the full models were constructed they were simplified  accordingly to backward selection protocol (Zuur et al., 2009). 


Model1: $logit(P_T) = Ptros + Subset + Ptros:Subset$

Model2: $logit(P_T) = Ptros + Subset + Species + Ptros:Subset + Ptros:Species + Subset:Species + Ptros:Subset:Species$

Model3: $logit(P_{correct}) = Ptros + Subset + Ptros:Subset$

Model4: $logit(P_{correct}) = Morph + Ptros + Subset + Morph:Ptros + Morph:Subset + Ptros:Subset$

Model5: $logit(Ptros) = P_T + Subset$







  
```{r}

# Model 1. P_T ~ Ptros*subset (GLM)

# Model 2. P_T ~ Ptros*subset*Sp (GLMM)

# Model 3. Accuracy ~ Ptros*subset (GLM)

# Model 4. Congr ~ Ptros*subset*Morph (GLMM, probit)

# Model 5. Ptros ~ P_T*subset (GLM)



#Модель 1
###################################################


Model_1_full <- glm(ind ~  freq_MT * Subset, data = myt2, family = binomial(link = "logit"))


# overdisp_fun(Model_1_full)


Model_1_final <- Model_1_full 

Model_1_final_summary <- tidy(Model_1_final)

Model_1_R2 <- r.squaredGLMM(Model_1_final)[1,1]






#Модель 2
######################################

Model_2_full <- glmer(ind ~  freq_MT * Subset * Sp + (1|pop), data = myt2, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))

# overdisp(Model_2_full)

Model_2_final <- Model_2_full

Model_2_final_summary <- tidy(Model_2_final)

Model_2_final_summary <- Model_2_final_summary[,!(names(Model_2_final_summary) %in% c("group"))]

Model_2_final_R2_m <- r.squaredGLMM(Model_2_final)[1,1]

Model_2_final_R2_c <- r.squaredGLMM(Model_2_final)[1, 2]




#Модель 3
#####################################


Model_3_full <- glm(congr ~ freq_MT*Subset, data = myt2, family = binomial(link = "logit"))
# overdisp_fun(Model_3_full)


# drop1(Mod_3_full, test = "Chi")

Model_3_final <- Model_3_full

Model_3_final_summary <- tidy(Model_3_final)


Model_3_R2 <- r.squaredGLMM(Model_3_final)[1,1]




#Модель 4
#####################################

Model_4_full <- glmer(congr ~ morph * freq_MT*Subset + (1 | pop), data = myt2, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
# overdisp_fun(Model_4_full)


# drop1(Model_4_full, test = "Chi")


Model_4_1 <- update(Model_4_full, .~.-morph:freq_MT:Subset )

# drop1(Model_4_1, test = "Chi")

Model_4_final <- Model_4_1
# overdisp_fun(Model_4_final)



Model_4_final_summary <- tidy(Model_4_final)


Model_4_final_summary <- Model_4_final_summary[,!(names(Model_4_final_summary) %in% c("group"))]

Model_4_final_R2_m <- r.squaredGLMM(Model_4_final)[1,1]

Model_4_final_R2_c <- r.squaredGLMM(Model_4_final)[1, 2]


#Модель 5
#####################################


Model_5_full <- glm(Sp2 ~  Prop_T * Subset, data = myt2, family = binomial(link = "logit"))
# overdisp_fun(Model_5_full)

# drop1(Model_5_full, test = "Chi")

Model_5_1 <- update(Model_5_full, . ~ . - Prop_T:Subset)

# drop1(Model_5_1, test = "Chi")

Model_5_final <- Model_5_1 

# lrtest(Model_5_final, Model_5_full)


Model_5_final_summary <- tidy(Model_5_final)

Model_5_R2 <- r.squaredGLMM(Model_5_final)[1,1]


```



```{r}

# Распечатка результатов всех моделей


empty_row <- rep(NA, 5 )


all_models <- rbind(empty_row, Model_1_final_summary, empty_row, Model_2_final_summary, empty_row, Model_3_final_summary,  empty_row, Model_4_final_summary, empty_row, Model_5_final_summary)

all_models$estimate <- round(all_models$estimate, 1)

all_models$std.error <- round(all_models$std.error, 2)

all_models$statistic <- round(all_models$statistic, 2)

all_models$p.value <- round(all_models$p.value, 3)

all_models$p.value_print <- ifelse(all_models$p.value < 0.001, "< 0.001", all_models$p.value)

all_models$term_print <- gsub("freq_MT", "Ptros", as.character(all_models$term))
all_models$term_print <- gsub("SubsetBL", "Subset(BL)", as.character(all_models$term_print))
all_models$term_print <- gsub("SubsetBH", "Subset(BH)", as.character(all_models$term_print))
all_models$term_print <- gsub("morphT_m", "Morph(T)", as.character(all_models$term_print))
all_models$term_print <- gsub("sd_(Intercept).pop", "SD(Intercept)", as.character(all_models$term_print))
all_models$term_print <- gsub("SpM.trossulus", "Species(*M.trossulus*)", as.character(all_models$term_print))
all_models$term_print <- gsub("Prop_T", "PT", as.character(all_models$term_print))



all_models_print <- all_models[, c("term_print", "estimate", "std.error", "statistic", "p.value_print" )] 

# options(knitr.kable.NA = ' ')
kable(all_models_print, col.names = c("Terms", "Estimate", "SE", "z-statistic", "p-value"))


```





In all models Ptros - proportion of *M.trossulus* in population; Subset - sampling area  (*W*, *BL*, *BH*); PT - proportion of T-morphotype in population; Species - mussel genotype (*M.edulis* or *M.trossulus*).
*M.edulis* and *W* where used as basic levels for categorical predictors.





## Regression models visualisation

```{r}

# Model1 ##############################

new_data <- myt2 %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT) ) %>% group_by(Subset) %>%  do(data.frame(freq_MT = seq(min(.$freq_MT), max(.$freq_MT), length.out = 10)))


predicted <- predict(Model_1_final, newdata = new_data,  type="response", se.fit = T)

new_data$fit <- predicted$fit

new_data$SE <- predicted$se.fit 




Pl_mod1 <- ggplot(new_data, aes(x = freq_MT, y = fit)) + geom_line(linetype = 2, color = "red", size = 1) + facet_wrap(~Subset) + geom_ribbon(aes(ymin = fit - 1.96*SE, ymax = fit + 1.96*SE), alpha = 0.1) + xlim(0, 1) + ylim(0, 1) +  geom_rug(data = myt2, inherit.aes = FALSE,  aes(x = freq_MT), size = 0.1)


# иллюстрация с точками
link_over_M <- myt2 %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(Sp2), freq_Tmorph = mean(ind), N_MT = sum(Sp2 == 1),  N_ME = sum(Sp2 == 0))

Pl_mod1_with_initial_data <- Pl_mod1 + geom_point(data = link_over_M, aes(y = freq_Tmorph, size = (N_MT+N_ME), fill = (freq_MT)), shape = 21) + scale_fill_continuous(high = "black", low = "white" ) + geom_abline() + labs(x =  "Proportion of M. trossulus", y = "Proportion of T-morphotype \n") + theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank()) 




# Model_2 ##############################

new_data2 <- myt2 %>% group_by(Subset,  Sp) %>% do(data.frame(freq_MT = seq(min(.$freq_MT), max(.$freq_MT), length.out = 100)))


new_data2$eta <- predict(Model_2_final, newdata = new_data2,  re.form = NA) 

X <- model.matrix(~freq_MT * Subset * Sp , data = new_data2)



new_data2$SE_eta <- sqrt(diag(X %*% vcov(Model_2_final) %*% t(X)))

new_data2$fit <- logit_back(new_data2$eta)

new_data2$lwr <- logit_back(new_data2$eta -  1.96 *new_data2$SE_eta)

new_data2$upr <- logit_back(new_data2$eta +  1.96 *new_data2$SE_eta)

Pl_mod2 <-  ggplot(new_data2, aes(x = freq_MT, y = fit, group = Sp)) + geom_line(linetype = 2,  size = 1, aes(color = Sp)) + geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.1) + facet_wrap(~Subset)  + xlim(0, 1) + ylim(0, 1) + scale_color_manual(values=c("blue", "red")) + guides(color = "none") +  geom_rug(data = myt2, inherit.aes = FALSE,  aes(x = freq_MT), size = 0.1)



pops_over_M <- myt2 %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT), N_MT = sum(Sp2 == 1),  N_T_MT = sum(Sp2 == 1 & ind == 1), N_E_MT = sum(Sp2 == 1 & ind == 0), N_ME = sum(Sp2 == 0), N_E_ME = sum(Sp2 == 0 & ind == 0), N_T_ME = sum(Sp2 == 0 & ind == 1))
 
pops_over_M$P_T_MT <- with(pops_over_M, N_T_MT / N_MT)
pops_over_M$P_E_MT <- with(pops_over_M, N_E_MT / N_MT)
pops_over_M$P_E_ME <- with(pops_over_M, N_E_ME / N_ME)
pops_over_M$P_T_ME <- with(pops_over_M, N_T_ME / N_ME)


Pl_mod2_with_initial_data <- Pl_mod2 +   geom_segment(data = pops_over_M, aes(x = freq_MT, y = (1-P_E_ME), xend = freq_MT, yend = P_T_MT, group = 1), color = "darkgray")+ 
  geom_hline(aes(yintercept=0.5), color="black") + 
  geom_point(data = pops_over_M, aes(y = (1-P_E_ME), size= N_ME, group =1), fill = "white", shape = 21)+
  geom_point(data = pops_over_M, aes(y = P_T_MT, size=N_MT, group =1), fill = "black", shape = 21)  + xlim(0,1)+ 
  labs(y =  "Proportion of T-morphotype \n among  M. trossulus  and  M. edulis", x = "Proportion of M. trossulus", fill = "") + 
  ylim(0,1) + xlim(0,1) + 
  theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank()) 



# Model_4 ##############################


new_data3 <- myt2 %>% group_by(Subset, morph) %>% do(data.frame(freq_MT = seq(min(.$freq_MT), max(.$freq_MT), length.out = 100)))

# Предсказанные значеня в шкале вероятностей
new_data3$fit <- predict(Model_4_final, newdata = new_data3, type = "response", re.form = NA) 

# Предсказанные значеня в шкале логитов
new_data3$fit_eta <- predict(Model_4_final, newdata = new_data3, re.form = NA) 

# Вычисление доверительного инеравала

X <- model.matrix(  ~ morph + freq_MT + Subset + morph:freq_MT + 
                      morph:Subset + freq_MT:Subset, data = new_data3) #Модельная матрица для визуализации


# Ошибки в шкале логитов
new_data3$se_eta <- sqrt(diag(X %*% vcov(Model_4_final) %*% t(X)))

new_data3$lwr <- logit_back(new_data3$fit_eta - 1.96 * new_data3$se_eta)

new_data3$upr <- logit_back(new_data3$fit_eta + 1.96 * new_data3$se_eta)



Pl_mod4 <- ggplot(new_data3, aes(x = freq_MT)) + 
  geom_ribbon(aes(ymin = lwr, ymax = upr, group = morph), alpha = 0.1)  + 
  geom_line(aes(y = fit, color = morph), size=1, linetype = 2) + 
  geom_rug(data = myt2, inherit.aes = FALSE,  aes(x = freq_MT), size = 0.1) + 
  scale_color_manual(values = c("blue", "red")) + 
  scale_fill_manual(values = c("blue", "red"))  + 
  xlim(0,1)  + 
  facet_wrap( ~ Subset)
   


pr_value_M <- myt2 %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT), N_T = sum(ind == 1),  N_T_MT = sum(Sp2 == 1 & ind == 1), N_E_MT = sum(Sp2 == 1 & ind == 0), N_E = sum(ind == 0), N_E_ME = sum(Sp2 == 0 & ind == 0), N_T_ME = sum(Sp2 == 0 & ind == 1))

pr_value_M$PMT_T <- with(pr_value_M, N_T_MT / N_T)
pr_value_M$PMT_E <- with(pr_value_M, N_E_MT / N_T)
pr_value_M$PME_E <- with(pr_value_M, N_E_ME / N_E)
pr_value_M$PME_T <- with(pr_value_M, N_T_ME / N_E)


Pl_mod4_with_initial_data <- Pl_mod4 + geom_segment(data = pr_value_M, aes(x = freq_MT, y = PME_E, xend = freq_MT, yend = PMT_T), color="darkgrey") + 
  geom_hline(data = pr_value_M, aes(yintercept=0.5), color="black") + 
  geom_point(data = pr_value_M, aes(y = PME_E, size= N_E), fill = "white", shape = 21) + 
  geom_point(data = pr_value_M, aes(y = PMT_T, size=N_T), fill = "black", shape = 21) + 
  labs(y =  "Proportions of correct species \n identification by morphotypes", x = "Proportion of M. trossulus", fill = "")+ 
  ylim(0,1) + 
  xlim(0,1) 
# +
#   theme(strip.background = element_blank(), strip.text = element_blank())


# Model_5 ##############################


new_data5 <- myt2 %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(Prop_T) ) %>% group_by(Subset) %>%  do(data.frame(Prop_T = seq(min(.$Prop_T), max(.$Prop_T), length.out = 10)))

predicted5 <- predict(Model_5_final, newdata = new_data5,  type="response", se.fit = T)

new_data5$fit <- predicted5$fit

new_data5$SE <- predicted5$se.fit 




Pl_mod5 <- ggplot(new_data5, aes(x = Prop_T, y = fit)) + geom_line(linetype = 2, color = "red", size = 1) + facet_wrap(~Subset) + geom_ribbon(aes(ymin = fit - 1.96*SE, ymax = fit + 1.96*SE), alpha = 0.1) + xlim(0, 1) + ylim(0, 1) +  geom_rug(data = myt2, inherit.aes = FALSE,  aes(x = Prop_T), size = 0.1)




# library(ggpubr)

# ggarrange(Pl_mod1_with_initial_data, Pl_mod2_with_initial_data, Pl_mod4_with_initial_data, nrow =  3,     labels = c("A", "B", "C"))



# library(cowplot)

# plot_grid(Pl_mod1_with_initial_data, Pl_mod2_with_initial_data, Pl_mod4_with_initial_data, ncol = 1)






grid.arrange(Pl_mod1_with_initial_data, Pl_mod2_with_initial_data, Pl_mod4_with_initial_data, ncol = 1)

```

Figure ++. Visualisation of regression models.  Initial data are presented as proportions of positive outcome in particular populations. Size of points is proportional to number of mussels in the particular sample.  (A) Model1: the fill intensity is proportional to Ptros (**А то этого не видно из значений абсциссы?...**). (B) Model2: filled points - *M.trossulus* with T-morphotype; emty points - *M.edulis* with T-morphotype. (C) Model3: filled points - *M.trossulus* with T-morphotype; empty points - *M.edulis* with E-morphotype.






## Strategy for finding of calibration samples

*Важно!*    
Внимательно посмотрев на результаты подбора моделей (см. таблицу), я понял что никакого статистического основания для объединения W и BL  у нас нет. Они везде значимо расходятся (везде BL значимо отличается от базового уровня). Поэтому единственно честное решение рассматривать Subset по-отдельности. Но для поиска стратегии отбора калибровочных выборок можно пойти другим путем. Нам ведь для этого  не важно в каком регионе модель работает хорошо, а в каком работает хуже. Нам важно понять какие выборки надо делать, чтобы теоретическая модель была максимально похожа на эмпирическую регрессию. Почему бы в этой ситуации не рассматривать все выборки вместе, без разделения на Subset. То есть мы берем все возможные пары выборок, строим для них бублик и вычисляем на его основе два предсказания: одно для связи Ptros c P_T (это теоретический аналог для Model5), а второе для связи Pcorrect c Ptros и Morph (теоретический аналог Model4).Ведь оба калькулятора ничего не знают  про разность акваторий. Да и мы, стрго говоря, ввели это деление очень условно. Кроме того, поиск стратегии отбора  калибровочных выборок - задача чисто техническая, надо ответить на вопрос какой генетической структурой должны обладать две калибровочные выборки, чтобы калькуляторы давали максимально похожий ответ. В такой ситуации вообще не надо делить на акватории. Короче, для этого анализа я ЗА либо полностью объединенные Subset, либо полностью разделенные Subset.

Пока привожу результаты так, как мне кажется лучше.



```{r}

Pl_teor_empir_5 <- ggplot(perms2(df = myt2), aes(x = Delta, y = Goodness)) + geom_point(size = 0.1) + geom_smooth(se = F)


Pl_teor_empir_4 <- ggplot(perms4(df = myt2), aes(x = Delta, y = Goodness)) + geom_point(size = 0.1) + geom_smooth(se = F)

grid.arrange(Pl_teor_empir_5, Pl_teor_empir_4, nrow =1)

```



Figure +. Correspondence between regression and theoretical models. Each point corresponds to one of the possible pairs of populations from modelling data set.  OX axis represents the differencу in genetic structre for each pair of populations. OY axis represents correspondence between prediction of regression model and theoretical model. Lines represent loess-smoother. (A ) Model 5 describing  the dependence of proportion of M.trossulus (Ptros) on proportion of T-morphotype (P_T) ; (B) Model 4  describing  the dependence of probability of correct species identification (Pcorrect) on  proportion of M.trossulus (Ptros)  and morphotype (Morph). 


Отсюда мы выносим два вываода. 1. Для построения теоретической модели для прогноза Ptros по частоте T-морфотипа лучше взять в регионе интереса две калибровочные выборки максимально различающиеся по своей генетической структуре. 2. Для построения теоретической модели, которая позволит оценить вероятность корректного определения вида конкретной мидии по морфотипу необходимо взять калибровочные выборки, в которых доля M.trossulus была бы длизка к 50%. 


А во далее я предлагаю показать картинку, на которой будет следующий результат.


```{r}
# Визуализация модели 5 и ленивого калькулятора 1, основанного на выборках максимально далеких по генетической структуре.

donat_max_dif <- donat(df = myt2[myt2$pop %in% max_dif(Subset = "W"), ])
calc1_W <- calc1(donat_max_dif[1], donat_max_dif[2])
calc1_W$Subset <- "W"

donat_max_dif <- donat(df = myt2[myt2$pop %in% max_dif(Subset = "BL"), ])
calc1_BL <- calc1(donat_max_dif[1], donat_max_dif[2])
calc1_BL$Subset <- "BL"


donat_max_dif <- donat(df = myt2[myt2$pop %in% max_dif(Subset = "BH"), ])
calc1_BH <- calc1(donat_max_dif[1], donat_max_dif[2])
calc1_BH$Subset <- "BH"

calc1_res <- rbind(calc1_W, calc1_BL, calc1_BH)


Pl_calc1 <- Pl_mod5 + geom_line(data = calc1_res, aes(x = P_T, y = Ptros), color = "blue")  + geom_point(data = myt3, aes(x = Prop_T, y = freq_MT), size = 4, color = "red")  + labs(x = "Proportion of T-morphotype", y = "Proportion of M.trossulus \n")
```



```{r}
# Визуализация модели 4 и ленивого калькулятора 2, основанного на выборках максимально смешанных.


donat_max_mix <- donat(df = myt2[myt2$pop %in% max_mix(Subset = "W"), ])
calc2_W <- calc2(donat_max_mix[1], donat_max_mix[2])
calc2_W$Subset <- "W"

donat_max_mix <- donat(df = myt2[myt2$pop %in% max_mix(Subset = "BL"), ])
calc2_BL <- calc2(donat_max_mix[1], donat_max_mix[2])
calc2_BL$Subset <- "BL"


donat_max_mix <- donat(df = myt2[myt2$pop %in% max_mix(Subset = "BH"), ])
calc2_BH <- calc2(donat_max_mix[1], donat_max_mix[2])
calc2_BH$Subset <- "BH"

calc2_res <- rbind(calc2_W, calc2_BL, calc2_BH)


testing_congr <- myt3 %>% group_by(Subset, pop, morph) %>% summarize(Pcorrect = mean(congr == 1), freq_MT = mean(freq_MT))


Pl_calc2 <- Pl_mod4 + geom_line(data = calc2_res, aes(x = freq_MT, y = P_MT_T), color = "red") + geom_line(data = calc2_res, aes(x = freq_MT, y = P_ME_E), color = "blue") + geom_point(data = testing_congr, aes(x = freq_MT, y = Pcorrect, color = morph), size = 4 ) + labs(x = "Proportion of M.trossulus", y = "Probability of \ncorrect identification ")


```



```{r}
grid.arrange(Pl_calc1, Pl_calc2)
```


Figure +. Visualisation of regression models and theoretical models. Points represent the testing data set.
