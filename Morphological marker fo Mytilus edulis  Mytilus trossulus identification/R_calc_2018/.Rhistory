Pl_mod6_with_initial_data
Pl_mod7_with_initial_data
residuals(Model_2_final)
qplot(y = residuals(Model_2_final), x = myt2$size)
qplot(y = residuals(Model_2_final), x = myt2$size[!is.na(myt2$myt2$size)])
fortify(Model_2_final)
fortify(Model_2_final)
Model_2_final
fortify(Model_2_final)
fortify(Model_2_final
fortify(Model_2_final)
fortify(Model_2_final)
=======
calc1_GOM_good <- calc1(donat_max_dif[1], donat_max_dif[2]) #Предсказания калькулятора 1 на основе наиболее различных по генетической структуре популяций
calc1_GOM_bad <- calc1(donat_max_mix[1], donat_max_mix[2]) #Предсказания калькулятора 1 на основе наиболее смешанных популяций
ggplot(calc1_GOM_good, aes(x = P_T, y = Ptros)) + geom_line(color = "blue") + geom_line(data = calc1_GOM_bad, color = "gray") + geom_point(data = init_data_Model_7[init_data_Model_7$Subset == "GOM", ], aes(x = Prop_T, y = freq_MT), shape = 21, size = 2 )
# coef_calc1_W  <- coef(lm(Ptros ~ P_T, data = calc1_W )) #Коэффицинты для теоретичекой модели, описывющей калькулятор 1
# Визуализация модели 7 и ленивого калькулятора 1, основанного на выборках максимально далеких по генетической структуре.
# Популяции наиболее различные по генетической структуре
pops_max_diff <- max_dif(df = myt2, Subset = c("BALT"))
# Популяции наиболее смешанные
pops_max_mix <- max_mix(df = myt2, Subset = c("BALT"))
# Бублики для наиболее различных по стуртуре популяций
donat_max_dif <- donat(df = myt2[myt2$pop %in% pops_max_diff, ])
# Бублики для наиболее смешанных популяций
donat_max_mix <- donat(df = myt2[myt2$pop %in% pops_max_mix, ])
# Описание структуры калибровочных популяций
calc1_calib_pop_str <- calib_str(df = myt2, pop1 = pops_max_diff [1], pop2 = pops_max_diff [2])
calc2_calib_pop_str <- calib_str(df = myt2, pop1 = pops_max_mix [1], pop2 = pops_max_mix [2])
calc1_GOM_good <- calc1(donat_max_dif[1], donat_max_dif[2]) #Предсказания калькулятора 1 на основе наиболее различных по генетической структуре популяций
calc1_GOM_bad <- calc1(donat_max_mix[1], donat_max_mix[2]) #Предсказания калькулятора 1 на основе наиболее смешанных популяций
ggplot(calc1_GOM_good, aes(x = P_T, y = Ptros)) + geom_line(color = "blue") + geom_line(data = calc1_GOM_bad, color = "gray") + geom_point(data = init_data_Model_7[init_data_Model_7$Subset == "GOM", ], aes(x = Prop_T, y = freq_MT), shape = 21, size = 2 )
# coef_calc1_W  <- coef(lm(Ptros ~ P_T, data = calc1_W )) #Коэффицинты для теоретичекой модели, описывющей калькулятор 1
ggplot(calc1_GOM_good, aes(x = P_T, y = Ptros)) + geom_line(color = "blue") + geom_line(data = calc1_GOM_bad, color = "gray") + geom_point(data = init_data_Model_7[init_data_Model_7$Subset == "BALT", ], aes(x = Prop_T, y = freq_MT), shape = 21, size = 2 )
# Визуализация модели 7 и ленивого калькулятора 1, основанного на выборках максимально далеких по генетической структуре.
# Популяции наиболее различные по генетической структуре
pops_max_diff <- max_dif(df = myt2, Subset = c("SCOT"))
# Популяции наиболее смешанные
pops_max_mix <- max_mix(df = myt2, Subset = c("SCOT"))
# Бублики для наиболее различных по стуртуре популяций
donat_max_dif <- donat(df = myt2[myt2$pop %in% pops_max_diff, ])
# Бублики для наиболее смешанных популяций
donat_max_mix <- donat(df = myt2[myt2$pop %in% pops_max_mix, ])
# Описание структуры калибровочных популяций
calc1_calib_pop_str <- calib_str(df = myt2, pop1 = pops_max_diff [1], pop2 = pops_max_diff [2])
calc2_calib_pop_str <- calib_str(df = myt2, pop1 = pops_max_mix [1], pop2 = pops_max_mix [2])
calc1_GOM_good <- calc1(donat_max_dif[1], donat_max_dif[2]) #Предсказания калькулятора 1 на основе наиболее различных по генетической структуре популяций
calc1_GOM_bad <- calc1(donat_max_mix[1], donat_max_mix[2]) #Предсказания калькулятора 1 на основе наиболее смешанных популяций
ggplot(calc1_GOM_good, aes(x = P_T, y = Ptros)) + geom_line(color = "blue") + geom_line(data = calc1_GOM_bad, color = "gray") + geom_point(data = init_data_Model_7[init_data_Model_7$Subset == "SCOT", ], aes(x = Prop_T, y = freq_MT), shape = 21, size = 2 )
# coef_calc1_W  <- coef(lm(Ptros ~ P_T, data = calc1_W )) #Коэффицинты для теоретичекой модели, описывющей калькулятор 1
Subset <- "GOM"
# Популяции наиболее различные по генетической структуре
pops_max_diff <- max_dif(df = myt2, Subset = c(Subset))
# Визуализация модели 7 и ленивого калькулятора 1, основанного на выборках максимально далеких по генетической структуре.
Subset <- "GOM"
# Популяции наиболее различные по генетической структуре
pops_max_diff <- max_dif(df = myt2, Subset = c(Subset))
# Популяции наиболее смешанные
pops_max_mix <- max_mix(df = myt2, Subset = c(Subset))
# Бублики для наиболее различных по стуртуре популяций
donat_max_dif <- donat(df = myt2[myt2$pop %in% pops_max_diff, ])
# Бублики для наиболее смешанных популяций
donat_max_mix <- donat(df = myt2[myt2$pop %in% pops_max_mix, ])
# Описание структуры калибровочных популяций
calc1_calib_pop_str <- calib_str(df = myt2, pop1 = pops_max_diff [1], pop2 = pops_max_diff [2])
calc2_calib_pop_str <- calib_str(df = myt2, pop1 = pops_max_mix [1], pop2 = pops_max_mix [2])
calc1_GOM_good <- calc1(donat_max_dif[1], donat_max_dif[2]) #Предсказания калькулятора 1 на основе наиболее различных по генетической структуре популяций
calc1_GOM_bad <- calc1(donat_max_mix[1], donat_max_mix[2]) #Предсказания калькулятора 1 на основе наиболее смешанных популяций
ggplot(calc1_GOM_good, aes(x = P_T, y = Ptros)) + geom_line(color = "blue") + geom_line(data = calc1_GOM_bad, color = "gray") + geom_point(data = init_data_Model_7[init_data_Model_7$Subset == Subset, ], aes(x = Prop_T, y = freq_MT), shape = 21, size = 2 )
# coef_calc1_W  <- coef(lm(Ptros ~ P_T, data = calc1_W )) #Коэффицинты для теоретичекой модели, описывющей калькулятор 1
myt_X <- myt2[myt2$Subset %in% c("WBL", "BH"), ]
is.na(myt_X$size)
sum(is.na(myt_X$size))
sum(!is.na(myt_X$size))
Mod_X <- glmer(ind ~ size*Sp2*Subset + (1|pop), data = myt_X, family = "binomial")
Mod_X <- glmer(ind ~ size*Sp2*Subset + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X_rs <- glmer(ind ~ size*Subset + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
myt_X$Sp
myt_X$Sp2
Mod_X <- glmer(ind ~ size*Sp*Subset + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X_rs <- glmer(ind ~ size*Sp*Subset + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X <- glmer(ind ~ scale(size)*Sp*Subset + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X_rs <- glmer(ind ~ scale(size)*Sp*Subset + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
AIC(Mod_X, Mod_X_rs)
resid_cor2
resid_cor
ggplot(new_data_size, aes(x = size, y = Predict, group = pop)) + geom_line() + facet_wrap(~Subset)
Mod_X_rs <- glmer(ind ~ scale(size)*Sp*Subset + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e6)))
Mod_X <- glmer(ind ~ scale(size)*Sp + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X_rs <- glmer(ind ~ scale(size)*Sp + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e6)))
AIC(Mod_X, Mod_X_rs)
summary(Mod_X_rs)
Mod_X <- glmer(ind ~ Sp*Subset + Size + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X <- glmer(ind ~ Sp*Subset + size + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X_rs <- glmer(ind ~ Sp*Subset + size + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e6)))
AIC(Mod_X, Mod_X_rs)
summary(Mod_X_rs)
r.squaredGLMM(Mod_X_rs)
Mod_X <- glmer(ind ~ Sp*Subset * size + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X <- glmer(ind ~ Sp*Subset * size + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
library("optimx")
Mod_X <- glmer(ind ~ Sp*Subset * size + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
Mod_X_rs <- glmer(ind ~ Sp*Subset * size + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
AIC(Mod_X, Mod_X_rs)
summary(Mod_X)
library(doBy)
myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~ Sp + size, data = .))
myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~ Sp + size, family = "binomial", data = .))
myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~ size, family = "binomial", data = .))
myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~ Sp + size, family = "binomial", data = .))
table(myt_X$pop, myt_X$Sp)
myt_X <- myt2[myt2$Subset %in% c("WBL", "BH"), ]
myt_X$pop <- factor(myt_X$pop)
unique(myt_X$pop)
table(myt_X$pop, myt_X$Sp)
myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
dd <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
str(dd)
dd$model
myt_X$Sp$AIC
myt_X$Sp
dd$model$AIC
dd$model
summary(dd$model)
dd %>% tidy(model)
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models %>% tidy(model)
size_models_res <- size_models %>% tidy(model)
size_models_res
size_models_res$term
size_models_res[size_models_res$term != "(Intercept)"]
size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope
View(size_models_res_slope)
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope[size_models_res_slope$p.value < 0.05, ]
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  Sp + size, family = "binomial", data = .))
table(myt_X$pop, myt_X$Sp)
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models_res <- size_models %>% tidy(model)
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope[size_models_res_slope$p.value < 0.05, ]
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(congr ~  size, family = "binomial", data = .))
size_models_res <- size_models %>% tidy(model)
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope[size_models_res_slope$p.value < 0.05, ]
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(congr ~  size, family = "binomial", data = .))
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models_res <- size_models %>% tidy(model)
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
myt_X %>% group_by(Subset, pop) %>% summarise(rang = range(size))
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(siz))
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))[pop == "umba",]
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))[myt_X$pop == "umba",]
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "umba")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "banka")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "berzakol")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "abram")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "seredina_sub")
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models_res <- size_models %>% tidy(model)
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "ustie_sub")
size_models <- myt2 %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models_res <- size_models %>% tidy(model)
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "ustie_sub")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope[size_models_res_slope$p.value < 0.05, ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "bonferroni")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "ustie_sub")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "BH")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "ustie_sub")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
>>>>>>> 936353f66a7106e9fdddad96842ab68a4d940d5b
library(knitr)
library(flextable)
opts_chunk$set(echo = FALSE, cache = FALSE, fig.align ="center", warning = FALSE, message = FALSE)
# set pander table-layout options
library(pander)
panderOptions('table.alignment.default', function(df)
ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)
library(lme4)
library(ggplot2)
library(reshape2)
library(sjstats)
library(dplyr)
library(car)
library(doBy)
library(pROC)
library(betareg)
library(lmtest)
library(broom)
library(MuMIn)
library(gridExtra)
#### Data reading and initial preparation #####
myt <- read.table("data_salinity3.csv", header = T, sep = ",")
myt_overseas <- myt[myt$dataset == "overseas", ]
myt <- myt[myt$dataset != "overseas", ]
myt$Sp [myt$str > 0.5] <- "M.trossulus" #Лучше обозначать так!
myt$Sp [myt$str <= 0.5] <- "M.edulis"
myt$Sp <- factor(myt$Sp)
# Оставляем только мидий, у которых есть оценка морфотипа
myt2 <- myt[!is.na(myt$ind), ]
# Вводим обозначения для морфотипов
myt2$morph <- ifelse(myt2$ind == 1, "T_m", "E_m")
myt2$morph <- factor(myt2$morph)
# Бинарное обозначение видов
myt2$Sp2 <- ifelse(myt2$Sp == "M.trossulus", 1, 0)
#Correct identification
myt2$congr <- ifelse((myt2$ind == 1 & myt2$Sp == "M.trossulus") | (myt2$ind == 0 & myt2$Sp == "M.edulis"), 1, 0   )
# Частота M.trossulus в популяции
freq_MT <- myt2 %>% group_by(pop) %>% summarise(freq_MT = mean(Sp2))
myt2 <- merge(myt2, freq_MT)
# Частота T-морфотипа в популяции
Prop_T <- myt2 %>% group_by(pop) %>% summarise(Prop_T = mean(ind))
myt2 <- merge(myt2, Prop_T)
# Подразделяем данные на три сабсета
myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "fresh"] <- "BL"
myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "normal"] <- "BH"
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "normal"] <- "W"
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "fresh"] <- "W"
myt2$Subset <- factor(myt2$Subset, levels = c("W", "BL", "BH"))
#
#Оставляем только данные, на основе, которых строится модель
myt3 <- myt2[myt2$dataset == "testing", ]
myt2 <- myt2[myt2$dataset == "training", ]
# Извлекаем из беломорского материала тестовую выборку
#В формальную тестовую выборку  попадают точки наиболее близкие к 20%, 40%, 60% и 80% freq_MT
selected_pop <- myt2[myt2$Subset == "W", ] %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT)) %>% group_by(Subset) %>% arrange(freq_MT, .by_group = TRUE) %>% mutate(dif_20 = (freq_MT - 0.2)^2, dif_40 = (freq_MT - 0.4)^2, dif_60 = (freq_MT - 0.6)^2, dif_80 = (freq_MT - 0.8)^2)  %>% group_by(Subset)  %>% summarize (n_pop =n(), q_20_pop = nth(pop, which.min(dif_20)), q_40_pop = nth(pop, which.min(dif_40)), q_60_pop = nth(pop, which.min(dif_60)), q_80_pop = nth(pop, which.min(dif_80)))
selected_pop <- melt(selected_pop, id.vars = c("Subset", "n_pop"))$value
myt4 <- myt2[myt2$pop %in% selected_pop, ] #новый testing dataset for the White sea
myt3 <- rbind(myt3, myt4)
myt2 <- myt2[!(myt2$pop %in% selected_pop), ] #новый modelling dataset
library(knitr)
library(flextable)
opts_chunk$set(echo = FALSE, cache = FALSE, fig.align ="center", warning = FALSE, message = FALSE)
# set pander table-layout options
library(pander)
panderOptions('table.alignment.default', function(df)
ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)
library(lme4)
library(ggplot2)
library(reshape2)
library(sjstats)
library(dplyr)
library(car)
library(doBy)
library(pROC)
library(betareg)
library(lmtest)
library(broom)
library(MuMIn)
library(gridExtra)
#### Data reading and initial preparation #####
myt <- read.table("data_salinity3.csv", header = T, sep = ",")
myt_overseas <- myt[myt$dataset == "overseas", ]
myt <- myt[myt$dataset != "overseas", ]
myt$Sp [myt$str > 0.5] <- "M.trossulus" #Лучше обозначать так!
myt$Sp [myt$str <= 0.5] <- "M.edulis"
myt$Sp <- factor(myt$Sp)
# Оставляем только мидий, у которых есть оценка морфотипа
myt2 <- myt[!is.na(myt$ind), ]
# Вводим обозначения для морфотипов
myt2$morph <- ifelse(myt2$ind == 1, "T_m", "E_m")
myt2$morph <- factor(myt2$morph)
# Бинарное обозначение видов
myt2$Sp2 <- ifelse(myt2$Sp == "M.trossulus", 1, 0)
#Correct identification
myt2$congr <- ifelse((myt2$ind == 1 & myt2$Sp == "M.trossulus") | (myt2$ind == 0 & myt2$Sp == "M.edulis"), 1, 0   )
# Частота M.trossulus в популяции
freq_MT <- myt2 %>% group_by(pop) %>% summarise(freq_MT = mean(Sp2))
myt2 <- merge(myt2, freq_MT)
# Частота T-морфотипа в популяции
Prop_T <- myt2 %>% group_by(pop) %>% summarise(Prop_T = mean(ind))
myt2 <- merge(myt2, Prop_T)
# Подразделяем данные на три сабсета
myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "fresh"] <- "BL"
myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "normal"] <- "BH"
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "normal"] <- "W"
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "fresh"] <- "W"
myt2$Subset <- factor(myt2$Subset, levels = c("W", "BL", "BH"))
#
#Оставляем только данные, на основе, которых строится модель
myt3 <- myt2[myt2$dataset == "testing", ]
myt2 <- myt2[myt2$dataset == "training", ]
# Извлекаем из беломорского материала тестовую выборку
#В формальную тестовую выборку  попадают точки наиболее близкие к 20%, 40%, 60% и 80% freq_MT
selected_pop <- myt2[myt2$Subset == "W", ] %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT)) %>% group_by(Subset) %>% arrange(freq_MT, .by_group = TRUE) %>% mutate(dif_20 = (freq_MT - 0.2)^2, dif_40 = (freq_MT - 0.4)^2, dif_60 = (freq_MT - 0.6)^2, dif_80 = (freq_MT - 0.8)^2)  %>% group_by(Subset)  %>% summarize (n_pop =n(), q_20_pop = nth(pop, which.min(dif_20)), q_40_pop = nth(pop, which.min(dif_40)), q_60_pop = nth(pop, which.min(dif_60)), q_80_pop = nth(pop, which.min(dif_80)))
selected_pop <- melt(selected_pop, id.vars = c("Subset", "n_pop"))$value
myt4 <- myt2[myt2$pop %in% selected_pop, ] #новый testing dataset for the White sea
myt3 <- rbind(myt3, myt4)
myt2 <- myt2[!(myt2$pop %in% selected_pop), ] #новый modelling dataset
myt3_print <- myt3 %>% group_by(Subset, pop) %>% summarise(N_Tm_T = sum(morph == "T_m" & Sp == "M.trossulus"), N_Em_T = sum(morph == "E_m" & Sp == "M.trossulus"), N_Tm_E = sum(morph == "T_m" & Sp == "M.edulis"), N_Em_E = sum(morph == "E_m" & Sp == "M.edulis"), Ptros = round(mean(Sp == "M.trossulus"), 2 ))
myt3_print_out <- flextable(
myt3_print,
col_keys = c("Subset",	"Population",	"N_Tm_T",	"N_Em_T",	"N_Tm_E",	"N_Em_E",	"Ptros"))
# kable(myt3_print)
# myt3_print_out
myt2_print <- myt2 %>% group_by(Subset, pop) %>% summarise(N_Tm_T = sum(morph == "T_m" & Sp == "M.trossulus"), N_Em_T = sum(morph == "E_m" & Sp == "M.trossulus"), N_Tm_E = sum(morph == "T_m" & Sp == "M.edulis"), N_Em_E = sum(morph == "E_m" & Sp == "M.edulis"), Ptros = round(mean(Sp == "M.trossulus"), 2 ))
# kable(myt2_print)
# Функция для вычисления P_T_MT и P_T_ME в заданном датасете (БУБЛИК) ####
donat <- function(df){
P_MT <- sum(df$Sp == "M.trossulus")
P_T_MT <- sum(df$Sp == "M.trossulus" & df$morph == "T_m")/P_MT
P_ME <- sum(df$Sp == "M.edulis")
P_T_ME <- sum(df$Sp == "M.edulis" & df$morph == "T_m")/P_ME
c(P_T_MT, P_T_ME)
}
########################################3
#Функция для "ленивого" калькулятора №1 который строит зависимость Ptros от P_T
# На входе параметры бублика
calc1 <- function(P_T_MT, P_T_ME){
result <- data.frame(P_T = seq(0, 1, 0.01))
result$Ptros <- (result$P_T - P_T_ME)/(P_T_MT - P_T_ME)
result <- result[result$P_T <= P_T_MT & result$P_T >= P_T_ME, ]
result
}
# Функция для вычисления баесовских вероятностей по данным из бублика
calc2 <- function(P_T_MT, P_T_ME){
result <- data.frame(freq_MT = seq(0, 1, 0.01))
result$P_MT_T <- (P_T_MT * result$freq_MT)/(P_T_MT * result$freq_MT + P_T_ME*(1-result$freq_MT))
result$P_ME_E <- ((1 - P_T_ME) * (1 - result$freq_MT))/(1 - P_T_ME + result$freq_MT * (P_T_ME - P_T_MT))
result
}
########################################3
# Фунция для определения похожести между эмпирическим и теоретическими моделями для МОДЕЛИ 5 (Ptros vs P_T)
perms2 <- function(df = myt2[myt2$Subset == "W", ], regr_model = Model_5_final,...) {
require(dplyr)
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
W <- donat(df_selected)
calc1_predict_W <- calc1(W[1], W[2])
names(calc1_predict_W) <- c("Prop_T", "Ptros_predicted" )
Model_prediction <- expand.grid(Subset = unique(df_selected$Subset), Prop_T = seq(0, 1, 0.01))
Model_prediction$Predict <- predict(regr_model, newdata = Model_prediction, type = "response")
all_prediction <- merge(calc1_predict_W, Model_prediction, by = c("Prop_T"))
perm_pairs$Goodness[i] <- 1/(mean((all_prediction$Predict - all_prediction$Ptros_predicted)^2))
}
perm_pairs
}
# Фунция для определения похожести между эмпирическими и теоретическими моделями для МОДЕЛИ 4 (Congr vs Ptros; Morph)
perms4 <- function(df = myt2[myt2$Subset == "W"], regr_model =  Model_4_final, ...) {
require(dplyr)
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
# perm_pairs$Delta[i] <- abs(means$freq_MT[1] - means$freq_MT[2])
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
W <- donat(df_selected)
calc2_predict_W <- calc2(W[1], W[2])
names(calc2_predict_W) <- c("freq_MT", "T_m",  "E_m")
calc2_predict_W <- melt(calc2_predict_W, id.vars = "freq_MT" )
names(calc2_predict_W) <- c("freq_MT", "morph", "Bayes_predict")
Model_prediction <- expand.grid(Subset = unique(df_selected$Subset),  morph = levels(df_selected$morph), freq_MT = seq(0, 1, 0.01))
Model_prediction$Predict <- predict(regr_model, newdata = Model_prediction, type = "response",  re.form = NA )
all_prediction <- merge(calc2_predict_W, Model_prediction, by = c("freq_MT", "morph"))
perm_pairs$Goodness[i] <- 1/mean((all_prediction$Bayes_predict - all_prediction$Predict)^2, na.rm = T)
perm_pairs$pop[i] <- unique(as.character(df_selected$pop))
}
perm_pairs
}
## Функция для поиска ниболее различающихся выборок
max_dif <- function(df = myt2, Subset = "W", ...) {
require(dplyr)
df = df[df$Subset %in% Subset, ]
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
}
max_dif <- perm_pairs[which.max(perm_pairs$Delta), ]
c(max_dif$First, max_dif$Second)
}
max_mix <- function(df = myt2, Subset = "W", ...) {
require(dplyr)
df = df[df$Subset %in% Subset, ]
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
}
max_mix <- perm_pairs[which.min(abs(perm_pairs$Delta - 0.25)), ]
c(max_mix$First, max_mix$Second)
}
### Функция для описания структуры калибровочных выборок
calib_str <- function(df = myt2, pop1, pop2){
df =df[df$pop %in% c(pop1, pop2), ]
df$Subset <- factor(df$Subset)
str_calib <- df %>% group_by(pop, Subset) %>% summarize(N_E = sum(Sp == "M.edulis"), N_T = sum(Sp ==  "M.trossulus"), P_T_ME = mean(Sp == "M.edulis" & morph == "T_m"), P_T_MT = mean(Sp == "M.trossulus" & morph == "T_m"), Ptros = mean(freq_MT) )
str_calib
}
########################################
# Функция для обратной трансформации логитов
logit_back <- function(x) exp(x)/(1 + exp(x)) # обратная логит-трансформация
# Функция для оценки сверхдисперсии в моделях GLM
overdisp_fun <- function(model) {
rdf <- df.residual(model)  # Число степеней свободы N - p
if (inherits(model, 'negbin')) rdf <- rdf - 1 ## учитываем k в NegBin GLMM
rp <- residuals(model,type='pearson') # Пирсоновские остатки
Pearson.chisq <- sum(rp^2) # Сумма квадратов остатков, подчиняется Хи-квадрат распределению
prat <- Pearson.chisq/rdf  # Отношение суммы квадратов остатков к числу степеней свободы
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE) # Уровень значимости
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)        # Вывод результатов
}
##### Theme for ggplot ######
theme_set(theme_bw() + theme(axis.title.x = element_text(size = 10), axis.title.y = element_text(size = 10), axis.text= element_text(size = 10), legend.position = "none" , title = element_text(size = 10)))
myt_pure <- myt2 %>% filter(str >= 0.9 | str<=0.1)
myt_pure <- myt2 %>% filter(str >= 0.9 | str<=0.1)
myt_pure
mixed_data
myt_pure <- mixed_data %>% filter(str >= 0.9 | str<=0.1) %>%
myt_pure <- mixed_data %>% filter(str >= 0.9 | str<=0.1)
myt_pure <- mixed_data %>% filter(str >= 0.9 | str<=0.1)
myt_pure
str(myt_pure)
unique(myt_pure$Subset)
myt_pure <- myt2 %>% filter(str >= 0.9 | str<=0.1)
unique(myt_pure$Subset)
myt_pure$Subset2 <- ifelse(myt_pure$Subset == "BH", "BH", "WBL")
myt_pure$Subset2
Mod_pure <- glmer(ind ~ str * freq_MT + (1 | pop), data = myt_pure, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_pure <- glmer(ind ~ str * freq_MT*Subset2 + (1 | pop), data = myt_pure, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
drop1(Mod_pure)
Mod_pure <- glmer(ind ~ Sp*freq_MT*Subset2 + (1 | pop), data = myt_pure, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
drop1(Mod_pure)
new_data_pure <- myt_pure %>% group_by(Sp, Subset2) %>% do(data.frame(freq_MT = seq(min(.$freq_MT), max(.$freq_MT), length.out = 100)))
# Предсказанные значеня в шкале вероятностей
new_data_pure$fit <- predict(Mod_pure, newdata = new_data_pure, type = "response", re.form = NA)
# Предсказанные значеня в шкале логитов
new_data_pure$fit_eta <- predict(Mod_pure, newdata = new_data_pure, re.form = NA)
X <- model.matrix(  ~ Sp * freq_MT*Subset2, data = new_data_pure) #Модельная матрица для визуализации
# Ошибки в шкале логитов
new_data_pure$se_eta <- sqrt(diag(X %*% vcov(Mod_pure) %*% t(X)))
new_data_pure
new_data_pure$lwr <- logit_back(new_data_pure$fit_eta - 1.96 * new_data_pure$se_eta)
new_data_pure$upr <- logit_back(new_data_pure$fit_eta + 1.96 * new_data_pure$se_eta)
Pl_mod_pure <- ggplot(new_data_pure, aes(x = freq_MT)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, group = morph), alpha = 0.1)  +
geom_line(aes(y = fit, color = morph), size=1, linetype = 2)
Pl_mod_pure
Pl_mod_pure <- ggplot(new_data_pure, aes(x = freq_MT)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, group = morph), alpha = 0.1)  +
geom_line(aes(y = fit, color = Sp), size=1, linetype = 2)
Pl_mod_pure
Pl_mod_pure <- ggplot(new_data_pure, aes(x = freq_MT)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, group = Sp), alpha = 0.1)  +
geom_line(aes(y = fit, color = Sp), size=1, linetype = 2)
Pl_mod_pure
Pl_mod_pure <- ggplot(new_data_pure, aes(x = freq_MT)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, group = Sp), alpha = 0.1)  +
geom_line(aes(y = fit, color = Sp), size=1, linetype = 2) +
xlim(0,1)+
facet_wrap(~Subset2)
Pl_mod_pure
