<<<<<<< HEAD
Pl_mod6_with_initial_data
Pl_mod7_with_initial_data
residuals(Model_2_final)
qplot(y = residuals(Model_2_final), x = myt2$size)
qplot(y = residuals(Model_2_final), x = myt2$size[!is.na(myt2$myt2$size)])
fortify(Model_2_final)
fortify(Model_2_final)
Model_2_final
fortify(Model_2_final)
fortify(Model_2_final
fortify(Model_2_final)
fortify(Model_2_final)
=======
calc1_GOM_good <- calc1(donat_max_dif[1], donat_max_dif[2]) #Предсказания калькулятора 1 на основе наиболее различных по генетической структуре популяций
calc1_GOM_bad <- calc1(donat_max_mix[1], donat_max_mix[2]) #Предсказания калькулятора 1 на основе наиболее смешанных популяций
ggplot(calc1_GOM_good, aes(x = P_T, y = Ptros)) + geom_line(color = "blue") + geom_line(data = calc1_GOM_bad, color = "gray") + geom_point(data = init_data_Model_7[init_data_Model_7$Subset == "GOM", ], aes(x = Prop_T, y = freq_MT), shape = 21, size = 2 )
# coef_calc1_W  <- coef(lm(Ptros ~ P_T, data = calc1_W )) #Коэффицинты для теоретичекой модели, описывющей калькулятор 1
# Визуализация модели 7 и ленивого калькулятора 1, основанного на выборках максимально далеких по генетической структуре.
# Популяции наиболее различные по генетической структуре
pops_max_diff <- max_dif(df = myt2, Subset = c("BALT"))
# Популяции наиболее смешанные
pops_max_mix <- max_mix(df = myt2, Subset = c("BALT"))
# Бублики для наиболее различных по стуртуре популяций
donat_max_dif <- donat(df = myt2[myt2$pop %in% pops_max_diff, ])
# Бублики для наиболее смешанных популяций
donat_max_mix <- donat(df = myt2[myt2$pop %in% pops_max_mix, ])
# Описание структуры калибровочных популяций
calc1_calib_pop_str <- calib_str(df = myt2, pop1 = pops_max_diff [1], pop2 = pops_max_diff [2])
calc2_calib_pop_str <- calib_str(df = myt2, pop1 = pops_max_mix [1], pop2 = pops_max_mix [2])
calc1_GOM_good <- calc1(donat_max_dif[1], donat_max_dif[2]) #Предсказания калькулятора 1 на основе наиболее различных по генетической структуре популяций
calc1_GOM_bad <- calc1(donat_max_mix[1], donat_max_mix[2]) #Предсказания калькулятора 1 на основе наиболее смешанных популяций
ggplot(calc1_GOM_good, aes(x = P_T, y = Ptros)) + geom_line(color = "blue") + geom_line(data = calc1_GOM_bad, color = "gray") + geom_point(data = init_data_Model_7[init_data_Model_7$Subset == "GOM", ], aes(x = Prop_T, y = freq_MT), shape = 21, size = 2 )
# coef_calc1_W  <- coef(lm(Ptros ~ P_T, data = calc1_W )) #Коэффицинты для теоретичекой модели, описывющей калькулятор 1
ggplot(calc1_GOM_good, aes(x = P_T, y = Ptros)) + geom_line(color = "blue") + geom_line(data = calc1_GOM_bad, color = "gray") + geom_point(data = init_data_Model_7[init_data_Model_7$Subset == "BALT", ], aes(x = Prop_T, y = freq_MT), shape = 21, size = 2 )
# Визуализация модели 7 и ленивого калькулятора 1, основанного на выборках максимально далеких по генетической структуре.
# Популяции наиболее различные по генетической структуре
pops_max_diff <- max_dif(df = myt2, Subset = c("SCOT"))
# Популяции наиболее смешанные
pops_max_mix <- max_mix(df = myt2, Subset = c("SCOT"))
# Бублики для наиболее различных по стуртуре популяций
donat_max_dif <- donat(df = myt2[myt2$pop %in% pops_max_diff, ])
# Бублики для наиболее смешанных популяций
donat_max_mix <- donat(df = myt2[myt2$pop %in% pops_max_mix, ])
# Описание структуры калибровочных популяций
calc1_calib_pop_str <- calib_str(df = myt2, pop1 = pops_max_diff [1], pop2 = pops_max_diff [2])
calc2_calib_pop_str <- calib_str(df = myt2, pop1 = pops_max_mix [1], pop2 = pops_max_mix [2])
calc1_GOM_good <- calc1(donat_max_dif[1], donat_max_dif[2]) #Предсказания калькулятора 1 на основе наиболее различных по генетической структуре популяций
calc1_GOM_bad <- calc1(donat_max_mix[1], donat_max_mix[2]) #Предсказания калькулятора 1 на основе наиболее смешанных популяций
ggplot(calc1_GOM_good, aes(x = P_T, y = Ptros)) + geom_line(color = "blue") + geom_line(data = calc1_GOM_bad, color = "gray") + geom_point(data = init_data_Model_7[init_data_Model_7$Subset == "SCOT", ], aes(x = Prop_T, y = freq_MT), shape = 21, size = 2 )
# coef_calc1_W  <- coef(lm(Ptros ~ P_T, data = calc1_W )) #Коэффицинты для теоретичекой модели, описывющей калькулятор 1
Subset <- "GOM"
# Популяции наиболее различные по генетической структуре
pops_max_diff <- max_dif(df = myt2, Subset = c(Subset))
# Визуализация модели 7 и ленивого калькулятора 1, основанного на выборках максимально далеких по генетической структуре.
Subset <- "GOM"
# Популяции наиболее различные по генетической структуре
pops_max_diff <- max_dif(df = myt2, Subset = c(Subset))
# Популяции наиболее смешанные
pops_max_mix <- max_mix(df = myt2, Subset = c(Subset))
# Бублики для наиболее различных по стуртуре популяций
donat_max_dif <- donat(df = myt2[myt2$pop %in% pops_max_diff, ])
# Бублики для наиболее смешанных популяций
donat_max_mix <- donat(df = myt2[myt2$pop %in% pops_max_mix, ])
# Описание структуры калибровочных популяций
calc1_calib_pop_str <- calib_str(df = myt2, pop1 = pops_max_diff [1], pop2 = pops_max_diff [2])
calc2_calib_pop_str <- calib_str(df = myt2, pop1 = pops_max_mix [1], pop2 = pops_max_mix [2])
calc1_GOM_good <- calc1(donat_max_dif[1], donat_max_dif[2]) #Предсказания калькулятора 1 на основе наиболее различных по генетической структуре популяций
calc1_GOM_bad <- calc1(donat_max_mix[1], donat_max_mix[2]) #Предсказания калькулятора 1 на основе наиболее смешанных популяций
ggplot(calc1_GOM_good, aes(x = P_T, y = Ptros)) + geom_line(color = "blue") + geom_line(data = calc1_GOM_bad, color = "gray") + geom_point(data = init_data_Model_7[init_data_Model_7$Subset == Subset, ], aes(x = Prop_T, y = freq_MT), shape = 21, size = 2 )
# coef_calc1_W  <- coef(lm(Ptros ~ P_T, data = calc1_W )) #Коэффицинты для теоретичекой модели, описывющей калькулятор 1
myt_X <- myt2[myt2$Subset %in% c("WBL", "BH"), ]
is.na(myt_X$size)
sum(is.na(myt_X$size))
sum(!is.na(myt_X$size))
Mod_X <- glmer(ind ~ size*Sp2*Subset + (1|pop), data = myt_X, family = "binomial")
Mod_X <- glmer(ind ~ size*Sp2*Subset + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X_rs <- glmer(ind ~ size*Subset + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
myt_X$Sp
myt_X$Sp2
Mod_X <- glmer(ind ~ size*Sp*Subset + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X_rs <- glmer(ind ~ size*Sp*Subset + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X <- glmer(ind ~ scale(size)*Sp*Subset + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X_rs <- glmer(ind ~ scale(size)*Sp*Subset + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
AIC(Mod_X, Mod_X_rs)
resid_cor2
resid_cor
ggplot(new_data_size, aes(x = size, y = Predict, group = pop)) + geom_line() + facet_wrap(~Subset)
Mod_X_rs <- glmer(ind ~ scale(size)*Sp*Subset + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e6)))
Mod_X <- glmer(ind ~ scale(size)*Sp + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X_rs <- glmer(ind ~ scale(size)*Sp + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e6)))
AIC(Mod_X, Mod_X_rs)
summary(Mod_X_rs)
Mod_X <- glmer(ind ~ Sp*Subset + Size + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X <- glmer(ind ~ Sp*Subset + size + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X_rs <- glmer(ind ~ Sp*Subset + size + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e6)))
AIC(Mod_X, Mod_X_rs)
summary(Mod_X_rs)
r.squaredGLMM(Mod_X_rs)
Mod_X <- glmer(ind ~ Sp*Subset * size + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_X <- glmer(ind ~ Sp*Subset * size + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
library("optimx")
Mod_X <- glmer(ind ~ Sp*Subset * size + (1|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
Mod_X_rs <- glmer(ind ~ Sp*Subset * size + (1 + size|pop), data = myt_X, family = "binomial", control=glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
AIC(Mod_X, Mod_X_rs)
summary(Mod_X)
library(doBy)
myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~ Sp + size, data = .))
myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~ Sp + size, family = "binomial", data = .))
myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~ size, family = "binomial", data = .))
myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~ Sp + size, family = "binomial", data = .))
table(myt_X$pop, myt_X$Sp)
myt_X <- myt2[myt2$Subset %in% c("WBL", "BH"), ]
myt_X$pop <- factor(myt_X$pop)
unique(myt_X$pop)
table(myt_X$pop, myt_X$Sp)
myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
dd <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
str(dd)
dd$model
myt_X$Sp$AIC
myt_X$Sp
dd$model$AIC
dd$model
summary(dd$model)
dd %>% tidy(model)
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models %>% tidy(model)
size_models_res <- size_models %>% tidy(model)
size_models_res
size_models_res$term
size_models_res[size_models_res$term != "(Intercept)"]
size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope
View(size_models_res_slope)
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope[size_models_res_slope$p.value < 0.05, ]
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  Sp + size, family = "binomial", data = .))
table(myt_X$pop, myt_X$Sp)
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models_res <- size_models %>% tidy(model)
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope[size_models_res_slope$p.value < 0.05, ]
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(congr ~  size, family = "binomial", data = .))
size_models_res <- size_models %>% tidy(model)
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope[size_models_res_slope$p.value < 0.05, ]
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(congr ~  size, family = "binomial", data = .))
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models_res <- size_models %>% tidy(model)
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
myt_X %>% group_by(Subset, pop) %>% summarise(rang = range(size))
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(siz))
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))[pop == "umba",]
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))[myt_X$pop == "umba",]
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "umba")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "banka")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "berzakol")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "abram")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "seredina_sub")
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models_res <- size_models %>% tidy(model)
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "ustie_sub")
size_models <- myt2 %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models <- myt_X %>% group_by(Subset, pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models_res <- size_models %>% tidy(model)
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "ustie_sub")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope[size_models_res_slope$p.value < 0.05, ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "bonferroni")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "ustie_sub")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "BH")
myt_X %>% group_by(Subset, pop) %>% summarise(min = min(size), max = max(size))%>% filter(pop == "ustie_sub")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope[size_models_res_slope$p_adj < 0.05, ]
>>>>>>> 936353f66a7106e9fdddad96842ab68a4d940d5b
library(knitr)
library(flextable)
opts_chunk$set(echo = FALSE, cache = FALSE, fig.align ="center", warning = FALSE, message = FALSE)
# set pander table-layout options
library(pander)
panderOptions('table.alignment.default', function(df)
ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)
library(lme4)
library(ggplot2)
library(reshape2)
library(sjstats)
library(dplyr)
library(car)
library(doBy)
library(pROC)
library(betareg)
library(lmtest)
library(broom)
library(MuMIn)
library(gridExtra)
#### Data reading and initial preparation #####
myt <- read.table("data_salinity3.csv", header = T, sep = ",")
myt_overseas <- myt[myt$dataset == "overseas", ]
myt <- myt[myt$dataset != "overseas", ]
myt$Sp [myt$str > 0.5] <- "M.trossulus" #Лучше обозначать так!
myt$Sp [myt$str <= 0.5] <- "M.edulis"
myt$Sp <- factor(myt$Sp)
# Оставляем только мидий, у которых есть оценка морфотипа
myt2 <- myt[!is.na(myt$ind), ]
# Вводим обозначения для морфотипов
myt2$morph <- ifelse(myt2$ind == 1, "T_m", "E_m")
myt2$morph <- factor(myt2$morph)
# Бинарное обозначение видов
myt2$Sp2 <- ifelse(myt2$Sp == "M.trossulus", 1, 0)
#Correct identification
myt2$congr <- ifelse((myt2$ind == 1 & myt2$Sp == "M.trossulus") | (myt2$ind == 0 & myt2$Sp == "M.edulis"), 1, 0   )
# Частота M.trossulus в популяции
freq_MT <- myt2 %>% group_by(pop) %>% summarise(freq_MT = mean(Sp2))
myt2 <- merge(myt2, freq_MT)
# Частота T-морфотипа в популяции
Prop_T <- myt2 %>% group_by(pop) %>% summarise(Prop_T = mean(ind))
myt2 <- merge(myt2, Prop_T)
# Подразделяем данные на три сабсета
myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "fresh"] <- "BL"
myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "normal"] <- "BH"
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "normal"] <- "W"
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "fresh"] <- "W"
myt2$Subset <- factor(myt2$Subset, levels = c("W", "BL", "BH"))
#
#Оставляем только данные, на основе, которых строится модель
myt3 <- myt2[myt2$dataset == "testing", ]
myt2 <- myt2[myt2$dataset == "training", ]
# Извлекаем из беломорского материала тестовую выборку
#В формальную тестовую выборку  попадают точки наиболее близкие к 20%, 40%, 60% и 80% freq_MT
selected_pop <- myt2[myt2$Subset == "W", ] %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT)) %>% group_by(Subset) %>% arrange(freq_MT, .by_group = TRUE) %>% mutate(dif_20 = (freq_MT - 0.2)^2, dif_40 = (freq_MT - 0.4)^2, dif_60 = (freq_MT - 0.6)^2, dif_80 = (freq_MT - 0.8)^2)  %>% group_by(Subset)  %>% summarize (n_pop =n(), q_20_pop = nth(pop, which.min(dif_20)), q_40_pop = nth(pop, which.min(dif_40)), q_60_pop = nth(pop, which.min(dif_60)), q_80_pop = nth(pop, which.min(dif_80)))
selected_pop <- melt(selected_pop, id.vars = c("Subset", "n_pop"))$value
myt4 <- myt2[myt2$pop %in% selected_pop, ] #новый testing dataset for the White sea
myt3 <- rbind(myt3, myt4)
myt2 <- myt2[!(myt2$pop %in% selected_pop), ] #новый modelling dataset
library(knitr)
library(flextable)
opts_chunk$set(echo = FALSE, cache = FALSE, fig.align ="center", warning = FALSE, message = FALSE)
# set pander table-layout options
library(pander)
panderOptions('table.alignment.default', function(df)
ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)
=======
test_Model_4$PME_E <- with(test_Model_4, N_E_ME / N_E)
test_Model_4$PME_T <- with(test_Model_4, N_T_ME / N_E)
Pl_mod4_with_initial_data <- Pl_mod4_with_initial_data_no_test + geom_point(data = test_Model_4, aes(y = PME_E, size= N_E), fill = "red", shape = 24) +
geom_point(data = test_Model_4, aes(y = PMT_T, size=N_T), fill = "blue", shape = 24)
# Model_5 ##############################
new_data5 <- myt2 %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(Prop_T) ) %>% group_by(Subset) %>%  do(data.frame(Prop_T = seq(min(.$Prop_T), max(.$Prop_T), length.out = 10)))
predicted5 <- predict(Model_5_final, newdata = new_data5,  type="response", se.fit = T)
new_data5$fit <- predicted5$fit
new_data5$SE <- predicted5$se.fit
Pl_mod5 <- ggplot(new_data5, aes(x = Prop_T, y = fit)) + geom_line(linetype = 2, color = "red", size = 1) + facet_wrap(~Subset) + geom_ribbon(aes(ymin = fit - 1.96*SE, ymax = fit + 1.96*SE), alpha = 0.1) + xlim(0, 1) + ylim(0, 1) +  geom_rug(data = myt2, inherit.aes = FALSE,  aes(x = Prop_T), size = 0.1) + geom_abline()
init_data_Model_5 <- myt2 %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(morph == "T_m"),  freq_MT = mean(Sp == "M.trossulus"), N = n())
Pl_mod5_with_initial_data_no_test <- Pl_mod5 + geom_point(data = init_data_Model_5, aes( y = freq_MT, size = N, fill = freq_MT), shape = 21 ) + scale_fill_continuous(low = "white", high = "black") + labs(x = "Proportion of mussels with T-morphotype", y = "Proportion of M.trossulus \n")
test_Model_5 <- myt3 %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(morph == "T_m"),  freq_MT = mean(Sp == "M.trossulus"), N = n())
Pl_mod5_with_initial_data <- Pl_mod5_with_initial_data_no_test + geom_point(data = test_Model_5, aes( y = freq_MT, size = N, fill = freq_MT), shape = 24, fill = "red" )
# grid.arrange(Pl_mod1_with_initial_data ,
#              Pl_mod2_with_initial_data + theme(strip.text = element_blank()),
#              Pl_mod3_with_initial_data + theme(strip.text = element_blank()),
#              Pl_mod4_with_initial_data+ theme(strip.text = element_blank()) ,
#              ncol = 1)
grid.arrange(Pl_mod1_with_initial_data ,
Pl_mod2_with_initial_data_no_test + theme(strip.text = element_blank()),
Pl_mod4_with_initial_data_no_test + theme(strip.text = element_blank()) ,
ncol = 1)
# Анализ корреляции с размерами
# residuals(Model_2_final)
Model_2_final_diagn <- fortify(Model_2_final)
# sum(is.na(myt2$resid_siz))
resid_siz <- merge(myt2, Model_2_final_diagn)
resid_siz <- resid_siz[!is.na(resid_siz$siz), ]
# cor.test(resid_siz$.scresid, resid_siz$size )
# ggplot(resid_siz, aes(x = size, y = .scresid)) + geom_point() + geom_smooth(method= "lm")
# sum(is.na(resid_siz$size))
resid_cor <- resid_siz %>% group_by(Subset, pop) %>% summarise(cor = cor.test(.scresid, size, method = "pearson")$estimate, p = cor.test(.scresid, size, method = "pearson")$p.value)
# str((cor.test(resid_siz$.scresid, resid_siz$size, method = "pearson")))
resid_cor$p_adj <- p.adjust(resid_cor$p, method = "hochberg")
# sum(resid_cor$p_adj < 0.05, na.rm = T)
# kable(resid_cor[resid_cor$p_adj < 0.05, ])
# То же самое для модели 4
# residuals(Model_4_final)
Model_4_final_diagn <- fortify(Model_4_final)
# sum(is.na(myt2$resid_siz))
resid_siz2 <- merge(myt2, Model_4_final_diagn)
resid_siz2 <- resid_siz2[!is.na(resid_siz2$siz), ]
# sum(is.na(resid_siz2$size))
# ggplot(resid_siz2, aes(x = size, y = .scresid)) + geom_point() + geom_smooth()
# cor.test(resid_siz2$.scresid, resid_siz2$size )
resid_cor2 <- resid_siz2 %>% group_by(Subset, pop) %>% summarise(cor = cor.test(.scresid, size, method = "pearson")$estimate, p = cor.test(.scresid, size, method = "pearson")$p.value)
# str((cor.test(resid_siz$.scresid, resid_siz$size, method = "pearson")))
resid_cor2$p_adj <- p.adjust(resid_cor2$p, method = "hochberg")
# kable(resid_cor2[resid_cor2$p_adj < 0.05, ])
## Анализ связи с размерами в каждой из популяций
myt2$pop <- factor(myt2$pop)
myt2$Subset <- factor(myt2$Subset)
size_models <- myt2 %>% group_by(pop) %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models_res <- size_models %>% tidy(model)
size_models_res_slope <- size_models_res[size_models_res$term != "(Intercept)", ]
size_models_res_slope$p_adj <- p.adjust(size_models_res_slope$p.value, method = "hochberg")
size_models_res_slope_signif <- size_models_res_slope[size_models_res_slope$p_adj <0.05, ]
signif_slope <- myt2 %>% filter(pop %in% size_models_res_slope_signif$pop) %>% select(size)
# length(signif_slope$size)
not_signif_slope <- myt2 %>% filter(!pop %in% size_models_res_slope_signif$pop) %>%  select(size)
# length(not_signif_slope$size)
# t.test(signif_slope$size, not_signif_slope$size)
candidat_data_1 <- myt2
candidat_data_1$Subset <- candidat_data_1$Subset
candidat_data_2 <- candidat_data_1
candidat_data_2$Subset <- ifelse(candidat_data_2$Subset == "W"| candidat_data_2$Subset == "BL", "WBL", "BH")
candidat_data_3 <- candidat_data_1
candidat_data_3$Subset <- ifelse(candidat_data_3$Subset == "W"| candidat_data_3$Subset == "BH", "WBH", "BL")
candidat_data_4 <- candidat_data_1
candidat_data_4$Subset <- ifelse(candidat_data_4$Subset == "BL"| candidat_data_4$Subset == "BH", "BLBH", "W")
Model_4_final_cand_1 <- Model_4_final
Model_4_final_cand_2 <- update(Model_4_final, data = candidat_data_2)
Model_4_final_cand_3 <- update(Model_4_final, data = candidat_data_3)
Model_4_final_cand_4 <- update(Model_4_final, data = candidat_data_4)
Model_4_final_cand_5 <- update(Model_4_final, . ~ . - Subset - morph:Subset - freq_MT:Subset)
AIC_print <- as.data.frame(AIC(Model_4_final_cand_1, Model_4_final_cand_2, Model_4_final_cand_3, Model_4_final_cand_4, Model_4_final_cand_5))
#
# ptop_T_MT_cand2 <- candidat_data_2 %>% group_by(Subset, pop) %>% summarize(Prop_T = mean(Prop_T), MT = sum(Sp2), N = n())
#
# ptop_T_MT_cand3 <- candidat_data_3 %>% group_by(Subset, pop) %>% summarize(Prop_T = mean(Prop_T), MT = sum(Sp2), N = n())
#
# ptop_T_MT_cand4 <- candidat_data_4 %>% group_by(Subset, pop) %>% summarize(Prop_T = mean(Prop_T), MT = sum(Sp2), N = n())
#
#
#
# Model_5_final_cand_1 <- Model_5_final
#
# Model_5_final_cand_2 <- update(Model_5_final, data = ptop_T_MT_cand2)
#
# Model_5_final_cand_3 <- update(Model_5_final, data = ptop_T_MT_cand3)
#
# Model_5_final_cand_4 <- update(Model_5_final, data = ptop_T_MT_cand4)
#
# Model_5_final_cand_5 <- update(Model_5_final, . ~ . - Subset - morph:Subset - freq_MT:Subset)
#
# AIC_print2 <- as.data.frame(AIC(Model_5_final_cand_1, Model_5_final_cand_2, Model_5_final_cand_3, Model_5_final_cand_4, Model_5_final_cand_5))
# kable(AIC_print)
new_data_mix <- expand.grid(morph = unique(myt2_reduced$morph), Subset = unique(myt2_reduced$Subset), freq_MT = 0.5 )
# Предсказанные значеня в шкале вероятностей
new_data_mix$fit <- predict(Model_6_final, newdata = new_data_mix, type = "response", re.form = NA)
# Предсказанные значеня в шкале логитов
new_data_mix$fit_eta <- predict(Model_6_final, newdata = new_data_mix, re.form = NA)
# Вычисление доверительного инеравала
# formula(Model_6_final)
X <- model.matrix(  ~ morph * freq_MT * Subset, data = new_data_mix) #Модельная матрица для визуализации
# Ошибки в шкале логитов
new_data_mix$se_eta <- sqrt(diag(X %*% vcov(Model_6_final) %*% t(X)))
new_data_mix$lwr <- logit_back(new_data_mix$fit_eta - 1.96 * new_data_mix$se_eta)
new_data_mix$upr <- logit_back(new_data_mix$fit_eta + 1.96 * new_data_mix$se_eta)
predict_Ptros_05 <- new_data_mix %>% select(-c(freq_MT, fit_eta, se_eta))
dd <- melt(predict_Ptros_05)
predict_Ptros_05_print <- dcast(dd, Subset ~ morph + variable, value.var = "value" )
predict_Ptros_05_print[,-1] <- round(predict_Ptros_05_print[,-1], 2)
predict_Ptros_05_print <- rbind(rep(NA, 7), predict_Ptros_05_print)
predict_Ptros_05_print[1,] <- c(NA, "Predicted", "Low", "Up", "Predicted", "Low", "Up")
kable(predict_Ptros_05_print, col.names = c("Subset", "P(edu|E)", "", "", "P(tris|T)", "", "" ), align = "rcccccc", caption = "Table ++. Predicted values of probability of correct species identification by mussel morphotype in mixed populations (Ptros = 0.5) in different geographical regions")
# Model 6#########################
myt2_all$Subset <- factor(myt2_all$Subset, levels = c("WBL", "BH", "GOM", "BALT", "SCOT", "NORW"))
new_data6 <- myt2_reduced %>% group_by(Subset, morph) %>% do(data.frame(freq_MT = seq(min(.$freq_MT), max(.$freq_MT), length.out = 100)))
# Предсказанные значеня в шкале вероятностей
new_data6$fit <- predict(Model_6_final, newdata = new_data6, type = "response", re.form = NA)
# Предсказанные значеня в шкале логитов
new_data6$fit_eta <- predict(Model_6_final, newdata = new_data6, re.form = NA)
# Вычисление доверительного инеравала
# formula(Model_6_final)
X <- model.matrix(  ~ morph * freq_MT * Subset, data = new_data6) #Модельная матрица для визуализации
# Ошибки в шкале логитов
new_data6$se_eta <- sqrt(diag(X %*% vcov(Model_6_final) %*% t(X)))
new_data6$lwr <- logit_back(new_data6$fit_eta - 1.96 * new_data6$se_eta)
new_data6$upr <- logit_back(new_data6$fit_eta + 1.96 * new_data6$se_eta)
Pl_mod6 <- ggplot(new_data6, aes(x = freq_MT)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, group = morph), alpha = 0.1)  +
geom_line(aes(y = fit, color = morph), size=1, linetype = 2) +
geom_rug(data = myt2_reduced, inherit.aes = FALSE,  aes(x = freq_MT), size = 0.1) +
scale_color_manual(values = c("blue", "red")) +
scale_fill_manual(values = c("blue", "red"))  +
xlim(0,1)  +
facet_wrap( ~ Subset) +
guides(color = "none")
pr_value_M <- myt2_all %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT), N_T = sum(ind == 1),  N_T_MT = sum(Sp2 == 1 & ind == 1), N_E_MT = sum(Sp2 == 1 & ind == 0), N_E = sum(ind == 0), N_E_ME = sum(Sp2 == 0 & ind == 0), N_T_ME = sum(Sp2 == 0 & ind == 1))
pr_value_M$PMT_T <- with(pr_value_M, N_T_MT / N_T)
pr_value_M$PMT_E <- with(pr_value_M, N_E_MT / N_T)
pr_value_M$PME_E <- with(pr_value_M, N_E_ME / N_E)
pr_value_M$PME_T <- with(pr_value_M, N_T_ME / N_E)
Pl_mod6_with_initial_data <- Pl_mod6 + geom_segment(data = pr_value_M, aes(x = freq_MT, y = PME_E, xend = freq_MT, yend = PMT_T), color="darkgrey") +
geom_hline(data = pr_value_M, aes(yintercept=0.5), color="black") +
geom_point(data = pr_value_M, aes(y = PME_E), fill = "white", shape = 21) +
geom_point(data = pr_value_M, aes(y = PMT_T), fill = "black", shape = 21) +
labs(y =  "Probability of correct species \n identification by morphotypes", x = "Proportion of M. trossulus", fill = "")+
ylim(0,1) +
xlim(0,1) +
theme_bw()
# Model 7#########################
new_data7 <- myt2_reduced %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(Prop_T) ) %>% group_by(Subset) %>%  do(data.frame(Prop_T = seq(min(.$Prop_T), max(.$Prop_T), length.out = 10)))
predicted7 <- predict(Model_7_final, newdata = new_data7,  type="response", se.fit = T)
new_data7$fit <- predicted7$fit
new_data7$SE <- predicted7$se.fit
Pl_mod7 <- ggplot(new_data7, aes(x = Prop_T, y = fit)) +
geom_line(linetype = 2, color = "red", size = 1) +
facet_wrap(~Subset) +
geom_ribbon(aes(ymin = fit - 1.96*SE, ymax = fit + 1.96*SE), alpha = 0.1) +
xlim(0, 1) +
ylim(0, 1) +
geom_rug(data = myt2_all, inherit.aes = FALSE,  aes(x = Prop_T), size = 0.1) +
geom_abline()
# unique(new_data7$Subset)
init_data_Model_7 <- myt2_all %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(morph == "T_m"),  freq_MT = mean(Sp == "M.trossulus"), N = n())
# init_data_Model_7 <- init_data_Model_7[init_data_Model_7$pop %in% c("Limh88", "CBCP"),  ]
Pl_mod7_with_initial_data <- Pl_mod7 + geom_point(data = init_data_Model_7, aes( y = freq_MT), shape = 21, size = 2 ) + scale_fill_continuous(low = "white", high = "black") + labs(x = "Proportion of mussels with T-morphotype", y = "Proportion of M.trossulus \n") + theme_bw()
## Calculator plot for all geographical areas
pops_max_dif_WBL <- max_dif(df = myt2_all, Subset = "WBL")
pops_max_dif_BH <- max_dif(df = myt2_all, Subset = "BH")
pops_max_dif_GOM <- max_dif(df = myt2_all, Subset = "GOM")
pops_max_dif_BALT <- max_dif(df = myt2_all, Subset = "BALT")
pops_max_dif_SCOT <- max_dif(df = myt2_all, Subset = "SCOT")
pops_max_dif_NORW <- max_dif(df = myt2_all, Subset = "NORW")
pops_max_mix_WBL <- max_mix(df = myt2_all, Subset = "WBL")
pops_max_mix_BH <- max_mix(df = myt2_all, Subset = "BH")
pops_max_mix_GOM <- max_mix(df = myt2_all, Subset = "GOM")
pops_max_mix_BALT <- max_mix(df = myt2_all, Subset = "BALT")
pops_max_mix_SCOT <- max_mix(df = myt2_all, Subset = "SCOT")
pops_max_mix_NORW <- max_mix(df = myt2_all, Subset = "NORW")
# Бублики для наиболее смешанных популяций
donat_max_mix_WBL <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_WBL, ])
donat_max_mix_BH <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_BH, ])
donat_max_mix_GOM <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_GOM, ])
donat_max_mix_BALT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_BALT, ])
# donat_max_mix_SCOT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_SCOT, ])
# donat_max_mix_NORW <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_NORW, ])
donat_max_mix_SCOT <- donat(myt2_all[myt2_all$Subset == "SCOT", ]) #При малом количесвте выборок бублик считаем по всем сборам
donat_max_mix_NORW <- donat(df = myt2_all[myt2_all$Subset == "NORW", ]) #При малом количесвте выборок бублик считаем по всем сборам
# Бублики для наиболее различных по стуртуре популяций
donat_max_dif_WBL <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_WBL, ])
donat_max_dif_BH <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_BH, ])
donat_max_dif_GOM <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_GOM, ])
donat_max_dif_BALT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_BALT, ])
# donat_max_dif_SCOT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_SCOT, ])
# donat_max_dif_NORW <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_NORW, ])
donat_max_dif_SCOT <- donat(df = myt2_all[myt2_all$Subset == "SCOT", ]) #При малом количесвте выборок бублик считаем по всем сборам
donat_max_dif_NORW <- donat(df = myt2_all[myt2_all$Subset == "NORW", ]) #При малом количесвте выборок бублик считаем по всем сборам
#Предсказания калькулятора 2 на основе наиболее смешанных популяций
calc2_WBL <- calc2(donat_max_mix_WBL[1], donat_max_mix_WBL[2])
calc2_BH <- calc2(donat_max_mix_BH[1], donat_max_mix_BH[2])
calc2_GOM <- calc2(donat_max_mix_GOM[1], donat_max_mix_GOM[2])
calc2_BALT <- calc2(donat_max_mix_BALT[1], donat_max_mix_BALT[2])
calc2_SCOT <- calc2(donat_max_mix_SCOT[1], donat_max_mix_SCOT[2])
calc2_NORW <- calc2(donat_max_mix_NORW[1], donat_max_mix_NORW[2])
calc2_WBL$Subset <- "WBL"
calc2_BH$Subset <- "BH"
calc2_GOM$Subset <- "GOM"
calc2_BALT$Subset <- "BALT"
calc2_SCOT$Subset <- "SCOT"
calc2_NORW$Subset <- "NORW"
calc2_predictions <- rbind(calc2_WBL, calc2_BH, calc2_GOM, calc2_BALT, calc2_SCOT, calc2_NORW)
calc2_predictions$Subset <- factor(calc2_predictions$Subset, levels = levels(myt2_all$Subset))
Pl_mod6_with_initial_data_teor_calc2 <- Pl_mod6_with_initial_data +
geom_line(data = calc2_predictions, aes(x = freq_MT, y = P_MT_T), color = "red") +
geom_line(data = calc2_predictions, aes(x = freq_MT, y = P_ME_E), color = "blue")
#Предсказания калькулятора 1 на основе наиболее различных популяций
calc1_WBL <- calc1(donat_max_dif_WBL[1], donat_max_dif_WBL[2])
calc1_BH <- calc1(donat_max_dif_BH[1], donat_max_dif_BH[2])
calc1_GOM <- calc1(donat_max_dif_GOM[1], donat_max_dif_GOM[2])
calc1_BALT <- calc1(donat_max_dif_BALT[1], donat_max_dif_BALT[2])
calc1_SCOT <- calc1(donat_max_dif_SCOT[1], donat_max_dif_SCOT[2])
calc1_NORW <- calc1(donat_max_dif_NORW[1], donat_max_dif_NORW[2])
calc1_WBL$Subset <- "WBL"
calc1_BH$Subset <- "BH"
calc1_GOM$Subset <- "GOM"
calc1_BALT$Subset <- "BALT"
calc1_SCOT$Subset <- "SCOT"
calc1_NORW$Subset <- "NORW"
calc1_predictions <- rbind(calc1_WBL, calc1_BH, calc1_GOM, calc1_BALT, calc1_SCOT, calc1_NORW)
calc1_predictions$Subset <- factor(calc1_predictions$Subset, levels = levels(myt2_all$Subset))
Pl_mod7_with_initial_data_teor_calc1 <- Pl_mod7_with_initial_data  +
geom_line(data = calc1_predictions, aes(x = P_T, y = Ptros), color = "darkgray", size = 1)
Pl_mod6_with_initial_data_teor_calc2
Pl_mod7_with_initial_data_teor_calc1
mixed_data <- myt2_all[myt2_all$Subset %in% c("WBL"), ]
n_pop <- length(unique(mixed_data$pop))
n_possible_pairs <- (n_pop^2 - n_pop)/2
Pl_teor_empir_Mod_7 <- ggplot(perms2(df = mixed_data, regr_model = Model_7_final), aes(x = Delta, y = Goodness)) + geom_point(size = 0.1) + geom_smooth(se = F) + labs(y = "Goodness \n")
# Pl_teor_empir_7 <- Pl_teor_empir_7 + ggtitle("Regression Model 8 \nvs Theoretical model Eq 3")
Pl_teor_empir_Mod_6 <- ggplot(perms4(df = mixed_data, regr_model = Model_6_final), aes(x = Delta, y = Goodness)) + geom_point(size = 0.1) + geom_smooth(se = F) + labs(y = "Goodness \n")
# Pl_teor_empir_6 <- Pl_teor_empir_6 + ggtitle("Regression Model 6 \nvs Theoretical model Eq 1, Eq 2")
grid.arrange(Pl_teor_empir_Mod_7, Pl_teor_empir_Mod_6, ncol = 2)
Pl_mod1
Pl_mod1_with_initial_data_no_test
Pl_mod1_with_initial_data
unique(myt3$Subset)
# Модели для всех географических выделов ####################
# Model 6. Congr ~ Ptros*subset*Morph (GLMM, probit) for WBL, BH, GOM, BALT
# Model 7. Ptros ~ P_T*subset (GLM) for WBL, BH, GOM, BALT
#### Data reading and initial preparation #####
myt <- read.table("data_salinity3.csv", header = T, sep = ",")
# Оставляем только мидий, у которых есть оценка морфотипа
myt2_all <- myt[!is.na(myt$ind), ]
# Подразделяем данные на сабсеты
myt2_all$Subset[myt2_all$sea == "barents" & myt2_all$sal_place == "fresh"] <- "WBL"
myt2_all$Subset[myt2_all$sea == "barents" & myt2_all$sal_place == "normal"] <- "BH"
myt2_all$Subset[myt2_all$sea == "white" & myt2_all$sal_place == "normal"] <- "WBL"
myt2_all$Subset[myt2_all$sea == "white" & myt2_all$sal_place == "fresh"] <- "WBL"
myt2_all$Subset[myt2_all$sea == "Baltic"] <- "BALT"
myt2_all$Subset[myt2_all$sea == "GOM"] <- "GOM"
myt2_all$Subset[myt2_all$sea == "Norway"] <- "NORW"
myt2_all$Subset[myt2_all$sea == "Scotland"] <- "SCOT"
myt2_all$Subset <- factor(myt2_all$Subset, levels = c("WBL", "BH", "NORW", "BALT", "SCOT", "GOM" ))
# Вводим обозначения
myt2_all$Sp [myt2_all$str > 0.5] <- "M.trossulus" #Лучше обозначать так!
myt2_all$Sp [myt2_all$str <= 0.5] <- "M.edulis"
myt2_all$Sp <- factor(myt2_all$Sp)
# Вводим обозначения для морфотипов
myt2_all$morph <- ifelse(myt2_all$ind == 1, "T_m", "E_m")
myt2_all$morph <- factor(myt2_all$morph)
# Бинарное обозначение видов
myt2_all$Sp2 <- ifelse(myt2_all$Sp == "M.trossulus", 1, 0)
#Correct identification
myt2_all$congr <- ifelse((myt2_all$ind == 1 & myt2_all$Sp == "M.trossulus") | (myt2_all$ind == 0 & myt2_all$Sp == "M.edulis"), 1, 0   )
# Частота M.trossulus в популяции
freq_MT <- myt2_all %>% group_by(pop) %>% summarise(freq_MT = mean(Sp2))
myt2_all <- merge(myt2_all, freq_MT)
# Частота T-морфотипа в популяции
Prop_T <- myt2_all %>% group_by(pop) %>% summarise(Prop_T = mean(ind))
myt2_all <- merge(myt2_all, Prop_T)
# Разделяем на тестовые и моделинговые датасеты
#
# # Извлекаем из беломорского материала тестовую выборку
# #В формальную тестовую выборку  попадают точки наиболее близкие к 20%, 40%, 60% и 80% freq_MT
#
# selected_pop <- myt2_all[myt2_all$Subset == "W", ] %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT)) %>% group_by(Subset) %>% arrange(freq_MT, .by_group = TRUE) %>% mutate(dif_20 = (freq_MT - 0.2)^2, dif_40 = (freq_MT - 0.4)^2, dif_60 = (freq_MT - 0.6)^2, dif_80 = (freq_MT - 0.8)^2)  %>% group_by(Subset)  %>% summarize (n_pop =n(), q_20_pop = nth(pop, which.min(dif_20)), q_40_pop = nth(pop, which.min(dif_40)), q_60_pop = nth(pop, which.min(dif_60)), q_80_pop = nth(pop, which.min(dif_80)))
#
# selected_pop <- melt(selected_pop, id.vars = c("Subset", "n_pop"))$value
#
# testing data set
myt3_all <- myt2_all[myt2_all$dataset == "testing" | myt2_all$pop %in% c("kovda", "rya", "chupa", "umba_pil"),  ]
#modelling data set
myt2_all <- myt2_all[! myt2_all$pop %in% unique(myt3$pop), ]
# Модели для сравнения geographical datasets
myt2_reduced <- myt2_all[myt2_all$Subset %in% c("WBL", "BH", "GOM", "BALT"), ]
# unique(myt2_reduced$Subset)
myt2_reduced$Subset <- factor(myt2_reduced$Subset, levels = c("WBL",  "BH",   "GOM",  "BALT"))
# levels(myt2_reduced$Subset)
# Model 6 #####################
library(optimx)
Model_6_full_geogr <- glmer(congr ~ morph * freq_MT * Subset + (1 | pop), data = myt2_reduced, family = binomial(link = "logit"), control=glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
# overdisp_fun(Model_6_full_geogr)
# summary(Model_6_full_geogr)
#
# r.squaredGLMM(Model_6_final)
#
# drop1(Model_6_full_geogr)
# Model_6_full_geogr2 <- update(Model_6_full_geogr, . ~ . - morph:freq_MT:Subset)
# drop1(Model_6_full_geogr2)
Model_6_final <- Model_6_full_geogr
Model_6_final_summary <- tidy(Model_6_final)
Model_6_final_summary <- Model_6_final_summary[,!(names(Model_6_final_summary) %in% c("group"))]
Model_6_final_R2_m <- r.squaredGLMM(Model_6_final)[1,1]
Model_6_final_R2_c <- r.squaredGLMM(Model_6_final)[1, 2]
# Model 7 #####################
ptop_T_MT <- myt2_reduced %>% group_by(Subset, pop) %>% summarize(Prop_T = mean(Prop_T), MT = sum(Sp2), N = n())
# ptop_T_MT <- ptop_T_MT[! ptop_T_MT$pop %in% c("Limh88", "CBCP"), ]
Model_7_full <- glm(cbind(MT, (N-MT)) ~  Prop_T * Subset, data = ptop_T_MT, family = binomial(link = "logit"))
#
# Model_7_full <- glm(Sp2 ~  Prop_T * Subset, data = myt2_reduced, family = binomial(link = "logit"))
#  overdisp_fun(Model_7_full)
# drop1(Model_7_full, test = "Chi")
# Model_7_1 <- update(Model_7_full, . ~ . - Prop_T:Subset)
# drop1(Model_7_1, test = "Chi")
Model_7_final <- Model_7_full
Model_7_final_summary <- tidy(Model_7_final)
Model_7_R2 <- r.squaredGLMM(Model_7_final)[1,1]
>>>>>>> 863795b52fc0bd64abfb125a7a6deedf8c43c076
library(lme4)
library(ggplot2)
library(reshape2)
library(sjstats)
library(dplyr)
library(car)
library(doBy)
library(pROC)
library(betareg)
library(lmtest)
library(broom)
library(MuMIn)
library(gridExtra)
#### Data reading and initial preparation #####
myt <- read.table("data_salinity3.csv", header = T, sep = ",")
myt_overseas <- myt[myt$dataset == "overseas", ]
myt <- myt[myt$dataset != "overseas", ]
myt$Sp [myt$str > 0.5] <- "M.trossulus" #Лучше обозначать так!
myt$Sp [myt$str <= 0.5] <- "M.edulis"
myt$Sp <- factor(myt$Sp)
# Оставляем только мидий, у которых есть оценка морфотипа
myt2 <- myt[!is.na(myt$ind), ]
# Вводим обозначения для морфотипов
myt2$morph <- ifelse(myt2$ind == 1, "T_m", "E_m")
myt2$morph <- factor(myt2$morph)
# Бинарное обозначение видов
myt2$Sp2 <- ifelse(myt2$Sp == "M.trossulus", 1, 0)
#Correct identification
myt2$congr <- ifelse((myt2$ind == 1 & myt2$Sp == "M.trossulus") | (myt2$ind == 0 & myt2$Sp == "M.edulis"), 1, 0   )
# Частота M.trossulus в популяции
freq_MT <- myt2 %>% group_by(pop) %>% summarise(freq_MT = mean(Sp2))
myt2 <- merge(myt2, freq_MT)
# Частота T-морфотипа в популяции
Prop_T <- myt2 %>% group_by(pop) %>% summarise(Prop_T = mean(ind))
myt2 <- merge(myt2, Prop_T)
# Подразделяем данные на три сабсета
myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "fresh"] <- "BL"
myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "normal"] <- "BH"
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "normal"] <- "W"
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "fresh"] <- "W"
myt2$Subset <- factor(myt2$Subset, levels = c("W", "BL", "BH"))
#
#Оставляем только данные, на основе, которых строится модель
myt3 <- myt2[myt2$dataset == "testing", ]
myt2 <- myt2[myt2$dataset == "training", ]
# Извлекаем из беломорского материала тестовую выборку
#В формальную тестовую выборку  попадают точки наиболее близкие к 20%, 40%, 60% и 80% freq_MT
selected_pop <- myt2[myt2$Subset == "W", ] %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT)) %>% group_by(Subset) %>% arrange(freq_MT, .by_group = TRUE) %>% mutate(dif_20 = (freq_MT - 0.2)^2, dif_40 = (freq_MT - 0.4)^2, dif_60 = (freq_MT - 0.6)^2, dif_80 = (freq_MT - 0.8)^2)  %>% group_by(Subset)  %>% summarize (n_pop =n(), q_20_pop = nth(pop, which.min(dif_20)), q_40_pop = nth(pop, which.min(dif_40)), q_60_pop = nth(pop, which.min(dif_60)), q_80_pop = nth(pop, which.min(dif_80)))
selected_pop <- melt(selected_pop, id.vars = c("Subset", "n_pop"))$value
myt4 <- myt2[myt2$pop %in% selected_pop, ] #новый testing dataset for the White sea
myt3 <- rbind(myt3, myt4)
myt2 <- myt2[!(myt2$pop %in% selected_pop), ] #новый modelling dataset
<<<<<<< HEAD
myt3_print <- myt3 %>% group_by(Subset, pop) %>% summarise(N_Tm_T = sum(morph == "T_m" & Sp == "M.trossulus"), N_Em_T = sum(morph == "E_m" & Sp == "M.trossulus"), N_Tm_E = sum(morph == "T_m" & Sp == "M.edulis"), N_Em_E = sum(morph == "E_m" & Sp == "M.edulis"), Ptros = round(mean(Sp == "M.trossulus"), 2 ))
myt3_print_out <- flextable(
myt3_print,
col_keys = c("Subset",	"Population",	"N_Tm_T",	"N_Em_T",	"N_Tm_E",	"N_Em_E",	"Ptros"))
# kable(myt3_print)
# myt3_print_out
myt2_print <- myt2 %>% group_by(Subset, pop) %>% summarise(N_Tm_T = sum(morph == "T_m" & Sp == "M.trossulus"), N_Em_T = sum(morph == "E_m" & Sp == "M.trossulus"), N_Tm_E = sum(morph == "T_m" & Sp == "M.edulis"), N_Em_E = sum(morph == "E_m" & Sp == "M.edulis"), Ptros = round(mean(Sp == "M.trossulus"), 2 ))
# kable(myt2_print)
# Функция для вычисления P_T_MT и P_T_ME в заданном датасете (БУБЛИК) ####
donat <- function(df){
P_MT <- sum(df$Sp == "M.trossulus")
P_T_MT <- sum(df$Sp == "M.trossulus" & df$morph == "T_m")/P_MT
P_ME <- sum(df$Sp == "M.edulis")
P_T_ME <- sum(df$Sp == "M.edulis" & df$morph == "T_m")/P_ME
c(P_T_MT, P_T_ME)
}
########################################3
#Функция для "ленивого" калькулятора №1 который строит зависимость Ptros от P_T
# На входе параметры бублика
calc1 <- function(P_T_MT, P_T_ME){
result <- data.frame(P_T = seq(0, 1, 0.01))
result$Ptros <- (result$P_T - P_T_ME)/(P_T_MT - P_T_ME)
result <- result[result$P_T <= P_T_MT & result$P_T >= P_T_ME, ]
result
}
# Функция для вычисления баесовских вероятностей по данным из бублика
calc2 <- function(P_T_MT, P_T_ME){
result <- data.frame(freq_MT = seq(0, 1, 0.01))
result$P_MT_T <- (P_T_MT * result$freq_MT)/(P_T_MT * result$freq_MT + P_T_ME*(1-result$freq_MT))
result$P_ME_E <- ((1 - P_T_ME) * (1 - result$freq_MT))/(1 - P_T_ME + result$freq_MT * (P_T_ME - P_T_MT))
result
}
########################################3
# Фунция для определения похожести между эмпирическим и теоретическими моделями для МОДЕЛИ 5 (Ptros vs P_T)
perms2 <- function(df = myt2[myt2$Subset == "W", ], regr_model = Model_5_final,...) {
require(dplyr)
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
W <- donat(df_selected)
calc1_predict_W <- calc1(W[1], W[2])
names(calc1_predict_W) <- c("Prop_T", "Ptros_predicted" )
Model_prediction <- expand.grid(Subset = unique(df_selected$Subset), Prop_T = seq(0, 1, 0.01))
Model_prediction$Predict <- predict(regr_model, newdata = Model_prediction, type = "response")
all_prediction <- merge(calc1_predict_W, Model_prediction, by = c("Prop_T"))
perm_pairs$Goodness[i] <- 1/(mean((all_prediction$Predict - all_prediction$Ptros_predicted)^2))
}
perm_pairs
}
# Фунция для определения похожести между эмпирическими и теоретическими моделями для МОДЕЛИ 4 (Congr vs Ptros; Morph)
perms4 <- function(df = myt2[myt2$Subset == "W"], regr_model =  Model_4_final, ...) {
require(dplyr)
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
# perm_pairs$Delta[i] <- abs(means$freq_MT[1] - means$freq_MT[2])
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
W <- donat(df_selected)
calc2_predict_W <- calc2(W[1], W[2])
names(calc2_predict_W) <- c("freq_MT", "T_m",  "E_m")
calc2_predict_W <- melt(calc2_predict_W, id.vars = "freq_MT" )
names(calc2_predict_W) <- c("freq_MT", "morph", "Bayes_predict")
Model_prediction <- expand.grid(Subset = unique(df_selected$Subset),  morph = levels(df_selected$morph), freq_MT = seq(0, 1, 0.01))
Model_prediction$Predict <- predict(regr_model, newdata = Model_prediction, type = "response",  re.form = NA )
all_prediction <- merge(calc2_predict_W, Model_prediction, by = c("freq_MT", "morph"))
perm_pairs$Goodness[i] <- 1/mean((all_prediction$Bayes_predict - all_prediction$Predict)^2, na.rm = T)
perm_pairs$pop[i] <- unique(as.character(df_selected$pop))
}
perm_pairs
}
## Функция для поиска ниболее различающихся выборок
max_dif <- function(df = myt2, Subset = "W", ...) {
require(dplyr)
df = df[df$Subset %in% Subset, ]
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
}
max_dif <- perm_pairs[which.max(perm_pairs$Delta), ]
c(max_dif$First, max_dif$Second)
}
max_mix <- function(df = myt2, Subset = "W", ...) {
require(dplyr)
df = df[df$Subset %in% Subset, ]
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
}
max_mix <- perm_pairs[which.min(abs(perm_pairs$Delta - 0.25)), ]
c(max_mix$First, max_mix$Second)
}
### Функция для описания структуры калибровочных выборок
calib_str <- function(df = myt2, pop1, pop2){
df =df[df$pop %in% c(pop1, pop2), ]
df$Subset <- factor(df$Subset)
str_calib <- df %>% group_by(pop, Subset) %>% summarize(N_E = sum(Sp == "M.edulis"), N_T = sum(Sp ==  "M.trossulus"), P_T_ME = mean(Sp == "M.edulis" & morph == "T_m"), P_T_MT = mean(Sp == "M.trossulus" & morph == "T_m"), Ptros = mean(freq_MT) )
str_calib
}
########################################
# Функция для обратной трансформации логитов
logit_back <- function(x) exp(x)/(1 + exp(x)) # обратная логит-трансформация
# Функция для оценки сверхдисперсии в моделях GLM
overdisp_fun <- function(model) {
rdf <- df.residual(model)  # Число степеней свободы N - p
if (inherits(model, 'negbin')) rdf <- rdf - 1 ## учитываем k в NegBin GLMM
rp <- residuals(model,type='pearson') # Пирсоновские остатки
Pearson.chisq <- sum(rp^2) # Сумма квадратов остатков, подчиняется Хи-квадрат распределению
prat <- Pearson.chisq/rdf  # Отношение суммы квадратов остатков к числу степеней свободы
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE) # Уровень значимости
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)        # Вывод результатов
}
##### Theme for ggplot ######
theme_set(theme_bw() + theme(axis.title.x = element_text(size = 10), axis.title.y = element_text(size = 10), axis.text= element_text(size = 10), legend.position = "none" , title = element_text(size = 10)))
myt_pure <- myt2 %>% filter(str >= 0.9 | str<=0.1)
myt_pure <- myt2 %>% filter(str >= 0.9 | str<=0.1)
myt_pure
mixed_data
myt_pure <- mixed_data %>% filter(str >= 0.9 | str<=0.1) %>%
myt_pure <- mixed_data %>% filter(str >= 0.9 | str<=0.1)
myt_pure <- mixed_data %>% filter(str >= 0.9 | str<=0.1)
myt_pure
str(myt_pure)
unique(myt_pure$Subset)
myt_pure <- myt2 %>% filter(str >= 0.9 | str<=0.1)
unique(myt_pure$Subset)
myt_pure$Subset2 <- ifelse(myt_pure$Subset == "BH", "BH", "WBL")
myt_pure$Subset2
Mod_pure <- glmer(ind ~ str * freq_MT + (1 | pop), data = myt_pure, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Mod_pure <- glmer(ind ~ str * freq_MT*Subset2 + (1 | pop), data = myt_pure, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
drop1(Mod_pure)
Mod_pure <- glmer(ind ~ Sp*freq_MT*Subset2 + (1 | pop), data = myt_pure, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
drop1(Mod_pure)
new_data_pure <- myt_pure %>% group_by(Sp, Subset2) %>% do(data.frame(freq_MT = seq(min(.$freq_MT), max(.$freq_MT), length.out = 100)))
# Предсказанные значеня в шкале вероятностей
new_data_pure$fit <- predict(Mod_pure, newdata = new_data_pure, type = "response", re.form = NA)
# Предсказанные значеня в шкале логитов
new_data_pure$fit_eta <- predict(Mod_pure, newdata = new_data_pure, re.form = NA)
X <- model.matrix(  ~ Sp * freq_MT*Subset2, data = new_data_pure) #Модельная матрица для визуализации
# Ошибки в шкале логитов
new_data_pure$se_eta <- sqrt(diag(X %*% vcov(Mod_pure) %*% t(X)))
new_data_pure
new_data_pure$lwr <- logit_back(new_data_pure$fit_eta - 1.96 * new_data_pure$se_eta)
new_data_pure$upr <- logit_back(new_data_pure$fit_eta + 1.96 * new_data_pure$se_eta)
Pl_mod_pure <- ggplot(new_data_pure, aes(x = freq_MT)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, group = morph), alpha = 0.1)  +
geom_line(aes(y = fit, color = morph), size=1, linetype = 2)
Pl_mod_pure
Pl_mod_pure <- ggplot(new_data_pure, aes(x = freq_MT)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, group = morph), alpha = 0.1)  +
geom_line(aes(y = fit, color = Sp), size=1, linetype = 2)
Pl_mod_pure
Pl_mod_pure <- ggplot(new_data_pure, aes(x = freq_MT)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, group = Sp), alpha = 0.1)  +
geom_line(aes(y = fit, color = Sp), size=1, linetype = 2)
Pl_mod_pure
Pl_mod_pure <- ggplot(new_data_pure, aes(x = freq_MT)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, group = Sp), alpha = 0.1)  +
geom_line(aes(y = fit, color = Sp), size=1, linetype = 2) +
xlim(0,1)+
facet_wrap(~Subset2)
Pl_mod_pure
=======
# Model1 ##############################
new_data <- myt2 %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT) ) %>% group_by(Subset) %>%  do(data.frame(freq_MT = seq(min(.$freq_MT), max(.$freq_MT), length.out = 10)))
predicted <- predict(Model_1_final, newdata = new_data,  type="response", se.fit = T)
new_data$fit <- predicted$fit
new_data$SE <- predicted$se.fit
Pl_mod1 <- ggplot(new_data, aes(x = freq_MT, y = fit)) + geom_line(linetype = 2, color = "red", size = 1) + facet_wrap(~Subset) + geom_ribbon(aes(ymin = fit - 1.96*SE, ymax = fit + 1.96*SE), alpha = 0.1) + xlim(0, 1) + ylim(0, 1) +  geom_rug(data = myt2, inherit.aes = FALSE,  aes(x = freq_MT), size = 0.1)
# иллюстрация с точками
link_over_M <- myt2 %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(Sp2), freq_Tmorph = mean(ind), N_MT = sum(Sp2 == 1),  N_ME = sum(Sp2 == 0))
Pl_mod1_with_initial_data_no_test <- Pl_mod1 +
geom_point(data = link_over_M, aes(y = freq_Tmorph, size = (N_MT+N_ME), fill = (freq_MT)), shape = 21) +
scale_fill_continuous(high = "black", low = "white" ) +
geom_abline() +
labs(x =  "Proportion of M. trossulus", y = "Proportion of T-morphotype \n") +
theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank())
test_Model_1 <- myt3 %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(Sp2), freq_Tmorph = mean(ind), N_MT = sum(Sp2 == 1),  N_ME = sum(Sp2 == 0))
Pl_mod1_with_initial_data <- Pl_mod1_with_initial_data_no_test + geom_point(data = test_Model_1, aes(x = freq_MT, y =freq_Tmorph, size = N_MT+N_ME), fill = "red", shape = 23 )
# Model_2 ##############################
new_data2 <- myt2 %>% group_by(Subset,  Sp) %>% do(data.frame(freq_MT = seq(min(.$freq_MT), max(.$freq_MT), length.out = 100)))
new_data2$eta <- predict(Model_2_final, newdata = new_data2,  re.form = NA)
X <- model.matrix(~freq_MT * Subset * Sp , data = new_data2)
new_data2$SE_eta <- sqrt(diag(X %*% vcov(Model_2_final) %*% t(X)))
new_data2$fit <- logit_back(new_data2$eta)
new_data2$lwr <- logit_back(new_data2$eta -  1.96 *new_data2$SE_eta)
new_data2$upr <- logit_back(new_data2$eta +  1.96 *new_data2$SE_eta)
Pl_mod2 <-  ggplot(new_data2, aes(x = freq_MT, y = fit, group = Sp)) + geom_line(linetype = 2,  size = 1, aes(color = Sp)) + geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.1) + facet_wrap(~Subset)  + xlim(0, 1) + ylim(0, 1) + scale_color_manual(values=c("blue", "red")) + guides(color = "none") +  geom_rug(data = myt2, inherit.aes = FALSE,  aes(x = freq_MT), size = 0.1)
pops_over_M <- myt2 %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT), N_MT = sum(Sp2 == 1),  N_T_MT = sum(Sp2 == 1 & ind == 1), N_E_MT = sum(Sp2 == 1 & ind == 0), N_ME = sum(Sp2 == 0), N_E_ME = sum(Sp2 == 0 & ind == 0), N_T_ME = sum(Sp2 == 0 & ind == 1))
pops_over_M$P_T_MT <- with(pops_over_M, N_T_MT / N_MT)
pops_over_M$P_E_MT <- with(pops_over_M, N_E_MT / N_MT)
pops_over_M$P_E_ME <- with(pops_over_M, N_E_ME / N_ME)
pops_over_M$P_T_ME <- with(pops_over_M, N_T_ME / N_ME)
Pl_mod2_with_initial_data_no_test <- Pl_mod2 +   geom_segment(data = pops_over_M, aes(x = freq_MT, y = (1-P_E_ME), xend = freq_MT, yend = P_T_MT, group = 1), color = "darkgray")+
geom_hline(aes(yintercept=0.5), color="black") +
geom_point(data = pops_over_M, aes(y = (1-P_E_ME), size= N_ME, group =1), fill = "white", shape = 21)+
geom_point(data = pops_over_M, aes(y = P_T_MT, size=N_MT, group =1), fill = "black", shape = 21)  + xlim(0,1)+
labs(y =  "Proportion of T-morphotype \n among  M. trossulus  and  M. edulis", x = "Proportion of M. trossulus", fill = "") +
ylim(0,1) + xlim(0,1) +
theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank())
test_Model_2 <- myt3%>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT), N_MT = sum(Sp2 == 1),  N_T_MT = sum(Sp2 == 1 & ind == 1), N_E_MT = sum(Sp2 == 1 & ind == 0), N_ME = sum(Sp2 == 0), N_E_ME = sum(Sp2 == 0 & ind == 0), N_T_ME = sum(Sp2 == 0 & ind == 1))
test_Model_2$P_T_MT <- with(test_Model_2, N_T_MT / N_MT)
test_Model_2$P_E_MT <- with(test_Model_2, N_E_MT / N_MT)
test_Model_2$P_E_ME <- with(test_Model_2, N_E_ME / N_ME)
test_Model_2$P_T_ME <- with(test_Model_2, N_T_ME / N_ME)
Pl_mod2_with_initial_data <- Pl_mod2_with_initial_data_no_test +  geom_point(data = test_Model_2, aes(y = (1-P_E_ME), size= N_ME, group =1), fill = "red", shape = 24)+
geom_point(data = test_Model_2, aes(y = P_T_MT, size=N_MT, group =1), fill = "blue", shape = 24)  + xlim(0,1)
# Model_3 ##############################
new_data3 <- myt2 %>% group_by(Subset,  Sp) %>% do(data.frame(freq_MT = seq(min(.$freq_MT), max(.$freq_MT), length.out = 100)))
new_data3$eta <- predict(Model_3_final, newdata = new_data2,  re.form = NA)
X <- model.matrix(~freq_MT* Subset , data = new_data3)
new_data3$SE_eta <- sqrt(diag(X %*% vcov(Model_3_final) %*% t(X)))
new_data3$fit <- logit_back(new_data3$eta)
new_data3$lwr <- logit_back(new_data3$eta -  1.96 *new_data3$SE_eta)
new_data3$upr <- logit_back(new_data3$eta +  1.96 *new_data3$SE_eta)
Pl_mod3 <-  ggplot(new_data3, aes(x = freq_MT, y = fit)) + geom_line(linetype = 2,  size = 1) + geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.1) + facet_wrap(~Subset)  + xlim(0, 1) + ylim(0, 1) + scale_color_manual(values=c("blue", "red")) + guides(color = "none") +  geom_rug(data = myt2, inherit.aes = FALSE,  aes(x = freq_MT), size = 0.1)
accuracy <- myt2 %>% group_by(Subset, pop) %>% summarize(freq_MT = mean(freq_MT), Accur = mean(congr), N = n())
Pl_mod3_with_initial_data_no_test <- Pl_mod3 + geom_point(data = accuracy, aes(x = freq_MT, y = Accur, fill = freq_MT, size = N),  shape = 21) + scale_fill_continuous(high = "black", low = "white" ) + labs(x = "Proportion of M.trossulus", y = "Proportion of correct \nidentification")  + theme(axis.title.x = element_blank(), axis.text.x = element_blank(), axis.ticks.x = element_blank()) + geom_hline(yintercept = 0.5)
test_Model_3 <- myt3 %>% group_by(Subset, pop) %>% summarize(freq_MT = mean(freq_MT), Accur = mean(congr), N = n())
Pl_mod3_with_initial_data <- Pl_mod3_with_initial_data_no_test + geom_point(data = test_Model_3, aes(x = freq_MT, y = Accur, size = N),  shape = 24, fill = "red")
# Model_4 ##############################
new_data4 <- myt2 %>% group_by(Subset, morph) %>% do(data.frame(freq_MT = seq(min(.$freq_MT), max(.$freq_MT), length.out = 100)))
# Предсказанные значеня в шкале вероятностей
new_data4$fit <- predict(Model_4_final, newdata = new_data4, type = "response", re.form = NA)
# Предсказанные значеня в шкале логитов
new_data4$fit_eta <- predict(Model_4_final, newdata = new_data4, re.form = NA)
# Вычисление доверительного инеравала
X <- model.matrix(  ~ morph + freq_MT + Subset + morph:freq_MT +
morph:Subset + freq_MT:Subset, data = new_data4) #Модельная матрица для визуализации
# Ошибки в шкале логитов
new_data4$se_eta <- sqrt(diag(X %*% vcov(Model_4_final) %*% t(X)))
new_data4$lwr <- logit_back(new_data4$fit_eta - 1.96 * new_data4$se_eta)
new_data4$upr <- logit_back(new_data4$fit_eta + 1.96 * new_data4$se_eta)
Pl_mod4 <- ggplot(new_data4, aes(x = freq_MT)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, group = morph), alpha = 0.1)  +
geom_line(aes(y = fit, color = morph), size=1, linetype = 2) +
geom_rug(data = myt2, inherit.aes = FALSE,  aes(x = freq_MT), size = 0.1) +
scale_color_manual(values = c("blue", "red")) +
scale_fill_manual(values = c("blue", "red"))  +
xlim(0,1)  +
facet_wrap( ~ Subset)
pr_value_M <- myt2 %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT), N_T = sum(ind == 1),  N_T_MT = sum(Sp2 == 1 & ind == 1), N_E_MT = sum(Sp2 == 1 & ind == 0), N_E = sum(ind == 0), N_E_ME = sum(Sp2 == 0 & ind == 0), N_T_ME = sum(Sp2 == 0 & ind == 1))
pr_value_M$PMT_T <- with(pr_value_M, N_T_MT / N_T)
pr_value_M$PMT_E <- with(pr_value_M, N_E_MT / N_T)
pr_value_M$PME_E <- with(pr_value_M, N_E_ME / N_E)
pr_value_M$PME_T <- with(pr_value_M, N_T_ME / N_E)
Pl_mod4_with_initial_data_no_test <- Pl_mod4 + geom_segment(data = pr_value_M, aes(x = freq_MT, y = PME_E, xend = freq_MT, yend = PMT_T), color="darkgrey") +
geom_hline(data = pr_value_M, aes(yintercept=0.5), color="black") +
geom_point(data = pr_value_M, aes(y = PME_E, size= N_E), fill = "white", shape = 21) +
geom_point(data = pr_value_M, aes(y = PMT_T, size=N_T), fill = "black", shape = 21) +
labs(y =  "Proportions of correct species \n identification by morphotypes", x = "Proportion of M. trossulus", fill = "")+
ylim(0,1) +
xlim(0,1)
# +
#   theme(strip.background = element_blank(), strip.text = element_blank())
test_Model_4 <- myt3 %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT), N_T = sum(ind == 1),  N_T_MT = sum(Sp2 == 1 & ind == 1), N_E_MT = sum(Sp2 == 1 & ind == 0), N_E = sum(ind == 0), N_E_ME = sum(Sp2 == 0 & ind == 0), N_T_ME = sum(Sp2 == 0 & ind == 1))
test_Model_4$PMT_T <- with(test_Model_4, N_T_MT / N_T)
test_Model_4$PMT_E <- with(test_Model_4, N_E_MT / N_T)
test_Model_4$PME_E <- with(test_Model_4, N_E_ME / N_E)
test_Model_4$PME_T <- with(test_Model_4, N_T_ME / N_E)
Pl_mod4_with_initial_data <- Pl_mod4_with_initial_data_no_test + geom_point(data = test_Model_4, aes(y = PME_E, size= N_E), fill = "red", shape = 24) +
geom_point(data = test_Model_4, aes(y = PMT_T, size=N_T), fill = "blue", shape = 24)
# Model_5 ##############################
new_data5 <- myt2 %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(Prop_T) ) %>% group_by(Subset) %>%  do(data.frame(Prop_T = seq(min(.$Prop_T), max(.$Prop_T), length.out = 10)))
predicted5 <- predict(Model_5_final, newdata = new_data5,  type="response", se.fit = T)
new_data5$fit <- predicted5$fit
new_data5$SE <- predicted5$se.fit
Pl_mod5 <- ggplot(new_data5, aes(x = Prop_T, y = fit)) + geom_line(linetype = 2, color = "red", size = 1) + facet_wrap(~Subset) + geom_ribbon(aes(ymin = fit - 1.96*SE, ymax = fit + 1.96*SE), alpha = 0.1) + xlim(0, 1) + ylim(0, 1) +  geom_rug(data = myt2, inherit.aes = FALSE,  aes(x = Prop_T), size = 0.1) + geom_abline()
init_data_Model_5 <- myt2 %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(morph == "T_m"),  freq_MT = mean(Sp == "M.trossulus"), N = n())
Pl_mod5_with_initial_data_no_test <- Pl_mod5 + geom_point(data = init_data_Model_5, aes( y = freq_MT, size = N, fill = freq_MT), shape = 21 ) + scale_fill_continuous(low = "white", high = "black") + labs(x = "Proportion of mussels with T-morphotype", y = "Proportion of M.trossulus \n")
test_Model_5 <- myt3 %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(morph == "T_m"),  freq_MT = mean(Sp == "M.trossulus"), N = n())
Pl_mod5_with_initial_data <- Pl_mod5_with_initial_data_no_test + geom_point(data = test_Model_5, aes( y = freq_MT, size = N, fill = freq_MT), shape = 24, fill = "red" )
grid.arrange(Pl_mod1_with_initial_data ,
Pl_mod2_with_initial_data_no_test + theme(strip.text = element_blank()),
Pl_mod4_with_initial_data_no_test + theme(strip.text = element_blank()) ,
ncol = 1)
# grid.arrange(Pl_mod1_with_initial_data ,
#              Pl_mod2_with_initial_data + theme(strip.text = element_blank()),
#              Pl_mod3_with_initial_data + theme(strip.text = element_blank()),
#              Pl_mod4_with_initial_data+ theme(strip.text = element_blank()) ,
#              ncol = 1)
grid.arrange(Pl_mod1_with_initial_data ,
Pl_mod2_with_initial_data_no_test + theme(strip.text = element_blank()),
Pl_mod4_with_initial_data_no_test + theme(strip.text = element_blank()) ,
ncol = 1)
grid.arrange(Pl_mod1_with_initial_data ,
Pl_mod2_with_initial_data + theme(strip.text = element_blank()),
Pl_mod3_with_initial_data + theme(strip.text = element_blank()),
Pl_mod4_with_initial_data+ theme(strip.text = element_blank()) ,
ncol = 1)
paste(round(mean(not_signif_slope$size, na.rm = T), 1),"±", round(sd(not_signif_slope$size, na.rm = T), 2) )
paste(round(mean(not_signif_slope$size, na.rm = T), 1),"±", round(sd(not_signif_slope$size, na.rm = T), 2) )
>>>>>>> 863795b52fc0bd64abfb125a7a6deedf8c43c076
