# plot_grid(Pl_mod1_with_initial_data, Pl_mod2_with_initial_data, Pl_mod4_with_initial_data, ncol = 1)
grid.arrange(Pl_mod1_with_initial_data, Pl_mod2_with_initial_data, Pl_mod4_with_initial_data, ncol = 1)
Pl_teor_empir_5 <- ggplot(perms2(df = myt2), aes(x = Delta, y = Goodness)) + geom_point(size = 0.1) + geom_smooth(se = F)
Pl_teor_empir_4 <- ggplot(perms4(df = myt2), aes(x = Delta, y = Goodness)) + geom_point(size = 0.1) + geom_smooth(se = F)
grid.arrange(Pl_teor_empir_5, Pl_teor_empir_4, nrow =1)
# Визуализация модели 5 и ленивого калькулятора 1, основанного на выборках максимально далеких по генетической структуре.
donat_max_dif <- donat(df = myt2[myt2$pop %in% max_dif(Subset = "W"), ])
calc1_W <- calc1(donat_max_dif[1], donat_max_dif[2])
calc1_W$Subset <- "W"
donat_max_dif <- donat(df = myt2[myt2$pop %in% max_dif(Subset = "BL"), ])
calc1_BL <- calc1(donat_max_dif[1], donat_max_dif[2])
calc1_BL$Subset <- "BL"
donat_max_dif <- donat(df = myt2[myt2$pop %in% max_dif(Subset = "BH"), ])
calc1_BH <- calc1(donat_max_dif[1], donat_max_dif[2])
calc1_BH$Subset <- "BH"
calc1_res <- rbind(calc1_W, calc1_BL, calc1_BH)
Pl_mod5 + geom_line(data = calc1_res, aes(x = P_T, y = Ptros), color = "blue")  + geom_point(data = myt3, aes(x = Prop_T, y = freq_MT), size = 4, color = "red")
# Визуализация модели 4 и ленивого калькулятора 2, основанного на выборках максимально смешанных.
donat_max_mix <- donat(df = myt2[myt2$pop %in% max_dif(Subset = "W"), ])
calc2_W <- calc2(donat_max_dif[1], donat_max_dif[2])
calc2_W$Subset <- "W"
donat_max_mix <- donat(df = myt2[myt2$pop %in% max_dif(Subset = "BL"), ])
calc2_BL <- calc2(donat_max_dif[1], donat_max_dif[2])
calc2_BL$Subset <- "BL"
donat_max_mix <- donat(df = myt2[myt2$pop %in% max_dif(Subset = "BH"), ])
calc2_BH <- calc2(donat_max_dif[1], donat_max_dif[2])
calc2_BH$Subset <- "BH"
calc2_res <- rbind(calc2_W, calc2_BL, calc2_BH)
Pl_mod4 + geom_line(data = calc2_res, aes(x = freq_MT, y = P_MT_T), color = "red") + geom_line(data = calc2_res, aes(x = freq_MT, y = P_ME_E), color = "blue")
Subset = "W"
require(dplyr)
df = myt2[myt2$Subset == Subset, ]
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
}
perm_pairs
perm_pairs[order(perm_pairs$Delta),]
perms2 <- function(df = myt2[myt2$Subset == "W", ], ...) {
require(dplyr)
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
W <- donat(df_selected)
calc1_predict_W <- calc1(W[1], W[2])
names(calc1_predict_W) <- c("Prop_T", "Ptros_predicted" )
Model_prediction <- expand.grid(Subset = unique(df_selected$Subset), Prop_T = seq(0, 1, 0.01))
Model_prediction$Predict <- predict(Model_5_final, newdata = Model_prediction, type = "response")
all_prediction <- merge(calc1_predict_W, Model_prediction, by = c("Prop_T"))
perm_pairs$Goodness[i] <- 1/(mean((all_prediction$Predict - all_prediction$Ptros_predicted)^2))
}
perm_pairs
}
# Фунция для определения похожести между эмпирическими и теоретическими моделями для МОДЕЛИ 4 (Congr vs Ptros; Morph)
perms4 <- function(df = myt2[myt2$Subset == "W", ], ...) {
require(dplyr)
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
# perm_pairs$Delta[i] <- abs(means$freq_MT[1] - means$freq_MT[2])
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
W <- donat(df_selected)
calc2_predict_W <- calc2(W[1], W[2])
names(calc2_predict_W) <- c("freq_MT", "T_m",  "E_m")
calc2_predict_W <- melt(calc2_predict_W, id.vars = "freq_MT" )
names(calc2_predict_W) <- c("freq_MT", "morph", "Bayes_predict")
Model_prediction <- expand.grid(Subset = unique(df_selected$Subset),  morph = levels(df_selected$morph), freq_MT = seq(0, 1, 0.01))
Model_prediction$Predict <- predict(Model_4_final, newdata = Model_prediction, type = "response",  re.form = NA )
all_prediction <- merge(calc2_predict_W, Model_prediction, by = c("freq_MT", "morph"))
perm_pairs$Goodness[i] <- 1/mean((all_prediction$Bayes_predict - all_prediction$Predict)^2, na.rm = T)
perm_pairs$pop[i] <- unique(as.character(df_selected$pop))
}
perm_pairs
}
## Функция для поиска ниболее различающихся выборок
max_dif <- function(Subset = "W", ...) {
require(dplyr)
df = myt2[myt2$Subset == Subset, ]
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
}
max_dif <- perm_pairs[which.max(perm_pairs$Delta), ]
c(max_dif$First, max_dif$Second)
}
max_mix <- function(Subset = "W", ...) {
require(dplyr)
df = myt2[myt2$Subset == Subset, ]
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
}
max_mix <- perm_pairs[which.min(abs(perm_pairs$Delta - 0.25)), ]
c(max_mix$First, max_mix$Second)
}
Subset = "W"
df = myt2[myt2$Subset == Subset, ]
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
}
max_mix <- perm_pairs[which.min(abs(perm_pairs$Delta - 0.25)), ]
max_mix[order(max_mix$Delta)]
perm_pairs
perm_pairs[order(perm_pairs$Delta)]
perm_pairs[order(perm_pairs$Delta), ]
max_mix <- perm_pairs[which.min(abs(perm_pairs$Delta - 0.25)), ]
max_mix
# Функция для вычисления P_T_MT и P_T_ME в заданном датасете (БУБЛИК) ####
donat <- function(df){
P_MT <- sum(df$Sp == "M.trossulus")
P_T_MT <- sum(df$Sp == "M.trossulus" & df$morph == "T_m")/P_MT
P_ME <- sum(df$Sp == "M.edulis")
P_T_ME <- sum(df$Sp == "M.edulis" & df$morph == "T_m")/P_ME
c(P_T_MT, P_T_ME)
}
########################################3
#Функция для "ленивого" калькулятора №1 который строит зависимость Ptros от P_T
# На входе параметры бублика
calc1 <- function(P_T_MT, P_T_ME){
result <- data.frame(P_T = seq(0, 1, 0.01))
result$Ptros <- (result$P_T - P_T_ME)/(P_T_MT - P_T_ME)
result <- result[result$P_T <= P_T_MT & result$P_T >= P_T_ME, ]
result
}
# Функция для вычисления баесовских вероятностей по данным из бублика
calc2 <- function(P_T_MT, P_T_ME){
result <- data.frame(freq_MT = seq(0, 1, 0.01))
result$P_MT_T <- (P_T_MT * result$freq_MT)/(P_T_MT * result$freq_MT + P_T_ME*(1-result$freq_MT))
result$P_ME_E <- ((1 - P_T_ME) * (1 - result$freq_MT))/(1 - P_T_ME + result$freq_MT * (P_T_ME - P_T_MT))
result
}
########################################3
# Фунция для определения похожести между эмпирическим и теоретическими моделями для МОДЕЛИ 5 (Ptros vs P_T)
perms2 <- function(df = myt2[myt2$Subset == "W", ], ...) {
require(dplyr)
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
W <- donat(df_selected)
calc1_predict_W <- calc1(W[1], W[2])
names(calc1_predict_W) <- c("Prop_T", "Ptros_predicted" )
Model_prediction <- expand.grid(Subset = unique(df_selected$Subset), Prop_T = seq(0, 1, 0.01))
Model_prediction$Predict <- predict(Model_5_final, newdata = Model_prediction, type = "response")
all_prediction <- merge(calc1_predict_W, Model_prediction, by = c("Prop_T"))
perm_pairs$Goodness[i] <- 1/(mean((all_prediction$Predict - all_prediction$Ptros_predicted)^2))
}
perm_pairs
}
# Фунция для определения похожести между эмпирическими и теоретическими моделями для МОДЕЛИ 4 (Congr vs Ptros; Morph)
perms4 <- function(df = myt2[myt2$Subset == "W", ], ...) {
require(dplyr)
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
# perm_pairs$Delta[i] <- abs(means$freq_MT[1] - means$freq_MT[2])
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
W <- donat(df_selected)
calc2_predict_W <- calc2(W[1], W[2])
names(calc2_predict_W) <- c("freq_MT", "T_m",  "E_m")
calc2_predict_W <- melt(calc2_predict_W, id.vars = "freq_MT" )
names(calc2_predict_W) <- c("freq_MT", "morph", "Bayes_predict")
Model_prediction <- expand.grid(Subset = unique(df_selected$Subset),  morph = levels(df_selected$morph), freq_MT = seq(0, 1, 0.01))
Model_prediction$Predict <- predict(Model_4_final, newdata = Model_prediction, type = "response",  re.form = NA )
all_prediction <- merge(calc2_predict_W, Model_prediction, by = c("freq_MT", "morph"))
perm_pairs$Goodness[i] <- 1/mean((all_prediction$Bayes_predict - all_prediction$Predict)^2, na.rm = T)
perm_pairs$pop[i] <- unique(as.character(df_selected$pop))
}
perm_pairs
}
## Функция для поиска ниболее различающихся выборок
max_dif <- function(Subset = "W", ...) {
require(dplyr)
df = myt2[myt2$Subset == Subset, ]
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
}
max_dif <- perm_pairs[which.max(perm_pairs$Delta), ]
c(max_dif$First, max_dif$Second)
}
max_mix <- function(Subset = "W", ...) {
require(dplyr)
df = myt2[myt2$Subset == Subset, ]
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
}
max_mix <- perm_pairs[which.min(abs(perm_pairs$Delta - 0.3)), ]
c(max_mix$First, max_mix$Second)
}
########################################
# Функция для обратной трансформации логитов
logit_back <- function(x) exp(x)/(1 + exp(x)) # обратная логит-трансформация
# Функция для оценки сверхдисперсии в моделях GLM
overdisp_fun <- function(model) {
rdf <- df.residual(model)  # Число степеней свободы N - p
if (inherits(model, 'negbin')) rdf <- rdf - 1 ## учитываем k в NegBin GLMM
rp <- residuals(model,type='pearson') # Пирсоновские остатки
Pearson.chisq <- sum(rp^2) # Сумма квадратов остатков, подчиняется Хи-квадрат распределению
prat <- Pearson.chisq/rdf  # Отношение суммы квадратов остатков к числу степеней свободы
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE) # Уровень значимости
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)        # Вывод результатов
}
donat_max_mix <- donat(df = myt2[myt2$pop %in% max_mix(Subset = "W"), ])
# Визуализация модели 4 и ленивого калькулятора 2, основанного на выборках максимально смешанных.
donat_max_mix <- donat(df = myt2[myt2$pop %in% max_mix(Subset = "W"), ])
calc2_W <- calc2(donat_max_dif[1], donat_max_dif[2])
calc2_W$Subset <- "W"
donat_max_mix <- donat(df = myt2[myt2$pop %in% max_mix(Subset = "BL"), ])
calc2_BL <- calc2(donat_max_dif[1], donat_max_dif[2])
calc2_BL$Subset <- "BL"
donat_max_mix <- donat(df = myt2[myt2$pop %in% max_mix(Subset = "BH"), ])
calc2_BH <- calc2(donat_max_dif[1], donat_max_dif[2])
calc2_BH$Subset <- "BH"
calc2_res <- rbind(calc2_W, calc2_BL, calc2_BH)
Pl_mod4 + geom_line(data = calc2_res, aes(x = freq_MT, y = P_MT_T), color = "red") + geom_line(data = calc2_res, aes(x = freq_MT, y = P_ME_E), color = "blue")
# Функция для вычисления P_T_MT и P_T_ME в заданном датасете (БУБЛИК) ####
donat <- function(df){
P_MT <- sum(df$Sp == "M.trossulus")
P_T_MT <- sum(df$Sp == "M.trossulus" & df$morph == "T_m")/P_MT
P_ME <- sum(df$Sp == "M.edulis")
P_T_ME <- sum(df$Sp == "M.edulis" & df$morph == "T_m")/P_ME
c(P_T_MT, P_T_ME)
}
########################################3
#Функция для "ленивого" калькулятора №1 который строит зависимость Ptros от P_T
# На входе параметры бублика
calc1 <- function(P_T_MT, P_T_ME){
result <- data.frame(P_T = seq(0, 1, 0.01))
result$Ptros <- (result$P_T - P_T_ME)/(P_T_MT - P_T_ME)
result <- result[result$P_T <= P_T_MT & result$P_T >= P_T_ME, ]
result
}
# Функция для вычисления баесовских вероятностей по данным из бублика
calc2 <- function(P_T_MT, P_T_ME){
result <- data.frame(freq_MT = seq(0, 1, 0.01))
result$P_MT_T <- (P_T_MT * result$freq_MT)/(P_T_MT * result$freq_MT + P_T_ME*(1-result$freq_MT))
result$P_ME_E <- ((1 - P_T_ME) * (1 - result$freq_MT))/(1 - P_T_ME + result$freq_MT * (P_T_ME - P_T_MT))
result
}
########################################3
# Фунция для определения похожести между эмпирическим и теоретическими моделями для МОДЕЛИ 5 (Ptros vs P_T)
perms2 <- function(df = myt2[myt2$Subset == "W", ], ...) {
require(dplyr)
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
W <- donat(df_selected)
calc1_predict_W <- calc1(W[1], W[2])
names(calc1_predict_W) <- c("Prop_T", "Ptros_predicted" )
Model_prediction <- expand.grid(Subset = unique(df_selected$Subset), Prop_T = seq(0, 1, 0.01))
Model_prediction$Predict <- predict(Model_5_final, newdata = Model_prediction, type = "response")
all_prediction <- merge(calc1_predict_W, Model_prediction, by = c("Prop_T"))
perm_pairs$Goodness[i] <- 1/(mean((all_prediction$Predict - all_prediction$Ptros_predicted)^2))
}
perm_pairs
}
# Фунция для определения похожести между эмпирическими и теоретическими моделями для МОДЕЛИ 4 (Congr vs Ptros; Morph)
perms4 <- function(df = myt2[myt2$Subset == "W", ], ...) {
require(dplyr)
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
# perm_pairs$Delta[i] <- abs(means$freq_MT[1] - means$freq_MT[2])
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
W <- donat(df_selected)
calc2_predict_W <- calc2(W[1], W[2])
names(calc2_predict_W) <- c("freq_MT", "T_m",  "E_m")
calc2_predict_W <- melt(calc2_predict_W, id.vars = "freq_MT" )
names(calc2_predict_W) <- c("freq_MT", "morph", "Bayes_predict")
Model_prediction <- expand.grid(Subset = unique(df_selected$Subset),  morph = levels(df_selected$morph), freq_MT = seq(0, 1, 0.01))
Model_prediction$Predict <- predict(Model_4_final, newdata = Model_prediction, type = "response",  re.form = NA )
all_prediction <- merge(calc2_predict_W, Model_prediction, by = c("freq_MT", "morph"))
perm_pairs$Goodness[i] <- 1/mean((all_prediction$Bayes_predict - all_prediction$Predict)^2, na.rm = T)
perm_pairs$pop[i] <- unique(as.character(df_selected$pop))
}
perm_pairs
}
## Функция для поиска ниболее различающихся выборок
max_dif <- function(Subset = "W", ...) {
require(dplyr)
df = myt2[myt2$Subset == Subset, ]
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
}
max_dif <- perm_pairs[which.max(perm_pairs$Delta), ]
c(max_dif$First, max_dif$Second)
}
max_mix <- function(Subset = "W", ...) {
require(dplyr)
df = myt2[myt2$Subset == Subset, ]
df$pop <- as.character(df$pop)
perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
perm_pairs$First <- as.character(perm_pairs$First)
perm_pairs$Second <- as.character(perm_pairs$Second)
perm_pairs$Delta <- NA
for(i in 1:nrow(perm_pairs)){
df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),]
means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
perm_pairs$Delta[i] <- max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
}
max_mix <- perm_pairs[which.min(abs(perm_pairs$Delta - 0.25)), ]
c(max_mix$First, max_mix$Second)
}
########################################
# Функция для обратной трансформации логитов
logit_back <- function(x) exp(x)/(1 + exp(x)) # обратная логит-трансформация
# Функция для оценки сверхдисперсии в моделях GLM
overdisp_fun <- function(model) {
rdf <- df.residual(model)  # Число степеней свободы N - p
if (inherits(model, 'negbin')) rdf <- rdf - 1 ## учитываем k в NegBin GLMM
rp <- residuals(model,type='pearson') # Пирсоновские остатки
Pearson.chisq <- sum(rp^2) # Сумма квадратов остатков, подчиняется Хи-квадрат распределению
prat <- Pearson.chisq/rdf  # Отношение суммы квадратов остатков к числу степеней свободы
pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE) # Уровень значимости
c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)        # Вывод результатов
}
donat_max_mix <- donat(df = myt2[myt2$pop %in% max_mix(Subset = "W"), ])
# Визуализация модели 4 и ленивого калькулятора 2, основанного на выборках максимально смешанных.
donat_max_mix <- donat(df = myt2[myt2$pop %in% max_mix(Subset = "W"), ])
calc2_W <- calc2(donat_max_mix[1], donat_max_mix[2])
calc2_W$Subset <- "W"
donat_max_mix <- donat(df = myt2[myt2$pop %in% max_mix(Subset = "BL"), ])
calc2_BL <- calc2(donat_max_mix[1], donat_max_mix[2])
calc2_BL$Subset <- "BL"
donat_max_mix <- donat(df = myt2[myt2$pop %in% max_mix(Subset = "BH"), ])
calc2_BH <- calc2(donat_max_mix[1], donat_max_mix[2])
calc2_BH$Subset <- "BH"
calc2_res <- rbind(calc2_W, calc2_BL, calc2_BH)
Pl_mod4 + geom_line(data = calc2_res, aes(x = freq_MT, y = P_MT_T), color = "red") + geom_line(data = calc2_res, aes(x = freq_MT, y = P_ME_E), color = "blue")
myt3 %>% group_by(Subset, pop) %>% summarize(Pcorrect = mean(Congr == 1))
myt3 %>% group_by(Subset, pop) %>% summarize(Pcorrect = mean(congr == 1))
myt3 %>% group_by(Subset, pop, Morph) %>% summarize(Pcorrect = mean(congr == 1))
myt3 %>% group_by(Subset, pop, morph) %>% summarize(Pcorrect = mean(congr == 1))
testing_congr <- myt3 %>% group_by(Subset, pop, morph) %>% summarize(Pcorrect = mean(congr == 1))
testing_congr <- myt3 %>% group_by(Subset, pop, morph) %>% summarize(Pcorrect = mean(congr == 1), freq_MT = mean(freq_MT))
testing_congr
Pl_mod4 + geom_line(data = calc2_res, aes(x = freq_MT, y = P_MT_T), color = "red") + geom_line(data = calc2_res, aes(x = freq_MT, y = P_ME_E), color = "blue") + geom_point(data = testing_congr, aes(x = freq_MT, y = Pcorrect) )
Pl_mod4 + geom_line(data = calc2_res, aes(x = freq_MT, y = P_MT_T), color = "red") + geom_line(data = calc2_res, aes(x = freq_MT, y = P_ME_E), color = "blue") + geom_point(data = testing_congr, aes(x = freq_MT, y = Pcorrect, color = morph), size = 4 )
Pl_calc1 <- Pl_mod5 + geom_line(data = calc1_res, aes(x = P_T, y = Ptros), color = "blue")  + geom_point(data = myt3, aes(x = Prop_T, y = freq_MT), size = 4, color = "red")
Pl_calc2 <- Pl_mod4 + geom_line(data = calc2_res, aes(x = freq_MT, y = P_MT_T), color = "red") + geom_line(data = calc2_res, aes(x = freq_MT, y = P_ME_E), color = "blue") + geom_point(data = testing_congr, aes(x = freq_MT, y = Pcorrect, color = morph), size = 4 )
grid.arrange(Pl_calc1, Pl_calc2)
myt <- read.table("data_salinity3.csv", header = T, sep = ";")
myt_overseas <- myt[myt$dataset == "overseas", ]
myt <- myt[myt$dataset != "overseas", ]
myt$Sp [myt$str > 0.5] <- "M.trossulus" #Лучше обозначать так!
myt$Sp [myt$str <= 0.5] <- "M.edulis"
myt$Sp <- factor(myt$Sp)
# Оставляем только мидий, у которых есть оценка морфотипа
myt2 <- myt[!is.na(myt$ind), ]
# Вводим обозначения для морфотипов
myt2$morph <- ifelse(myt2$ind == 1, "T_m", "E_m")
myt2$morph <- factor(myt2$morph)
# Бинарное обозначение видов
myt2$Sp2 <- ifelse(myt2$Sp == "M.trossulus", 1, 0)
#Correct identification
myt2$congr <- ifelse((myt2$ind == 1 & myt2$Sp == "M.trossulus") | (myt2$ind == 0 & myt2$Sp == "M.edulis"), 1, 0   )
# Частота M.trossulus в популяции
freq_MT <- myt2 %>% group_by(pop) %>% summarise(freq_MT = mean(Sp2))
myt2 <- merge(myt2, freq_MT)
# Частота T-морфотипа в популяции
Prop_T <- myt2 %>% group_by(pop) %>% summarise(Prop_T = mean(ind))
myt2 <- merge(myt2, Prop_T)
# Подразделяем данные на три сабсета
myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "fresh"] <- "BL"
myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "normal"] <- "BH"
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "normal"] <- "W"
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "fresh"] <- "W"
myt2$Subset <- factor(myt2$Subset, levels = c("W", "BL", "BH"))
#
# #Оставляем только данные, на основе, которых строится модель
# myt3 <- myt2[myt2$dataset == "testing", ]
# myt2 <- myt2[myt2$dataset == "training", ]
# Новое деление на testing and modelling dataset.########
# В формальную тестовую выборку попадают точки наиболее близкие к 20%, 40%, 60% и 80% квантили freq_MT
selected_pop <- myt2 %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT)) %>% group_by(Subset) %>% arrange(freq_MT, .by_group = TRUE) %>% mutate(dif_20 = (freq_MT - quantile(freq_MT, probs = 0.2))^2, dif_40 = (freq_MT - quantile(freq_MT, probs = 0.4))^2, dif_60 = (freq_MT - quantile(freq_MT, probs = 0.6))^2, dif_80 = (freq_MT - quantile(freq_MT, probs = 0.8))^2)  %>% group_by(Subset)  %>% summarize (n_pop =n(), q_20_pop = nth(pop, which.min(dif_20)), q_40_pop = nth(pop, which.min(dif_40)), q_60_pop = nth(pop, which.min(dif_60)), q_80_pop = nth(pop, which.min(dif_80)))
selected_pop <- melt(selected_pop, id.vars = c("Subset", "n_pop"))$value
myt3 <- myt2[myt2$pop %in% selected_pop, ] #новый testing dataset
myt2 <- myt2[!(myt2$pop %in% selected_pop), ] #новый modelling dataset
Model_4_full <- glmer(congr ~ morph * freq_MT*Subset + (1 | pop), data = myt2, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
library(lme4)
library(ggplot2)
library(reshape2)
library(sjstats)
library(dplyr)
library(car)
library(doBy)
library(pROC)
library(betareg)
library(lmtest)
library(broom)
Model_4_full <- glmer(congr ~ morph * freq_MT*Subset + (1 | pop), data = myt2, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
myt2$Subset2 <- ifelse(myt2$Subset %in% c("W", "BL"), "WBL", "BH")
Model_4_full_mix <- glmer(congr ~ morph * freq_MT*Subset2 + (1 | pop), data = myt2, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
Model_4_full <- glmer(congr ~ morph * freq_MT*Subset + (1 | pop), data = myt2, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
AIC(Model_4_full, Model_4_full_mix)
Model_3_full <- glm(congr ~ freq_MT*Subset, data = myt2, family = binomial(link = "logit"))
Model_3_full_mix <- glm(congr ~ freq_MT*Subset2, data = myt2, family = binomial(link = "logit"))
AIC(Model_3_full, Model_3_full_mix)
Model_5_full <- glm(Sp2 ~  Prop_T * Subset, data = myt2, family = binomial(link = "logit"))
Model_5_full_mix <- glm(Sp2 ~  Prop_T * Subset2, data = myt2, family = binomial(link = "logit"))
AIC(Model_5_full, Model_5_full_mix)
AIC(Model_4_full, Model_4_full_mix)
AIC(Model_3_full, Model_3_full_mix)
AIC(Model_5_full, Model_5_full_mix)
BIC(Model_4_full, Model_4_full_mix)
BIC(Model_3_full, Model_3_full_mix)
BIC(Model_5_full, Model_5_full_mix)
