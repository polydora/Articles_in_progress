pr_value_M$PME_T <- with(pr_value_M, N_T_ME / N_E)
Pl_mod4_with_initial_data_no_test <- Pl_mod4 + geom_segment(data = pr_value_M, aes(x = freq_MT, y = PME_E, xend = freq_MT, yend = PMT_T), color="darkgrey") +
geom_hline(data = pr_value_M, aes(yintercept=0.5), color="black") +
geom_point(data = pr_value_M, aes(y = PME_E, size= N_E), fill = "white", shape = 21) +
geom_point(data = pr_value_M, aes(y = PMT_T, size=N_T), fill = "black", shape = 21) +
labs(y =  "Proportions of correct species \n identification by morphotypes", x = "Proportion of M. trossulus", fill = "")+
ylim(0,1) +
xlim(0,1)
# +
#   theme(strip.background = element_blank(), strip.text = element_blank())
# test_Model_4 <- myt3 %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT), N_T = sum(ind == 1),  N_T_MT = sum(Sp2 == 1 & ind == 1), N_E_MT = sum(Sp2 == 1 & ind == 0), N_E = sum(ind == 0), N_E_ME = sum(Sp2 == 0 & ind == 0), N_T_ME = sum(Sp2 == 0 & ind == 1))
#
# test_Model_4$PMT_T <- with(test_Model_4, N_T_MT / N_T)
# test_Model_4$PMT_E <- with(test_Model_4, N_E_MT / N_T)
# test_Model_4$PME_E <- with(test_Model_4, N_E_ME / N_E)
# test_Model_4$PME_T <- with(test_Model_4, N_T_ME / N_E)
#
# Pl_mod4_with_initial_data <- Pl_mod4_with_initial_data_no_test + geom_point(data = test_Model_4, aes(y = PME_E, size= N_E), fill = "red", shape = 24) +  geom_point(data = test_Model_4, aes(y = PMT_T, size=N_T), fill = "blue", shape = 24)
Pl_mod4_with_initial_data <- Pl_mod4_with_initial_data_no_test
# Model_5 ##############################
new_data5 <- myt2 %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(Prop_T) ) %>% group_by(Subset) %>%  do(data.frame(Prop_T = seq(min(.$Prop_T), max(.$Prop_T), length.out = 10)))
predicted5 <- predict(Model_5_final, newdata = new_data5,  type="response", se.fit = T)
new_data5$fit <- predicted5$fit
new_data5$SE <- predicted5$se.fit
Pl_mod5 <- ggplot(new_data5, aes(x = Prop_T, y = fit)) + geom_line(linetype = 2, color = "red", size = 1) + facet_wrap(~Subset) + geom_ribbon(aes(ymin = fit - 1.96*SE, ymax = fit + 1.96*SE), alpha = 0.1) + xlim(0, 1) + ylim(0, 1) +  geom_rug(data = myt2, inherit.aes = FALSE,  aes(x = Prop_T), size = 0.1) + geom_abline()
init_data_Model_5 <- myt2 %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(morph == "T_m"),  freq_MT = mean(Sp == "M.trossulus"), N = n())
Pl_mod5_with_initial_data_no_test <- Pl_mod5 + geom_point(data = init_data_Model_5, aes( y = freq_MT, size = N), shape = 21, fill = "gray" ) + scale_fill_continuous(low = "white", high = "black") + labs(x = "Proportion of mussels with T-morphotype", y = "Proportion of M.trossulus \n")
#  test_Model_5 <- myt3 %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(morph == "T_m"),  freq_MT = mean(Sp == "M.trossulus"), N = n())
#
# Pl_mod5_with_initial_data <- Pl_mod5_with_initial_data_no_test + geom_point(data = test_Model_5, aes( y = freq_MT, size = N, fill = freq_MT), shape = 24, fill = "red" )
#
Pl_mod5_with_initial_data <- Pl_mod5_with_initial_data_no_test
# Chunk 12
#### В этом чанке вычисляются  значения P(T|tros) P(E|edu), предсказанные для Ptos=0.5
new_data_ptros_05_model_2 <- expand.grid(Sp = c("M.trossulus", "M.edulis"), Subset = c("WS", "BL", "BH"), freq_MT = 0.5)
new_data_ptros_05_model_2$eta <- predict(Model_2_final, newdata = new_data_ptros_05_model_2,  re.form = NA)
X <- model.matrix(~freq_MT * Subset * Sp, data = new_data_ptros_05_model_2)
new_data_ptros_05_model_2$SE_eta <- sqrt(diag(X %*% vcov(Model_2_final) %*% t(X)))
new_data_ptros_05_model_2$fit <- logit_back(new_data_ptros_05_model_2$eta)
new_data_ptros_05_model_2$lwr <- logit_back(new_data_ptros_05_model_2$eta -  1.96 *new_data_ptros_05_model_2$SE_eta)
new_data_ptros_05_model_2$upr <- logit_back(new_data_ptros_05_model_2$eta +  1.96 *new_data_ptros_05_model_2$SE_eta)
new_data_ptros_05_model_2$CI <- logit_back(1.96 *new_data_ptros_05_model_2$SE_eta)
#### Все то же самое,  P(T|tros) P(E|edu), предсказанные для Ptos=0
new_data_ptros_0_model_2 <- expand.grid(Sp = c("M.trossulus", "M.edulis"), Subset = c("WS", "BL", "BH"), freq_MT = 0)
new_data_ptros_0_model_2$eta <- predict(Model_2_final, newdata = new_data_ptros_0_model_2,  re.form = NA)
X <- model.matrix(~freq_MT * Subset * Sp  , data = new_data_ptros_0_model_2)
new_data_ptros_0_model_2$SE_eta <- sqrt(diag(X %*% vcov(Model_2_final) %*% t(X)))
new_data_ptros_0_model_2$fit <- logit_back(new_data_ptros_0_model_2$eta)
new_data_ptros_0_model_2$lwr <- logit_back(new_data_ptros_0_model_2$eta -  1.96 *new_data_ptros_0_model_2$SE_eta)
new_data_ptros_0_model_2$upr <- logit_back(new_data_ptros_0_model_2$eta +  1.96 *new_data_ptros_0_model_2$SE_eta)
new_data_ptros_0_model_2$CI <- logit_back(1.96 *new_data_ptros_0_model_2$SE_eta)
#### Все то же самое,  P(T|tros) P(E|edu), предсказанные для Ptos=1
new_data_ptros_1_model_2 <- expand.grid(Sp = c("M.trossulus", "M.edulis"), Subset = c("WS", "BL", "BH"), freq_MT = 1)
new_data_ptros_1_model_2$eta <- predict(Model_2_final, newdata = new_data_ptros_1_model_2,  re.form = NA)
X <- model.matrix(~freq_MT * Subset * Sp , data = new_data_ptros_1_model_2)
new_data_ptros_1_model_2$SE_eta <- sqrt(diag(X %*% vcov(Model_2_final) %*% t(X)))
new_data_ptros_1_model_2$fit <- logit_back(new_data_ptros_1_model_2$eta)
new_data_ptros_1_model_2$lwr <- logit_back(new_data_ptros_1_model_2$eta -  1.96 *new_data_ptros_1_model_2$SE_eta)
new_data_ptros_1_model_2$upr <- logit_back(new_data_ptros_1_model_2$eta +  1.96 *new_data_ptros_1_model_2$SE_eta)
new_data_ptros_1_model_2$CI <- logit_back(1.96 *new_data_ptros_1_model_2$SE_eta)
# new_data_ptros_1_model_2$fit - new_data_ptros_0_model_2$fit
# Chunk 13
#### В этом чанке вычисляются  значения P(T|tros) P(E|edu), предсказанные для Ptos=0.5
new_data_ptros_05_model_8 <- expand.grid(Sp = c("M.trossulus", "M.edulis"), Subset = c("WSBL", "BH", "GOM", "BALT", "NORW"), freq_MT = 0.5)
new_data_ptros_05_model_8$eta <- predict(Model_8_final, newdata = new_data_ptros_05_model_8,  re.form = NA)
X <- model.matrix(~freq_MT * Subset * Sp, data = new_data_ptros_05_model_8)
new_data_ptros_05_model_8$SE_eta <- sqrt(diag(X %*% vcov(Model_8_final) %*% t(X)))
new_data_ptros_05_model_8$fit <- logit_back(new_data_ptros_05_model_8$eta)
new_data_ptros_05_model_8$lwr <- logit_back(new_data_ptros_05_model_8$eta -  1.96 *new_data_ptros_05_model_8$SE_eta)
new_data_ptros_05_model_8$upr <- logit_back(new_data_ptros_05_model_8$eta +  1.96 *new_data_ptros_05_model_8$SE_eta)
new_data_ptros_05_model_8$CI <- logit_back(1.96 *new_data_ptros_05_model_8$SE_eta)
#### Все то же самое,  P(T|tros) P(E|edu), предсказанные для Ptos=0
new_data_ptros_0_model_8 <- expand.grid(Sp = c("M.trossulus", "M.edulis"), Subset = c("WSBL", "BH", "GOM", "BALT", "NORW"), freq_MT = 0)
new_data_ptros_0_model_8$eta <- predict(Model_8_final, newdata = new_data_ptros_0_model_8,  re.form = NA)
X <- model.matrix(~freq_MT * Subset * Sp  , data = new_data_ptros_0_model_8)
new_data_ptros_0_model_8$SE_eta <- sqrt(diag(X %*% vcov(Model_8_final) %*% t(X)))
new_data_ptros_0_model_8$fit <- logit_back(new_data_ptros_0_model_8$eta)
new_data_ptros_0_model_8$lwr <- logit_back(new_data_ptros_0_model_8$eta -  1.96 *new_data_ptros_0_model_8$SE_eta)
new_data_ptros_0_model_8$upr <- logit_back(new_data_ptros_0_model_8$eta +  1.96 *new_data_ptros_0_model_8$SE_eta)
new_data_ptros_0_model_8$CI <- logit_back(1.96 *new_data_ptros_0_model_8$SE_eta)
#### Все то же самое,  P(T|tros) P(E|edu), предсказанные для Ptos=1
new_data_ptros_1_model_8 <- expand.grid(Sp = c("M.trossulus", "M.edulis"), Subset = c("WSBL", "BH", "GOM", "BALT", "NORW"), freq_MT = 1)
new_data_ptros_1_model_8$eta <- predict(Model_8_final, newdata = new_data_ptros_1_model_8,  re.form = NA)
X <- model.matrix(~freq_MT * Subset * Sp , data = new_data_ptros_1_model_8)
new_data_ptros_1_model_8$SE_eta <- sqrt(diag(X %*% vcov(Model_8_final) %*% t(X)))
new_data_ptros_1_model_8$fit <- logit_back(new_data_ptros_1_model_8$eta)
new_data_ptros_1_model_8$lwr <- logit_back(new_data_ptros_1_model_8$eta -  1.96 *new_data_ptros_1_model_8$SE_eta)
new_data_ptros_1_model_8$upr <- logit_back(new_data_ptros_1_model_8$eta +  1.96 *new_data_ptros_1_model_8$SE_eta)
new_data_ptros_1_model_8$CI <- logit_back(1.96 *new_data_ptros_1_model_8$SE_eta)
# new_data_ptros_1_model_8$fit - new_data_ptros_0_model_8$fit
# Chunk 14
# grid.arrange(Pl_mod1_with_initial_data ,
#              Pl_mod2_with_initial_data + theme(strip.text = element_blank()),
#              Pl_mod4_with_initial_data+ theme(strip.text = element_blank()) ,
#              ncol = 1)
# Pl_mod3_with_initial_data + theme(strip.text = element_blank()),
grid.arrange(Pl_mod1_with_initial_data_no_test ,
Pl_mod2_with_initial_data_no_test + theme(strip.text = element_blank()),
Pl_mod4_with_initial_data_no_test + theme(strip.text = element_blank()) ,
ncol = 1)
# Chunk 15
# Анализ корреляции с размерами
# residuals(Model_2_final)
Model_2_final_diagn <- fortify(Model_2_final)
# sum(is.na(myt2$resid_siz))
resid_siz <- merge(myt2, Model_2_final_diagn)
resid_siz <- resid_siz[!is.na(resid_siz$siz), ]
# cor.test(resid_siz$.scresid, resid_siz$size )
# ggplot(resid_siz, aes(x = size, y = .scresid)) + geom_point() + geom_smooth(method= "lm")
# sum(is.na(resid_siz$size))
resid_cor <- resid_siz %>% group_by(Subset, pop) %>% summarise(cor = cor.test(.scresid, size, method = "pearson")$estimate, p = cor.test(.scresid, size, method = "pearson")$p.value)
# str((cor.test(resid_siz$.scresid, resid_siz$size, method = "pearson")))
resid_cor$p_adj <- p.adjust(resid_cor$p, method = "hochberg")
# sum(resid_cor$p_adj < 0.05, na.rm = T)
# kable(resid_cor[resid_cor$p_adj < 0.05, ])
# То же самое для модели 4
# residuals(Model_4_final)
Model_4_final_diagn <- fortify(Model_4_final)
# sum(is.na(myt2$resid_siz))
resid_siz2 <- merge(myt2, Model_4_final_diagn)
resid_siz2 <- resid_siz2[!is.na(resid_siz2$siz), ]
# sum(is.na(resid_siz2$size))
# ggplot(resid_siz2, aes(x = size, y = .scresid)) + geom_point() + geom_smooth()
# cor.test(resid_siz2$.scresid, resid_siz2$size )
resid_cor2 <- resid_siz2 %>% group_by(Subset, pop) %>% summarise(cor = cor.test(.scresid, size, method = "pearson")$estimate, p = cor.test(.scresid, size, method = "pearson")$p.value)
# str((cor.test(resid_siz$.scresid, resid_siz$size, method = "pearson")))
resid_cor2$p_adj <- p.adjust(resid_cor2$p, method = "hochberg")
# kable(resid_cor2[resid_cor2$p_adj < 0.05, ])
###### То же самое для Model_6_final ##############################
# residuals(Model_6_final)
Model_6_final_diagn <- fortify(Model_6_final)
resid_siz2 <- merge(myt2_reduced, Model_6_final_diagn)
resid_siz2 <- resid_siz2[!is.na(resid_siz2$siz), ]
# sum(is.na(resid_siz2$size))
# ggplot(resid_siz2, aes(x = size, y = .scresid)) + geom_point() + geom_smooth()
# cor.test(resid_siz2$.scresid, resid_siz2$size )
resid_cor2 <- resid_siz2 %>% group_by(Subset, pop) %>% summarise(cor = cor.test(.scresid, size, method = "pearson")$estimate, p = cor.test(.scresid, size, method = "pearson")$p.value)
# str((cor.test(resid_siz$.scresid, resid_siz$size, method = "pearson")))
resid_cor2$p_adj <- p.adjust(resid_cor2$p, method = "hochberg")
# kable(resid_cor2[resid_cor2$p_adj < 0.05, ])
## Анализ связи с размерами в каждой из популяций, включая популяции из Атлантики
myt2_all$pop <- factor(myt2_all$pop)
myt2_all$Subset <- factor(myt2_all$Subset)
size_models_tros <- myt2_all  %>% group_by(pop)%>% filter(Sp == "M.trossulus") %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models_tros$pop <- factor(size_models_tros$pop)
size_models_tros_res <- size_models_tros %>% tidy(model)
size_models_tros_res$p.value <- round(size_models_tros_res$p.value, 4)
# write.table(size_models_tros_res, "clipboard", sep = "\t", row.names = F)
size_models_res_tros_slope <- size_models_tros_res[size_models_tros_res$term != "(Intercept)", ]
size_models_res_tros_slope$p_adj <- p.adjust(size_models_res_tros_slope$p.value, method = "hochberg")
# size_models_res_tros_slope_signif <-size_models_res_tros_slope[size_models_res_tros_slope$p_adj <0.05, ]
size_models_edu <- myt2_all  %>% group_by(pop)%>% filter(Sp == "M.edulis") %>% do(model = glm(ind ~  size, family = "binomial", data = .))
size_models_edu$pop <- factor(size_models_edu$pop)
size_models_edu_res <- size_models_edu %>% tidy(model)
size_models_edu_res$p.value <- round(size_models_edu_res$p.value, 4)
# write.table(size_models_edu_res, "clipboard", sep = "\t", row.names = F)
size_models_res_edu_slope <- size_models_edu_res[size_models_edu_res$term != "(Intercept)", ]
size_models_res_edu_slope$p_adj <- p.adjust(size_models_res_edu_slope$p.value, method = "hochberg")
size_models_res_edu_slope$p.value <- round(size_models_res_edu_slope$p.value, 4)
# signif_slope <- myt2 %>% filter(pop %in% size_models_res_slope_signif$pop) %>% select(size)
# length(signif_slope$size)
# not_signif_slope <- myt2 %>% filter(!pop %in% size_models_res_slope_signif$pop) %>%  select(size)
# length(not_signif_slope$size)
# t.test(signif_slope$size, not_signif_slope$size)
# Chunk 16: "Compare different ways of data joinings"
candidat_data_1 <- myt2
candidat_data_1$Subset <- candidat_data_1$Subset
candidat_data_2 <- candidat_data_1
candidat_data_2$Subset <- ifelse(candidat_data_2$Subset == "WS"| candidat_data_2$Subset == "BL", "WSBL", "BH")
candidat_data_3 <- candidat_data_1
candidat_data_3$Subset <- ifelse(candidat_data_3$Subset == "WS"| candidat_data_3$Subset == "BH", "WBH", "BL")
candidat_data_4 <- candidat_data_1
candidat_data_4$Subset <- ifelse(candidat_data_4$Subset == "BL"| candidat_data_4$Subset == "BH", "BLBH", "WS")
Model_4_final_cand_1 <- Model_4_final
Model_4_final_cand_2 <- update(Model_4_final, data = candidat_data_2)
Model_4_final_cand_3 <- update(Model_4_final, data = candidat_data_3)
Model_4_final_cand_4 <- update(Model_4_final, data = candidat_data_4)
Model_4_final_cand_5 <- update(Model_4_final, . ~ . - Subset - morph:Subset - freq_MT:Subset)
AIC_print <- as.data.frame(AIC(Model_4_final_cand_1, Model_4_final_cand_2, Model_4_final_cand_3, Model_4_final_cand_4, Model_4_final_cand_5))
#
# ptop_T_MT_cand2 <- candidat_data_2 %>% group_by(Subset, pop) %>% summarize(Prop_T = mean(Prop_T), MT = sum(Sp2), N = n())
#
# ptop_T_MT_cand3 <- candidat_data_3 %>% group_by(Subset, pop) %>% summarize(Prop_T = mean(Prop_T), MT = sum(Sp2), N = n())
#
# ptop_T_MT_cand4 <- candidat_data_4 %>% group_by(Subset, pop) %>% summarize(Prop_T = mean(Prop_T), MT = sum(Sp2), N = n())
#
# Model_5_final_cand_1 <- Model_5_final
#
# Model_5_final_cand_2 <- update(Model_5_final, data = ptop_T_MT_cand2)
#
# Model_5_final_cand_3 <- update(Model_5_final, data = ptop_T_MT_cand3)
#
# Model_5_final_cand_4 <- update(Model_5_final, data = ptop_T_MT_cand4)
#
# Model_5_final_cand_5 <- update(Model_5_final, . ~ . - Subset - morph:Subset - freq_MT:Subset)
#
# AIC_print2 <- as.data.frame(AIC(Model_5_final_cand_1, Model_5_final_cand_2, Model_5_final_cand_3, Model_5_final_cand_4, Model_5_final_cand_5))
# kable(AIC_print)
# Chunk 17
# Model 6#########################
myt2_all$Subset <- factor(myt2_all$Subset, levels = c("WSBL", "BH", "GOM", "BALT", "SCOT", "NORW"))
new_data6 <- myt2_reduced %>% group_by(Subset, morph) %>% do(data.frame(freq_MT = seq(min(.$freq_MT), max(.$freq_MT), length.out = 100)))
# Предсказанные значеня в шкале вероятностей
new_data6$fit <- predict(Model_6_final, newdata = new_data6, type = "response", re.form = NA)
# Предсказанные значеня в шкале логитов
new_data6$fit_eta <- predict(Model_6_final, newdata = new_data6, re.form = NA)
# Вычисление доверительного инеравала
# formula(Model_6_final)
X <- model.matrix(  ~ morph * freq_MT * Subset, data = new_data6) #Модельная матрица для визуализации
# Ошибки в шкале логитов
new_data6$se_eta <- sqrt(diag(X %*% vcov(Model_6_final) %*% t(X)))
new_data6$lwr <- logit_back(new_data6$fit_eta - 1.96 * new_data6$se_eta)
new_data6$upr <- logit_back(new_data6$fit_eta + 1.96 * new_data6$se_eta)
Pl_mod6 <- ggplot(new_data6, aes(x = freq_MT)) +
geom_ribbon(aes(ymin = lwr, ymax = upr, group = morph), alpha = 0.1)  +
geom_line(aes(y = fit, color = morph), size=1, linetype = 2) +
geom_rug(data = myt2_reduced, inherit.aes = FALSE,  aes(x = freq_MT), size = 0.1) +
scale_color_manual(values = c("blue", "red")) +
scale_fill_manual(values = c("blue", "red"))  +
xlim(0,1)  +
facet_wrap( ~ Subset, ncol = 1) +
guides(color = "none")
pr_value_M <- myt2_all %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT), N_T = sum(ind == 1),  N_T_MT = sum(Sp2 == 1 & ind == 1), N_E_MT = sum(Sp2 == 1 & ind == 0), N_E = sum(ind == 0), N_E_ME = sum(Sp2 == 0 & ind == 0), N_T_ME = sum(Sp2 == 0 & ind == 1))
pr_value_M$PMT_T <- with(pr_value_M, N_T_MT / N_T)
pr_value_M$PMT_E <- with(pr_value_M, N_E_MT / N_T)
pr_value_M$PME_E <- with(pr_value_M, N_E_ME / N_E)
pr_value_M$PME_T <- with(pr_value_M, N_T_ME / N_E)
# myt3_and_Atlantic <- rbind(myt3_all, myt2_all[myt2_all$Subset %in% c("GOM", "BALT", "SCOT", "NORW"), ])
#
# myt3_and_Atlantic$Subset[myt3_and_Atlantic$sea == "barents" & myt3_and_Atlantic$sal_place == "fresh"] <- "WBL"
# myt3_and_Atlantic$Subset[myt3_and_Atlantic$sea == "barents" & myt3_and_Atlantic$sal_place == "normal"] <- "BH"
# myt3_and_Atlantic$Subset[myt3_and_Atlantic$sea == "white" & myt3_and_Atlantic$sal_place == "normal"] <- "WBL"
# myt3_and_Atlantic$Subset[myt3_and_Atlantic$sea == "white" & myt3_and_Atlantic$sal_place == "fresh"] <- "WBL"
#
# myt3_and_Atlantic$Subset <- factor(myt3_and_Atlantic$Subset, levels = c("WBL", "BH", "GOM",  "BALT", "NORW", "SCOT" ))
myt3_and_Atlantic <- myt2_all[myt2_all$Subset %in% c("GOM", "BALT", "SCOT", "NORW"), ]
pr_value_myt3_and_Atlantic <- myt3_and_Atlantic %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT), N_T = sum(ind == 1),  N_T_MT = sum(Sp2 == 1 & ind == 1), N_E_MT = sum(Sp2 == 1 & ind == 0), N_E = sum(ind == 0), N_E_ME = sum(Sp2 == 0 & ind == 0), N_T_ME = sum(Sp2 == 0 & ind == 1))
pr_value_myt3_and_Atlantic$PMT_T <- with(pr_value_myt3_and_Atlantic, N_T_MT / N_T)
pr_value_myt3_and_Atlantic$PMT_E <- with(pr_value_myt3_and_Atlantic, N_E_MT / N_T)
pr_value_myt3_and_Atlantic$PME_E <- with(pr_value_myt3_and_Atlantic, N_E_ME / N_E)
pr_value_myt3_and_Atlantic$PME_T <- with(pr_value_myt3_and_Atlantic, N_T_ME / N_E)
#
Pl_mod6_with_initial_data <- Pl_mod6 + geom_segment(data = pr_value_myt3_and_Atlantic, aes(x = freq_MT, y = PME_E, xend = freq_MT, yend = PMT_T), color="darkgrey") +
geom_hline(aes(yintercept=0.5), color="black") +
geom_point(data = pr_value_myt3_and_Atlantic, aes(y = PME_E), fill = "white", shape = 22) +
geom_point(data = pr_value_myt3_and_Atlantic, aes(y = PMT_T), fill = "black", shape = 22) +
labs(y =  "Probability of correct species \n identification by morphotypes", x = "Proportion of M. trossulus", fill = "")+
ylim(0,1) +
xlim(0,1) +
theme_bw()
# Pl_mod6 + geom_segment(data = pr_value_myt3_and_Atlantic, aes(x = freq_MT, y = PME_E, xend = freq_MT, yend = PMT_T), color="darkgrey") +
#   geom_hline(aes(yintercept=0.5), color="black") +
#   geom_text(data = pr_value_myt3_and_Atlantic, aes(y = PME_E, label = pop ), fill = "white", shape = 22) +
#   geom_text(data = pr_value_myt3_and_Atlantic, aes(y = PMT_T, label = pop), fill = "black", shape = 22) +
#   labs(y =  "Probability of correct species \n identification by morphotypes", x = "Proportion of M. trossulus", fill = "")+
#   ylim(0,1) +
#   xlim(0,1) +
#   theme_bw()
# Model 7#########################
new_data7 <- myt2_reduced %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(Prop_T) ) %>% group_by(Subset) %>%  do(data.frame(Prop_T = seq(min(.$Prop_T), max(.$Prop_T), length.out = 10)))
predicted7 <- predict(Model_7_final, newdata = new_data7,  type="response", se.fit = T)
new_data7$fit <- predicted7$fit
new_data7$SE <- predicted7$se.fit
Pl_mod7 <- ggplot(new_data7, aes(x = Prop_T, y = fit)) +
geom_line(linetype = 2, color = "red", size = 1) +
facet_wrap(~Subset, ncol = 1) +
geom_ribbon(aes(ymin = fit - 1.96*SE, ymax = fit + 1.96*SE), alpha = 0.1) +
xlim(0, 1) +
ylim(0, 1) +
geom_rug(data = myt2_reduced, inherit.aes = FALSE,  aes(x = Prop_T), size = 0.1) +
geom_abline()
# unique(new_data7$Subset)
init_data_Model_7 <- myt3_and_Atlantic %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(morph == "T_m"),  freq_MT = mean(Sp == "M.trossulus"), N = n())
init_data_Model_7$Subset <- factor(init_data_Model_7$Subset, levels = c("WSBL", "BH", "GOM", "BALT", "NORW", "SCOT"))
# init_data_Model_7 <- init_data_Model_7[init_data_Model_7$pop %in% c("Limh88", "CBCP"),  ]
Pl_mod7_with_initial_data <- Pl_mod7 + geom_point(data = init_data_Model_7, aes( y = freq_MT), shape = 22, size = 2 ) + scale_fill_continuous(low = "white", high = "black") + labs(x = "Proportion of mussels with T-morphotype", y = "Proportion of M.trossulus \n") + theme_bw()
# Model 8#########################
new_data8 <- myt2_reduced %>% group_by(Subset,  Sp) %>% do(data.frame(freq_MT = seq(min(.$freq_MT), max(.$freq_MT), length.out = 100)))
new_data8$eta <- predict(Model_8_final, newdata = new_data8,  re.form = NA)
X <- model.matrix( ~ freq_MT * Subset * Sp  , data = new_data8)
new_data8$SE_eta <- sqrt(diag(X %*% vcov(Model_8_final) %*% t(X)))
new_data8$fit <- logit_back(new_data8$eta)
new_data8$lwr <- logit_back(new_data8$eta -  1.96 *new_data8$SE_eta)
new_data8$upr <- logit_back(new_data8$eta +  1.96 *new_data8$SE_eta)
Pl_mod8 <-  ggplot(new_data8, aes(x = freq_MT, y = fit, group = Sp)) + geom_line(linetype = 2,  size = 1, aes(color = Sp)) + geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.1) + facet_wrap(~Subset, ncol = 1)  + xlim(0, 1) + ylim(0, 1) + scale_color_manual(values=c("blue", "red")) + guides(color = "none") +  geom_rug(data = myt2_reduced, inherit.aes = FALSE,  aes(x = freq_MT), size = 0.1)
pops_over_M <- myt2_reduced %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT), N_MT = sum(Sp2 == 1),  N_T_MT = sum(Sp2 == 1 & ind == 1), N_E_MT = sum(Sp2 == 1 & ind == 0), N_ME = sum(Sp2 == 0), N_E_ME = sum(Sp2 == 0 & ind == 0), N_T_ME = sum(Sp2 == 0 & ind == 1))
pops_over_M$P_T_MT <- with(pops_over_M, N_T_MT / N_MT)
pops_over_M$P_E_MT <- with(pops_over_M, N_E_MT / N_MT)
pops_over_M$P_E_ME <- with(pops_over_M, N_E_ME / N_ME)
pops_over_M$P_T_ME <- with(pops_over_M, N_T_ME / N_ME)
test_Model_8 <- myt3_and_Atlantic%>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT), N_MT = sum(Sp2 == 1),  N_T_MT = sum(Sp2 == 1 & ind == 1), N_E_MT = sum(Sp2 == 1 & ind == 0), N_ME = sum(Sp2 == 0), N_E_ME = sum(Sp2 == 0 & ind == 0), N_T_ME = sum(Sp2 == 0 & ind == 1))
test_Model_8$P_T_MT <- with(test_Model_8, N_T_MT / N_MT)
test_Model_8$P_E_MT <- with(test_Model_8, N_E_MT / N_MT)
test_Model_8$P_E_ME <- with(test_Model_8, N_E_ME / N_ME)
test_Model_8$P_T_ME <- with(test_Model_8, N_T_ME / N_ME)
Pl_mod8_with_initial_data <- Pl_mod8 +
labs(y =  "Proportion of T-morphotype \n among  M. trossulus  and  M. edulis",
x = "Proportion of M. trossulus", fill = "") +
geom_segment(data = test_Model_8, aes(x = freq_MT, y = (1-P_E_ME), xend = freq_MT, yend = P_T_MT, group = 1), color = "darkgray")+
geom_point(data = test_Model_8, aes(y = (1-P_E_ME),  group =1), fill = "white", shape = 22)+
geom_point(data = test_Model_8, aes(y = P_T_MT,  group =1), fill = "black", shape = 22)  +
ylim(0,1) +
xlim(0,1) +
geom_hline(aes(yintercept=0.5), color="black")
# Chunk 18
## Calculator plot for all geographical areas
## Калькулятор основан на калибровочных выборках, выбранных в соответствии с "правильной" стратегией.
# В этом коде для поиска максимально различных или максимально смешанных выборок используются истинные данные по генотипам
# pops_max_dif_WBL <- max_dif(df = myt2_all, Subset = "WSBL")
# pops_max_dif_BH <- max_dif(df = myt2_all, Subset = "BH")
# pops_max_dif_GOM <- max_dif(df = myt2_all, Subset = "GOM")
# pops_max_dif_BALT <- max_dif(df = myt2_all, Subset = "BALT")
# pops_max_dif_SCOT <- max_dif(df = myt2_all, Subset = "SCOT")
# pops_max_dif_NORW <- max_dif(df = myt2_all, Subset = "NORW")
#
# pops_max_mix_WBL <- max_mix(df = myt2_all, Subset = "WSBL")
# pops_max_mix_BH <- max_mix(df = myt2_all, Subset = "BH")
# pops_max_mix_GOM <- max_mix(df = myt2_all, Subset = "GOM")
# pops_max_mix_BALT <- max_mix(df = myt2_all, Subset = "BALT")
# pops_max_mix_SCOT <- max_mix(df = myt2_all, Subset = "SCOT")
# pops_max_mix_NORW <- max_mix(df = myt2_all, Subset = "NORW")
#
# В этом коде для поиска максимально различных или максимально смешанных выборок используются истинные данные по генотипам
# НО Отбор популяций идет вручную
# max_dif Ptros<0.1 and Ptros>0.8
# max_mix 0.45 < Ptros < 0.65
pops_max_dif_WBL <- c("belok2", "berzakol", "luv_korg",  "nm", "padan", "salnij", "umba_06", "umba_bridge","umba_kamni", "umba_pioner", "vor1", "vor2", "vor5", "kanal", "oenij", "zmis")
pops_max_dif_BH <- c("banka",  "dz_banka","tu_old")
pops_max_dif_GOM <- c("BI", "CBE", "JPC", "KIM", "MDICOA", "PH", "VH")
pops_max_dif_BALT <- c("kast05", "Solvesborg", "Ystad05")
pops_max_dif_SCOT <- max_dif(df = myt2_all, Subset = "SCOT")
pops_max_dif_NORW <- c("Esp04", "Bergen_MV")
pops_max_mix_WBL <- c("abram", "niva_sl", "sevsk", "umba", "umba_pikut")
pops_max_mix_BH <-  c("kuvsh", "seredina", "seredina_sub", "ustie")
pops_max_mix_GOM <- c("CBSL")
pops_max_mix_BALT <- c("kast87", "Vhg05")
pops_max_mix_SCOT <- max_mix(df = myt2_all, Subset = "SCOT")
pops_max_mix_NORW <- as.character(unique(myt2_all [myt2_all$Subset == "NORW", "pop"]))
#########################################################
# # В этом коде для поиска максимально различных или максимально смешанных выборок используются данные по чстотам T-morphotype
# pops_max_dif_WBL <- max_dif_T(df = myt2_all, Subset = "WSBL")
# pops_max_dif_BH <- max_dif_T(df = myt2_all, Subset = "BH")
# pops_max_dif_GOM <- max_dif_T(df = myt2_all, Subset = "GOM")
# pops_max_dif_BALT <- max_dif_T(df = myt2_all, Subset = "BALT")
# pops_max_dif_SCOT <- max_dif_T(df = myt2_all, Subset = "SCOT")
# pops_max_dif_NORW <- max_dif_T(df = myt2_all, Subset = "NORW")
#
# pops_max_mix_WBL <- max_mix_T(df = myt2_all, Subset = "WBL")
# pops_max_mix_BH <- max_mix_T(df = myt2_all, Subset = "BH")
# pops_max_mix_GOM <- max_mix_T(df = myt2_all, Subset = "GOM")
# pops_max_mix_BALT <- max_mix_T(df = myt2_all, Subset = "BALT")
# pops_max_mix_SCOT <- max_mix_T(df = myt2_all, Subset = "SCOT")
# pops_max_mix_NORW <- max_mix_T(df = myt2_all, Subset = "NORW")
# ##########################################################
# Бублики для наиболее смешанных популяций
donat_max_mix_WBL <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_WBL, ])
donat_max_mix_BH <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_BH, ])
donat_max_mix_GOM <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_GOM, ])
donat_max_mix_BALT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_BALT, ])
# donat_max_mix_SCOT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_SCOT, ])
donat_max_mix_NORW <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_NORW, ])
donat_max_mix_SCOT <- donat(myt2_all[myt2_all$Subset == "SCOT", ]) #При малом количесвте выборок бублик считаем по всем сборам
# donat_max_mix_NORW <- donat(df = myt2_all[myt2_all$Subset == "NORW", ]) #При малом количесвте выборок бублик считаем по всем сборам
# Бублики для наиболее различных по стуртуре популяций
donat_max_dif_WBL <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_WBL, ])
donat_max_dif_BH <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_BH, ])
donat_max_dif_GOM <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_GOM, ])
donat_max_dif_BALT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_BALT, ])
# donat_max_dif_SCOT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_SCOT, ])
donat_max_dif_NORW <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_NORW, ])
donat_max_dif_SCOT <- donat(df = myt2_all[myt2_all$Subset == "SCOT", ]) #При малом количесвте выборок бублик считаем по всем сборам
# donat_max_dif_NORW <- donat(df = myt2_all[myt2_all$Subset == "NORW", ]) #При малом количесвте выборок бублик считаем по всем сборам
#Предсказания калькулятора 2 на основе наиболее смешанных популяций
calc2_WBL <- calc2(donat_max_mix_WBL[1], donat_max_mix_WBL[2])
calc2_BH <- calc2(donat_max_mix_BH[1], donat_max_mix_BH[2])
calc2_GOM <- calc2(donat_max_mix_GOM[1], donat_max_mix_GOM[2])
calc2_BALT <- calc2(donat_max_mix_BALT[1], donat_max_mix_BALT[2])
calc2_SCOT <- calc2(donat_max_mix_SCOT[1], donat_max_mix_SCOT[2])
calc2_NORW <- calc2(donat_max_mix_NORW[1], donat_max_mix_NORW[2])
calc2_WBL$Subset <- "WSBL"
calc2_BH$Subset <- "BH"
calc2_GOM$Subset <- "GOM"
calc2_BALT$Subset <- "BALT"
calc2_SCOT$Subset <- "SCOT"
calc2_NORW$Subset <- "NORW"
calc2_predictions <- rbind(calc2_WBL, calc2_BH, calc2_GOM, calc2_BALT, calc2_SCOT, calc2_NORW)
calc2_predictions$Subset <- factor(calc2_predictions$Subset, levels = levels(myt2_all$Subset))
#Предсказания калькулятора 1 на основе наиболее различных популяций
calc1_WBL <- calc1(donat_max_dif_WBL[1], donat_max_dif_WBL[2])
calc1_BH <- calc1(donat_max_dif_BH[1], donat_max_dif_BH[2])
calc1_GOM <- calc1(donat_max_dif_GOM[1], donat_max_dif_GOM[2])
calc1_BALT <- calc1(donat_max_dif_BALT[1], donat_max_dif_BALT[2])
calc1_SCOT <- calc1(donat_max_dif_SCOT[1], donat_max_dif_SCOT[2])
calc1_NORW <- calc1(donat_max_dif_NORW[1], donat_max_dif_NORW[2])
calc1_WBL$Subset <- "WSBL"
calc1_BH$Subset <- "BH"
calc1_GOM$Subset <- "GOM"
calc1_BALT$Subset <- "BALT"
calc1_SCOT$Subset <- "SCOT"
calc1_NORW$Subset <- "NORW"
calc1_predictions <- rbind(calc1_WBL, calc1_BH, calc1_GOM, calc1_BALT, calc1_SCOT, calc1_NORW)
calc1_predictions$Subset <- factor(calc1_predictions$Subset, levels = levels(myt2_all$Subset))
# Chunk 19
Pl_mod6_with_initial_data_teor_calc2 <- Pl_mod6_with_initial_data +
geom_line(data = calc2_predictions, aes(x = freq_MT, y = P_MT_T), color = "red") +
geom_line(data = calc2_predictions, aes(x = freq_MT, y = P_ME_E), color = "blue")
Pl_mod7_with_initial_data_teor_calc1 <- Pl_mod7_with_initial_data  +
geom_line(data = calc1_predictions, aes(x = P_T, y = Ptros), color = "darkgray", size = 1)
# Chunk 20
grid.arrange(Pl_mod7_with_initial_data_teor_calc1, Pl_mod8_with_initial_data,  Pl_mod6_with_initial_data_teor_calc2, ncol =3)
# Chunk 21: "Predictive values of morphotype test for all geographical regions"
new_data_mix <- expand.grid(morph = unique(myt2_reduced$morph), Subset = unique(myt2_reduced$Subset), freq_MT = 0.5 )
# Предсказанные значеня в шкале вероятностей
new_data_mix$fit <- predict(Model_6_final, newdata = new_data_mix, type = "response", re.form = NA)
# Предсказанные значеня в шкале логитов
new_data_mix$fit_eta <- predict(Model_6_final, newdata = new_data_mix, re.form = NA)
# Вычисление доверительного инеравала
# formula(Model_6_final)
X <- model.matrix(  ~ morph * freq_MT * Subset, data = new_data_mix) #Модельная матрица для визуализации
# Ошибки в шкале логитов
new_data_mix$se_eta <- sqrt(diag(X %*% vcov(Model_6_final) %*% t(X)))
new_data_mix$lwr <- logit_back(new_data_mix$fit_eta - 1.96 * new_data_mix$se_eta)
new_data_mix$upr <- logit_back(new_data_mix$fit_eta + 1.96 * new_data_mix$se_eta)
predict_Ptros_05 <- new_data_mix %>% select(-c(freq_MT, fit_eta, se_eta))
dd <- melt(predict_Ptros_05)
predict_Ptros_05_print <- dcast(dd, Subset ~ morph + variable, value.var = "value" )
predict_Ptros_05_print[,-1] <- round(predict_Ptros_05_print[,-1], 2)
predict_Ptros_05_print <- rbind(rep(NA, 7), predict_Ptros_05_print)
predict_Ptros_05_print[1,] <- c(NA, "Predicted", "Low", "Up", "Predicted", "Low", "Up")
kable(predict_Ptros_05_print, col.names = c("Subset", "P(edu|E)", "", "", "P(tros|T)", "", "" ), align = "rcccccc", caption = "Table ++. Predicted values of probability of correct species identification by mussel morphotype in mixed populations (Ptros = 0.5) in different geographical regions. Low and upper boundaries of 95% conficencal intervals are given for predicted values.")
# Реальные частоты M.trossulus среди T-морфотипа и реальные частоты M.edulis  среди E-морфотипа
#
# myt2_all %>% group_by(Subset, morph) %>% summarise(P_trossulus = mean(Sp == "M.trossulus"), P_edulis = mean(Sp == "M.edulis")) %>% filter(morph == "E_m")
#
# myt2_all %>% group_by(Subset, morph) %>% summarise(P_trossulus = mean(Sp == "M.trossulus"), P_edulis = mean(Sp == "M.edulis")) %>% filter(morph == "T_m")
# Chunk 22
# Accuracy assessment
level_prob <- 0.8 #Условная величина вероятности правильного определения, которая является приемлемой
# test_myt_3_Atlantic <- myt3_and_Atlantic %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(ind == 1)) %>% filter(! Subset %in% c( "SCOT"))
test_myt_3_Atlantic <- myt2_all %>% group_by(Subset, pop) %>% summarise(Prop_T = mean(ind == 1)) %>% filter(! Subset %in% c( "SCOT"))
test_myt_3_Atlantic$freq_MT_predicted <-  predict(Model_7_final, newdata = test_myt_3_Atlantic, type = "response")
# test_myt_3_Atlantic_2  <- myt3_and_Atlantic %>% select(Subset, pop, Sp, morph)%>% filter(! Subset %in% c("SCOT"))
test_myt_3_Atlantic_2  <- myt2_all %>% select(Subset, pop, Sp, morph)%>% filter(! Subset %in% c("SCOT"))
test_myt_3_Atlantic_3 <- merge(test_myt_3_Atlantic_2, test_myt_3_Atlantic)
test_myt_3_Atlantic_3$freq_MT <- test_myt_3_Atlantic_3$freq_MT_predicted
test_myt_3_Atlantic_3$Predicted_P_correct <- predict(Model_6_final, newdata = test_myt_3_Atlantic_3, type = "response" , re.form = NA)
test_myt_3_Atlantic_3$Congr_predicted <- ifelse(test_myt_3_Atlantic_3$Predicted_P_correct >= level_prob, 1, 0)
test_result <- test_myt_3_Atlantic_3 %>% group_by(Subset, morph) %>% summarise(Accuracy_T = round(mean( (morph == "T_m" & Sp == "M.trossulus" & Congr_predicted ==1) | (morph == "E_m" & Sp == "M.edulis" & Congr_predicted ==1) ), 2))
test_result <- dcast(test_result, Subset ~ morph, value.var = "Accuracy_T" )
mixed_data <- myt2_all[myt2_all$Subset %in% c("WSBL"), ]
n_pop <- length(unique(mixed_data$pop))
n_possible_pairs <- (n_pop^2 - n_pop)/2
Pl_teor_empir_Mod_7 <- ggplot(perms2(df = mixed_data, regr_model = Model_7_final), aes(x = Delta, y = Goodness)) + geom_point(size = 0.1) + geom_smooth(se = F, method = "loess") + labs(y = "Goodness \n")
Pl_teor_empir_Mod_7
Pl_teor_empir_Mod_6 <- ggplot(perms4(df = mixed_data, regr_model = Model_6_final), aes(x = Delta, y = Goodness)) + geom_point(size = 0.1) + geom_smooth(se = F, method = "loess") + labs(y = "Goodness \n")
Pl_teor_empir_Mod_6
Pl_teor_empir_Mod_7_T <- ggplot(perms2_T(df = mixed_data, regr_model = Model_7_final), aes(x = Delta, y = Goodness)) + geom_point(size = 0.1) + geom_smooth(se = F, method = "loess") + labs(y = "Goodness \n")+ ggtitle("Calibration on the base of T-morphotype frequency")
Pl_teor_empir_Mod_7_T
Pl_teor_empir_Mod_6_T <- ggplot(perms4_T(df = mixed_data, regr_model = Model_6_final), aes(x = Delta, y = Goodness)) + geom_point(size = 0.1) + geom_smooth(se = F, method = "loess") + labs(y = "Goodness \n") + ggtitle("Calibration on the base of T-morphotype frequency")
donat_max_mix_WBL
calc1(donat_max_dif_WBL)
calc1(donat_max_dif_WBL[1], donat_max_dif_WBL[2])
calc2(donat_max_dif_WBL[1], donat_max_dif_WBL[2])
Eq3_pred_WSBL <- calc1(donat_max_dif_WBL[1], donat_max_dif_WBL[2])
Eq12_pred_WSBL <- calc2(donat_max_dif_WBL[1], donat_max_dif_WBL[2])
Eq3_pred_WSBL
Eq3_pred_WSBL$Subset <- "WSBL"
Model_7
Model_6_final
Model_7_final
Eq3_pred_WSBL
Eq3_pred_WSBL$Prop_T <- Eq3_pred_WSBL$P_T
predict(Model_7_final, newdata = Eq3_pred_WSBL, type = "response")
Eq3_pred_WSBL$Predict_Model_7 <- predict(Model_7_final, newdata = Eq3_pred_WSBL, type = "response")
Eq3_pred_WSBL
(Ptros - Predict_Model_7)^2
Goodness_Eq3_Model7_WSBL <- with(Eq3_pred_WSBL, 1/sum((Ptros - Predict_Model_7)^2) )
Goodness_Eq3_Model7_WSBL
Goodness_Eq3_Model7_WSBL <- with(Eq3_pred_WSBL, sum((Ptros - Predict_Model_7)^2) )
Goodness_Eq3_Model7_WSBL
Goodness_Eq3_Model7_WSBL <- with(Eq3_pred_WSBL, 1/sum((Ptros - Predict_Model_7)^2) )
Goodness_Eq3_Model7_WSBL
Model_7_final
Eq3_pred_WSBL
qplot(Eq3_pred_WSBL$Predict_Model_7, Eq3_pred_WSBL$Ptros)
qplot(Eq3_pred_WSBL$Predict_Model_7, Eq3_pred_WSBL$Ptros) + geom_abline()
Goodness_Eq3_Model7_WSBL <- with(Eq3_pred_WSBL, 1/mean((Ptros - Predict_Model_7)^2) )
Goodness_Eq3_Model7_WSBL
Eq12_pred_WSBL
Model_6_final
melt(Eq12_pred_WSBL)
dd <- melt(Eq12_pred_WSBL)
Eq12_pred_WSBL <- calc2(donat_max_dif_WBL[1], donat_max_dif_WBL[2])
Eq12_pred_WSBL
Model_6_final
data.frame(freq_MT = c(Eq12_pred_WSBL$freq_MT, Eq12_pred_WSBL$freq_MT), morph = c(rep("T_m", nrow(Eq12_pred_WSBL)), rep("E_m", nrow(Eq12_pred_WSBL))), Subset = "WSBL", Prdict_Eq12 = c(Eq12_pred_WSBL$P_MT_T, Eq12_pred_WSBL$P_ME_E))
Eq12_pred_WSBL_long <- data.frame(freq_MT = c(Eq12_pred_WSBL$freq_MT, Eq12_pred_WSBL$freq_MT), morph = c(rep("T_m", nrow(Eq12_pred_WSBL)), rep("E_m", nrow(Eq12_pred_WSBL))), Subset = "WSBL", Prdict_Eq12 = c(Eq12_pred_WSBL$P_MT_T, Eq12_pred_WSBL$P_ME_E))
predict(Model_6_final, newdata = Eq12_pred_WSBL_long, type = "response")
predict(Model_6_final, newdata = Eq12_pred_WSBL_long, type = "response", re.form = NA)
Eq12_pred_WSBL_long$Predict_Model_6 <- predict(Model_6_final, newdata = Eq12_pred_WSBL_long, type = "response", re.form = NA)
Eq12_pred_WSBL_long
Goodness_Eq12_Model6_WSBL <- with(Eq12_pred_WSBL_long, 1/mean(( Prdict_Eq12 - Predict_Model_6)^2) )
Goodness_Eq12_Model6_WSBL
Pl_teor_empir_Mod_7_add <- Pl_teor_empir_Mod_7 + geom_hline(yintercept = Goodness_Eq3_Model7_WSBL, linetype = 2)
Pl_teor_empir_Mod_7_add
Pl_teor_empir_Mod_6_add <- Pl_teor_empir_Mod_6 + geom_hline(yintercept = Goodness_Eq12_Model6_WSBL, linetype = 2)
Pl_teor_empir_Mod_6_add
grid.arrange(Pl_teor_empir_Mod_6_add, Pl_teor_empir_Mod_7_add, ncol = 2)
grid.arrange( Pl_teor_empir_Mod_7_add, Pl_teor_empir_Mod_6_add, ncol = 2)
citation("lme4")
citation("MuMIn")
Pl_mod7_with_initial_data_teor_calc1
