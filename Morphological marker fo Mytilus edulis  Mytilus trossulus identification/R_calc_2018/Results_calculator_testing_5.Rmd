---
title: ""
author: ""
date: ""
output: html_document
---

```{r setup, include=FALSE, echo=FALSE}
library(knitr)
# library(flextable)

opts_chunk$set(echo = FALSE, cache = FALSE, fig.align ="center", warning = FALSE, message = FALSE)

# set pander table-layout options
library(pander)
panderOptions('table.alignment.default', function(df)
    ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)

```


```{r}

library(lme4)
library(ggplot2)
library(reshape2)
library(sjstats)
library(dplyr)
library(car)
library(doBy)
library(pROC)
library(betareg)
library(lmtest)
library(broom)
library(MuMIn)
library(gridExtra)





#### Data reading and initial preparation #####

myt <- read.table("data_salinity3.csv", header = T, sep = ",")


myt_overseas <- myt[myt$dataset == "overseas", ]

myt <- myt[myt$dataset != "overseas", ]

# str(myt)

myt$Sp [myt$str > 0.5] <- "M.trossulus" #Лучше обозначать так!
myt$Sp [myt$str <= 0.5] <- "M.edulis"
myt$Sp <- factor(myt$Sp)

# Оставляем только мидий, у которых есть оценка морфотипа
myt2 <- myt[!is.na(myt$ind), ]


# Вводим обозначения для морфотипов
myt2$morph <- ifelse(myt2$ind == 1, "T_m", "E_m")
myt2$morph <- factor(myt2$morph)



# Бинарное обозначение видов
myt2$Sp2 <- ifelse(myt2$Sp == "M.trossulus", 1, 0)


#Correct identification
myt2$congr <- ifelse((myt2$ind == 1 & myt2$Sp == "M.trossulus") | (myt2$ind == 0 & myt2$Sp == "M.edulis"), 1, 0   )


# Частота M.trossulus в популяции

freq_MT <- myt2 %>% group_by(pop) %>% summarise(freq_MT = mean(Sp2))

myt2 <- merge(myt2, freq_MT)


# Частота T-морфотипа в популяции

Prop_T <- myt2 %>% group_by(pop) %>% summarise(Prop_T = mean(ind))

myt2 <- merge(myt2, Prop_T)


# Подразделяем данные на три сабсета

myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "fresh"] <- "BL" 
myt2$Subset[myt2$sea == "barents" & myt2$sal_place == "normal"] <- "BH" 
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "normal"] <- "W" 
myt2$Subset[myt2$sea == "white" & myt2$sal_place == "fresh"] <- "W" 

myt2$Subset <- factor(myt2$Subset, levels = c("W", "BL", "BH"))

# 
#Оставляем только данные, на основе, которых строится модель

# myt3 <- myt2[myt2$dataset == "testing", ]
# 
# myt2 <- myt2[myt2$dataset == "training", ]


# Извлекаем из беломорского материала тестовую выборку 
#В формальную тестовую выборку  попадают точки наиболее близкие к 20%, 40%, 60% и 80% freq_MT

# selected_pop <- myt2[myt2$Subset == "W", ] %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT)) %>% group_by(Subset) %>% arrange(freq_MT, .by_group = TRUE) %>% mutate(dif_20 = (freq_MT - 0.2)^2, dif_40 = (freq_MT - 0.4)^2, dif_60 = (freq_MT - 0.6)^2, dif_80 = (freq_MT - 0.8)^2)  %>% group_by(Subset)  %>% summarize (n_pop =n(), q_20_pop = nth(pop, which.min(dif_20)), q_40_pop = nth(pop, which.min(dif_40)), q_60_pop = nth(pop, which.min(dif_60)), q_80_pop = nth(pop, which.min(dif_80))) 
  
  


# selected_pop <- melt(selected_pop, id.vars = c("Subset", "n_pop"))$value




# myt4 <- myt2[myt2$pop %in% selected_pop, ] #новый testing dataset for the White sea

# myt3 <- rbind(myt3, myt4)

# myt2 <- myt2[!(myt2$pop %in% selected_pop), ] #новый modelling dataset

```


```{r}
# Таблица с характеристиками тестинговых данных
# myt3_print <- myt3 %>% group_by(Subset, pop) %>% summarise(N_Tm_T = sum(morph == "T_m" & Sp == "M.trossulus"), N_Em_T = sum(morph == "E_m" & Sp == "M.trossulus"), N_Tm_E = sum(morph == "T_m" & Sp == "M.edulis"), N_Em_E = sum(morph == "E_m" & Sp == "M.edulis"), Ptros = round(mean(Sp == "M.trossulus"), 2 ))

# myt3_print_out <- flextable(
#   myt3_print, 
#   col_keys = c("Subset",	"Population",	"N_Tm_T",	"N_Em_T",	"N_Tm_E",	"N_Em_E",	"Ptros"))



# kable(myt3_print)
# myt3_print_out
```

```{r}
# Таблица с характеристиками моделлинговых данных
myt2_print <- myt2 %>% group_by(Subset, pop) %>% summarise(N_Tm_T = sum(morph == "T_m" & Sp == "M.trossulus"), N_Em_T = sum(morph == "E_m" & Sp == "M.trossulus"), N_Tm_E = sum(morph == "T_m" & Sp == "M.edulis"), N_Em_E = sum(morph == "E_m" & Sp == "M.edulis"), Ptros = round(mean(Sp == "M.trossulus"), 2 ))

# kable(myt2_print)
```




```{r}

# Функция для вычисления P_T_MT и P_T_ME в заданном датасете (БУБЛИК) ####
donat <- function(df){
  P_MT <- sum(df$Sp == "M.trossulus")
  P_T_MT <- sum(df$Sp == "M.trossulus" & df$morph == "T_m")/P_MT
  
  P_ME <- sum(df$Sp == "M.edulis")
  P_T_ME <- sum(df$Sp == "M.edulis" & df$morph == "T_m")/P_ME
  c(P_T_MT, P_T_ME)
}




########################################3

#Функция для "ленивого" калькулятора №1 который строит зависимость Ptros от P_T  

# На входе параметры бублика

calc1 <- function(P_T_MT, P_T_ME){
  result <- data.frame(P_T = seq(0, 1, 0.01))
  result$Ptros <- (result$P_T - P_T_ME)/(P_T_MT - P_T_ME)
  result <- result[result$P_T <= P_T_MT & result$P_T >= P_T_ME, ]
  result
}



# Функция для вычисления баесовских вероятностей по данным из бублика

calc2 <- function(P_T_MT, P_T_ME){
  result <- data.frame(freq_MT = seq(0, 1, 0.01))
  result$P_MT_T <- (P_T_MT * result$freq_MT)/(P_T_MT * result$freq_MT + P_T_ME*(1-result$freq_MT))
  result$P_ME_E <- ((1 - P_T_ME) * (1 - result$freq_MT))/(1 - P_T_ME + result$freq_MT * (P_T_ME - P_T_MT))
  result
}


########################################3


# Фунция для определения похожести между эмпирическим и теоретическими моделями для МОДЕЛИ 5 (Ptros vs P_T)



perms2 <- function(df = myt2[myt2$Subset == "W", ], regr_model = Model_5_final,...) {
  require(dplyr)
  df$pop <- as.character(df$pop)
  perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
  perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
  perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
  
  perm_pairs$First <- as.character(perm_pairs$First)
  perm_pairs$Second <- as.character(perm_pairs$Second)
  perm_pairs$Delta <- NA
  for(i in 1:nrow(perm_pairs)){
    df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),] 
    
    means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
    
    perm_pairs$Delta[i] <- 
      min(c(means$freq_MT[1],means$freq_MT[2])) *(1 - max(c(means$freq_MT[1],means$freq_MT[2]))) +
      max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2]))) 
    
    W <- donat(df_selected)
    
    calc1_predict_W <- calc1(W[1], W[2])
    
    names(calc1_predict_W) <- c("Prop_T", "Ptros_predicted" )
    
    Model_prediction <- expand.grid(Subset = unique(df_selected$Subset), Prop_T = seq(0, 1, 0.01))
    
    Model_prediction$Predict <- predict(regr_model, newdata = Model_prediction, type = "response")
    
    all_prediction <- merge(calc1_predict_W, Model_prediction, by = c("Prop_T"))
    
    perm_pairs$Goodness[i] <- 1/(mean((all_prediction$Predict - all_prediction$Ptros_predicted)^2))
    
  }
  perm_pairs
}



# Фунция для определения похожести между эмпирическим и теоретическими моделями для МОДЕЛИ 5 (Ptros vs P_T) НО калибровочные вборки взяты по степени различия между частотой T-морфотипа


perms2_T <- function(df = myt2[myt2$Subset == "W", ], regr_model = Model_5_final,...) {
  require(dplyr)
  df$pop <- as.character(df$pop)
  perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
  perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
  perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
  
  perm_pairs$First <- as.character(perm_pairs$First)
  perm_pairs$Second <- as.character(perm_pairs$Second)
  perm_pairs$Delta <- NA
  for(i in 1:nrow(perm_pairs)){
    df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),] 
    
    means <- df_selected %>% group_by(pop) %>% summarise(freq_T = mean(Prop_T))
    
    perm_pairs$Delta[i] <- 
      min(c(means$freq_T[1],means$freq_T[2])) *(1 - max(c(means$freq_T[1],means$freq_T[2]))) +
      max(c(means$freq_T[1],means$freq_T[2])) *(1 - min(c(means$freq_T[1],means$freq_T[2]))) 
    
    W <- donat(df_selected)
    
    calc1_predict_W <- calc1(W[1], W[2])
    
    names(calc1_predict_W) <- c("Prop_T", "Ptros_predicted" )
    
    Model_prediction <- expand.grid(Subset = unique(df_selected$Subset), Prop_T = seq(0, 1, 0.01))
    
    Model_prediction$Predict <- predict(regr_model, newdata = Model_prediction, type = "response")
    
    all_prediction <- merge(calc1_predict_W, Model_prediction, by = c("Prop_T"))
    
    perm_pairs$Goodness[i] <- 1/(mean((all_prediction$Predict - all_prediction$Ptros_predicted)^2))
    
  }
  perm_pairs
}





# Фунция для определения похожести между эмпирическими и теоретическими моделями для МОДЕЛИ 4 (Congr vs Ptros; Morph)
perms4 <- function(df = myt2[myt2$Subset == "W"], regr_model =  Model_4_final, ...) {
  require(dplyr)
  df$pop <- as.character(df$pop)
  perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
  perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
  perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]  
  
  perm_pairs$First <- as.character(perm_pairs$First)
  perm_pairs$Second <- as.character(perm_pairs$Second)
  perm_pairs$Delta <- NA
  for(i in 1:nrow(perm_pairs)){
    df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),] 
    
    means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
    # perm_pairs$Delta[i] <- abs(means$freq_MT[1] - means$freq_MT[2])
    perm_pairs$Delta[i] <- 
      min(c(means$freq_MT[1],means$freq_MT[2])) *(1 - max(c(means$freq_MT[1],means$freq_MT[2]))) + 
      max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2])))
    W <- donat(df_selected)
    
    calc2_predict_W <- calc2(W[1], W[2])
    names(calc2_predict_W) <- c("freq_MT", "T_m",  "E_m")
    
    calc2_predict_W <- melt(calc2_predict_W, id.vars = "freq_MT" )
    names(calc2_predict_W) <- c("freq_MT", "morph", "Bayes_predict") 
    
    Model_prediction <- expand.grid(Subset = unique(df_selected$Subset),  morph = levels(df_selected$morph), freq_MT = seq(0, 1, 0.01))
    
    Model_prediction$Predict <- predict(regr_model, newdata = Model_prediction, type = "response",  re.form = NA )
    
    all_prediction <- merge(calc2_predict_W, Model_prediction, by = c("freq_MT", "morph"))
    
    
    perm_pairs$Goodness[i] <- 1/mean((all_prediction$Bayes_predict - all_prediction$Predict)^2, na.rm = T)
    perm_pairs$pop[i] <- unique(as.character(df_selected$pop))
    
  }
  perm_pairs
}




# Фунция для определения похожести между эмпирическими и теоретическими моделями для МОДЕЛИ 4 (Congr vs Ptros; Morph) но в качестве калибровочных рассматриваются выборки с наиболее смешаннойчастотой T-морфотипа

perms4_T <- function(df = myt2[myt2$Subset == "W"], regr_model =  Model_4_final, ...) {
  require(dplyr)
  df$pop <- as.character(df$pop)
  perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
  perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
  perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]  
  
  perm_pairs$First <- as.character(perm_pairs$First)
  perm_pairs$Second <- as.character(perm_pairs$Second)
  perm_pairs$Delta <- NA
  for(i in 1:nrow(perm_pairs)){
    df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),] 
    
    means <- df_selected %>% group_by(pop) %>% summarise(freq_T = mean(Prop_T))
    # perm_pairs$Delta[i] <- abs(means$freq_MT[1] - means$freq_MT[2])
    perm_pairs$Delta[i] <- 
      min(c(means$freq_T[1],means$freq_T[2])) *(1 - max(c(means$freq_T[1],means$freq_T[2]))) + 
      max(c(means$freq_T[1],means$freq_T[2])) *(1 - min(c(means$freq_T[1],means$freq_T[2])))
    W <- donat(df_selected)
    
    calc2_predict_W <- calc2(W[1], W[2])
    names(calc2_predict_W) <- c("freq_MT", "T_m",  "E_m")
    
    calc2_predict_W <- melt(calc2_predict_W, id.vars = "freq_MT" )
    names(calc2_predict_W) <- c("freq_MT", "morph", "Bayes_predict") 
    
    Model_prediction <- expand.grid(Subset = unique(df_selected$Subset),  morph = levels(df_selected$morph), freq_MT = seq(0, 1, 0.01))
    
    Model_prediction$Predict <- predict(regr_model, newdata = Model_prediction, type = "response",  re.form = NA )
    
    all_prediction <- merge(calc2_predict_W, Model_prediction, by = c("freq_MT", "morph"))
    
    
    perm_pairs$Goodness[i] <- 1/mean((all_prediction$Bayes_predict - all_prediction$Predict)^2, na.rm = T)
    perm_pairs$pop[i] <- unique(as.character(df_selected$pop))
    
  }
  perm_pairs
}


## Функция для поиска ниболее различающихся выборок по генетической струкутре
max_dif <- function(df = myt2, Subset = "W", ...) {
  require(dplyr)
  df = df[df$Subset %in% Subset, ]
  df$pop <- as.character(df$pop)
  perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
  perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
  perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]  
  
  perm_pairs$First <- as.character(perm_pairs$First)
  perm_pairs$Second <- as.character(perm_pairs$Second)
  perm_pairs$Delta <- NA

  for(i in 1:nrow(perm_pairs)){
    df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),] 
    
    means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
    
    perm_pairs$Delta[i] <- 
      max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2]))) +
      min(c(means$freq_MT[1],means$freq_MT[2])) *(1 - max(c(means$freq_MT[1],means$freq_MT[2])))
  }
  max_dif <- perm_pairs[which.max(perm_pairs$Delta), ]
  c(max_dif$First, max_dif$Second)
}



## Функция для поиска ниболее различающихся выборок по частоте T-морфотипа
max_dif_T <- function(df = myt2, Subset = "W", ...) {
  require(dplyr)
  df = df[df$Subset %in% Subset, ]
  df$pop <- as.character(df$pop)
  perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
  perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
  perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]  
  
  perm_pairs$First <- as.character(perm_pairs$First)
  perm_pairs$Second <- as.character(perm_pairs$Second)
  perm_pairs$Delta <- NA

  for(i in 1:nrow(perm_pairs)){
    df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),] 
    
    means <- df_selected %>% group_by(pop) %>% summarise(freq_T = mean(Prop_T))
    
    perm_pairs$Delta[i] <- 
      max(c(means$freq_T[1],means$freq_T[2])) *(1 - min(c(means$freq_T[1],means$freq_T[2]))) +
      min(c(means$freq_T[1],means$freq_T[2])) *(1 - max(c(means$freq_T[1],means$freq_T[2])))
  }
  max_dif <- perm_pairs[which.max(perm_pairs$Delta), ]
  c(max_dif$First, max_dif$Second)
}



# Функция для поиска выборок наиболее смешанных по генетической структуре

max_mix <- function(df = myt2, Subset = "W", ...) {
  require(dplyr)
  df = df[df$Subset %in% Subset, ]
  df$pop <- as.character(df$pop)
  perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
  perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
  perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
    
  perm_pairs$First <- as.character(perm_pairs$First)
  perm_pairs$Second <- as.character(perm_pairs$Second)
  perm_pairs$Delta <- NA

  for(i in 1:nrow(perm_pairs)){
    df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),] 
    
    means <- df_selected %>% group_by(pop) %>% summarise(freq_MT = mean(freq_MT))
    
    perm_pairs$Delta[i] <- 
      max(c(means$freq_MT[1],means$freq_MT[2])) *(1 - min(c(means$freq_MT[1],means$freq_MT[2]))) + 
      min(c(means$freq_MT[1],means$freq_MT[2])) *(1 - max(c(means$freq_MT[1],means$freq_MT[2])))
    
  }
  
  max_mix <- perm_pairs[which.min(abs(perm_pairs$Delta - 0.5)), ]
  c(max_mix$First, max_mix$Second)
}



# Функция для поиска выборок наиболее смешанных по частоте T-морфотипа

max_mix_T <- function(df = myt2, Subset = "W", ...) {
  require(dplyr)
  df = df[df$Subset %in% Subset, ]
  df$pop <- as.character(df$pop)
  perm_pairs <- expand.grid(First = unique(df$pop), Second = unique(df$pop))
  perm_pairs <- perm_pairs[perm_pairs$First != perm_pairs$Second,]
  perm_pairs <- perm_pairs[perm_pairs$Second != perm_pairs$First,]
    
  perm_pairs$First <- as.character(perm_pairs$First)
  perm_pairs$Second <- as.character(perm_pairs$Second)
  perm_pairs$Delta <- NA

  for(i in 1:nrow(perm_pairs)){
    df_selected <- df[df$pop %in% c(perm_pairs$First[i], perm_pairs$Second[i]),] 
    
    means <- df_selected %>% group_by(pop) %>% summarise(freq_T = mean(Prop_T))
    
    perm_pairs$Delta[i] <- 
      max(c(means$freq_T[1],means$freq_T[2])) *(1 - min(c(means$freq_T[1],means$freq_T[2]))) + 
      min(c(means$freq_T[1],means$freq_T[2])) *(1 - max(c(means$freq_T[1],means$freq_T[2])))
    
  }
  
  max_mix <- perm_pairs[which.min(abs(perm_pairs$Delta - 0.5)), ]
  c(max_mix$First, max_mix$Second)
}






### Функция для описания структуры калибровочных выборок

calib_str <- function(df = myt2, pop1, pop2){
  df =df[df$pop %in% c(pop1, pop2), ]
  df$Subset <- factor(df$Subset)
  str_calib <- df %>% group_by(pop, Subset) %>% summarize(N_E = sum(Sp == "M.edulis"), N_T = sum(Sp ==  "M.trossulus"), P_T_ME = mean(Sp == "M.edulis" & morph == "T_m"), P_T_MT = mean(Sp == "M.trossulus" & morph == "T_m"), Ptros = mean(freq_MT) )
  str_calib
}




########################################

# Функция для обратной трансформации логитов
logit_back <- function(x) exp(x)/(1 + exp(x)) # обратная логит-трансформация



# Функция для оценки сверхдисперсии в моделях GLM

overdisp_fun <- function(model) {
  rdf <- df.residual(model)  # Число степеней свободы N - p
  if (inherits(model, 'negbin')) rdf <- rdf - 1 ## учитываем k в NegBin GLMM
  rp <- residuals(model,type='pearson') # Пирсоновские остатки
  Pearson.chisq <- sum(rp^2) # Сумма квадратов остатков, подчиняется Хи-квадрат распределению
  prat <- Pearson.chisq/rdf  # Отношение суммы квадратов остатков к числу степеней свободы
  pval <- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE) # Уровень значимости
  c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p=pval)        # Вывод результатов
}





```


```{r}
##### Theme for ggplot ######
theme_set(theme_bw() + theme(axis.title.x = element_text(size = 10), axis.title.y = element_text(size = 10), axis.text= element_text(size = 10), legend.position = "none" , title = element_text(size = 10)))  

```





<!-- ## Associations among morphotypes and species-specific genotypes around Kola Peninsular  -->


```{r}

# # Model 1. P_T ~ Ptros*subset (GLM)
# 
# # Model 2. P_T ~ Ptros*subset*Sp (GLMM)
# 
# # Model 3. Accuracy ~ Ptros*subset (GLM)
# 
# # Model 4. Congr ~ Ptros*subset*Morph (GLMM, probit)
# 
# # Model 5. Ptros ~ P_T*subset (GLM)
# 
# 
# 
# 
# #Модель 1 ###################################################
# 
# 
# Model_1_full <- glm(ind ~  freq_MT * Subset, data = myt2, family = binomial(link = "logit"))
# 
# 
# # overdisp_fun(Model_1_full)
# # drop1(Model_1_full, test = "Chi")
# 
# # Model_1_1 <- update(Model_1_full, . ~ . - freq_MT:Subset)
# # drop1(Model_1_1, test = "Chi")
# 
# 
# 
# Model_1_final <- Model_1_full 
# 
# Model_1_final_summary <- tidy(Model_1_final)
# 
# Model_1_R2 <- r.squaredGLMM(Model_1_final)[1,1]
# 
# 
# 
# 
# 
# 
# #Модель 2 ######################################
# 
# Model_2_full <- glmer(ind ~  freq_MT * Subset * Sp + (1|pop), data = myt2, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
# 
# #  overdisp_fun(Model_2_full)
# # drop1(Model_2_full, test = "Chi")
# 
# # Model_2_1 <- update(Model_2_full, . ~ . - freq_MT:Subset:Sp)
# 
# # drop1(Model_2_1, test = "Chi")
# 
# # Model_2_2 <- update(Model_2_1, . ~ . - freq_MT:Subset)
# # drop1(Model_2_2, test = "Chi")
# 
# # Model_2_3 <- update(Model_2_2, . ~ . - freq_MT:Sp)
# # drop1(Model_2_3, test = "Chi")
# 
# 
# Model_2_final <- Model_2_full
# #  overdisp_fun(Model_2_full)
# 
# 
# Model_2_final_summary <- tidy(Model_2_final)
# 
# Model_2_final_summary <- Model_2_final_summary[,!(names(Model_2_final_summary) %in% c("group"))]
# 
# Model_2_final_R2_m <- r.squaredGLMM(Model_2_final)[1,1]
# 
# Model_2_final_R2_c <- r.squaredGLMM(Model_2_final)[1, 2]
# 
# 
# 
# 
# #Модель 3 #####################################
# 
# 
# Model_3_full <- glm(congr ~ freq_MT*Subset, data = myt2, family = binomial(link = "logit"))
# # overdisp_fun(Model_3_full)
# 
# 
# # drop1(Model_3_full, test = "Chi")
# 
# Model_3_final <- Model_3_full
# 
# Model_3_final_summary <- tidy(Model_3_final)
# 
# 
# Model_3_R2 <- r.squaredGLMM(Model_3_final)[1,1]
# 
# 
# 
# 
# #Модель 4 #####################################
# 
# Model_4_full <- glmer(congr ~ morph * freq_MT*Subset + (1 | pop), data = myt2, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
# # overdisp_fun(Model_4_full)
# 
# 
# # drop1(Model_4_full, test = "Chi")
# 
# 
# # Model_4_1 <- update(Model_4_full, .~.-morph:freq_MT:Subset )
# 
# # drop1(Model_4_1, test = "Chi")
# 
# # Model_4_2 <- update(Model_4_1, .~.- freq_MT:Subset )
# # drop1(Model_4_2, test = "Chi")
# 
# 
# Model_4_final <- Model_4_full
# # overdisp_fun(Model_4_final)
# 
# 
# 
# Model_4_final_summary <- tidy(Model_4_final)
# 
# 
# Model_4_final_summary <- Model_4_final_summary[,!(names(Model_4_final_summary) %in% c("group"))]
# 
# Model_4_final_R2_m <- r.squaredGLMM(Model_4_final)[1,1]
# 
# Model_4_final_R2_c <- r.squaredGLMM(Model_4_final)[1, 2]
# 
# 
# #Модель 5 #####################################
# 
# 
# ptop_T_MT <- myt2 %>% group_by(Subset, pop) %>% summarize(Prop_T = mean(Prop_T), MT = sum(Sp2), N = n())
# 
# 
# Model_5_full <- glm(cbind(MT, (N-MT)) ~  Prop_T * Subset, data = ptop_T_MT, family = binomial(link = "logit"))
# 
# 
# # Model_5_full <- glm(Sp2 ~  Prop_T * Subset, data = myt2, family = binomial(link = "logit"))
# # overdisp_fun(Model_5_full)
# 
# # drop1(Model_5_full, test = "Chi")
# 
# # Model_5_1 <- update(Model_5_full, . ~ . - Prop_T:Subset)
# 
# # drop1(Model_5_1, test = "Chi")
# 
# Model_5_final <- Model_5_full
# 
# Model_5_final_summary <- tidy(Model_5_final)
# 
# Model_5_R2 <- r.squaredGLMM(Model_5_final)[1,1]
# 

```




```{r}

# Модели для всех географических выделов ####################


# Model 6. Congr ~ Ptros*subset*Morph (GLMM, probit) for WBL, BH, GOM, BALT

# Model 7. Ptros ~ P_T*subset (GLM) for WBL, BH, GOM, BALT




#### Data reading and initial preparation #####

myt <- read.table("data_salinity3.csv", header = T, sep = ",")

# Оставляем только мидий, у которых есть оценка морфотипа
myt2_all <- myt[!is.na(myt$ind), ]



### Объединяем популяции в данных Сары #####
# myt2_all$pop2 <- myt2_all$pop
# 
# myt2_all$pop[myt2_all$pop %in% c("CBCP", "CBSC")] <- "CB"
# 
# myt2_all$pop[myt2_all$pop %in% c("MDRE",   "MDRW")] <- "MDR"


# Подразделяем данные на сабсеты

myt2_all$Subset[myt2_all$sea == "barents" & myt2_all$sal_place == "fresh"] <- "WBL" 
myt2_all$Subset[myt2_all$sea == "barents" & myt2_all$sal_place == "normal"] <- "BH" 
myt2_all$Subset[myt2_all$sea == "white" & myt2_all$sal_place == "normal"] <- "WBL" 
myt2_all$Subset[myt2_all$sea == "white" & myt2_all$sal_place == "fresh"] <- "WBL" 

myt2_all$Subset[myt2_all$sea == "Baltic"] <- "BALT" 
myt2_all$Subset[myt2_all$sea == "GOM"] <- "GOM" 
myt2_all$Subset[myt2_all$sea == "Norway"] <- "NORW" 
myt2_all$Subset[myt2_all$sea == "Scotland"] <- "SCOT" 


myt2_all$Subset <- factor(myt2_all$Subset, levels = c("WBL", "BH", "NORW", "BALT", "SCOT", "GOM" ))




# Вводим обозначения 

myt2_all$Sp [myt2_all$str > 0.5] <- "M.trossulus" #Лучше обозначать так!
myt2_all$Sp [myt2_all$str <= 0.5] <- "M.edulis"
myt2_all$Sp <- factor(myt2_all$Sp)



# Вводим обозначения для морфотипов
myt2_all$morph <- ifelse(myt2_all$ind == 1, "T_m", "E_m")
myt2_all$morph <- factor(myt2_all$morph)



# Бинарное обозначение видов
myt2_all$Sp2 <- ifelse(myt2_all$Sp == "M.trossulus", 1, 0)


#Correct identification
myt2_all$congr <- ifelse((myt2_all$ind == 1 & myt2_all$Sp == "M.trossulus") | (myt2_all$ind == 0 & myt2_all$Sp == "M.edulis"), 1, 0   )




# Частота M.trossulus в популяции

freq_MT <- myt2_all %>% group_by(pop) %>% summarise(freq_MT = mean(Sp2))

myt2_all <- merge(myt2_all, freq_MT)


# Частота T-морфотипа в популяции

Prop_T <- myt2_all %>% group_by(pop) %>% summarise(Prop_T = mean(ind))

myt2_all <- merge(myt2_all, Prop_T)


# Разделяем на тестовые и моделинговые датасеты


# 
# # Извлекаем из беломорского материала тестовую выборку 
# #В формальную тестовую выборку  попадают точки наиболее близкие к 20%, 40%, 60% и 80% freq_MT
# 
# selected_pop <- myt2_all[myt2_all$Subset == "W", ] %>% group_by(Subset, pop) %>% summarise(freq_MT = mean(freq_MT)) %>% group_by(Subset) %>% arrange(freq_MT, .by_group = TRUE) %>% mutate(dif_20 = (freq_MT - 0.2)^2, dif_40 = (freq_MT - 0.4)^2, dif_60 = (freq_MT - 0.6)^2, dif_80 = (freq_MT - 0.8)^2)  %>% group_by(Subset)  %>% summarize (n_pop =n(), q_20_pop = nth(pop, which.min(dif_20)), q_40_pop = nth(pop, which.min(dif_40)), q_60_pop = nth(pop, which.min(dif_60)), q_80_pop = nth(pop, which.min(dif_80))) 
# 
# selected_pop <- melt(selected_pop, id.vars = c("Subset", "n_pop"))$value
# 


# testing data set
# myt3_all <- myt2_all[myt2_all$dataset == "testing" | myt2_all$pop %in% c("kovda", "rya", "chupa", "umba_pil"),  ]

# myt3_all$pop2 <- myt3_all$pop


#modelling data set
# myt2_all <- myt2_all[! myt2_all$pop %in% unique(myt3$pop), ]






# Модели для сравнения geographical datasets 

myt2_reduced <- myt2_all[myt2_all$Subset %in% c("WBL", "BH", "GOM", "BALT", "NORW"), ]

# unique(myt2_reduced$Subset)

myt2_reduced$Subset <- factor(myt2_reduced$Subset, levels = c("WBL",  "BH",   "GOM",  "BALT", "NORW"))



# levels(myt2_reduced$Subset)


# Model 6 #####################

# 
# library(optimx)
# 
# Model_6_full_geogr <- glmer(congr ~ morph * freq_MT * Subset + (1 | pop), data = myt2_reduced, family = binomial(link = "logit"), control=glmerControl(optimizer = "optimx", calc.derivs = FALSE, optCtrl = list(method = "nlminb", starttests = FALSE, kkt = FALSE)))
# 
# 
# 
# # Model_6_full_geogr <- glmer(congr ~ morph * freq_MT * Subset + (1 | pop), data = myt2_reduced, family = binomial(link = "logit"))
# 
# 
# 
# # overdisp_fun(Model_6_full_geogr)
# 
# # summary(Model_6_full_geogr)
# # 
# # r.squaredGLMM(Model_6_final)
# # 
# # drop1(Model_6_full_geogr, test = "Chi")
# 
# # Model_6_full_geogr2 <- update(Model_6_full_geogr, . ~ . - morph:freq_MT:Subset)
# 
# # drop1(Model_6_full_geogr2)
# 
# 
# Model_6_final <- Model_6_full_geogr 
# 
# 
# 
# Model_6_final_summary <- tidy(Model_6_final)
# 
# Model_6_final_summary <- Model_6_final_summary[,!(names(Model_6_final_summary) %in% c("group"))]
# 
# Model_6_final_R2_m <- r.squaredGLMM(Model_6_final)[1,1]
# 
# Model_6_final_R2_c <- r.squaredGLMM(Model_6_final)[1, 2]
# 
# 
# 
# 
# 
# # Model 7 #####################
# 
# ptop_T_MT <- myt2_reduced %>% group_by(Subset, pop) %>% summarize(Prop_T = mean(Prop_T), MT = sum(Sp2), N = n())
# 
# # ptop_T_MT <- ptop_T_MT[! ptop_T_MT$pop %in% c("Limh88", "CBCP"), ]
# 
# 
# Model_7_full <- glm(cbind(MT, (N-MT)) ~  Prop_T * Subset, data = ptop_T_MT, family = binomial(link = "logit"))
# 
# # 
# # Model_7_full <- glm(Sp2 ~  Prop_T * Subset, data = myt2_reduced, family = binomial(link = "logit"))
# #  overdisp_fun(Model_7_full)
# 
# # drop1(Model_7_full, test = "Chi")
# 
# # Model_7_1 <- update(Model_7_full, . ~ . - Prop_T:Subset)
# 
# # drop1(Model_7_1, test = "Chi")
# 
# Model_7_final <- Model_7_full 
# 
# Model_7_final_summary <- tidy(Model_7_final)
# 
# Model_7_final_R2 <- r.squaredGLMM(Model_7_final)[1,1]
# 
# 
# 
# # Model 8 #####################
# 
# Model_8_full <- glmer(ind ~  freq_MT * Subset * Sp + (1|pop), data = myt2_reduced, family = binomial(link = "logit"), control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
# 
# # overdisp_fun(Model_8_full)
# # drop1(Model_8_full, test = "Chi")
# 
#  # Model_8_1 <- update(Model_8_full, . ~ . - freq_MT:Subset:Sp)
# 
# # drop1(Model_8_1, test = "Chi")
# 
# # Model_2_2 <- update(Model_2_1, . ~ . - freq_MT:Subset)
# # drop1(Model_2_2, test = "Chi")
# 
# # Model_2_3 <- update(Model_2_2, . ~ . - freq_MT:Sp)
# # drop1(Model_2_3, test = "Chi")
# 
# 
# Model_8_final <- Model_8_full
# 
# Model_8_final_summary <- tidy(Model_8_final)
# 
# Model_8_final_summary <- Model_8_final_summary[,!(names(Model_8_final_summary) %in% c("group"))]
# 
# Model_8_final_R2_m <- r.squaredGLMM(Model_8_final)[1,1]
# 
# Model_8_final_R2_c <- r.squaredGLMM(Model_8_final)[1, 2]
# 
# 




```





<!-- Чанк приведенный ниже отчасти повторяет то, что было написано раньше, но здесь еще раз все пересчитывеам, чтобы не было сбоев -->
```{r}
## Calculator plot for all geographical areas 
## Калькулятор основан на калибровочных выборках, выбранных в соответствии с "правильной" стратегией. 



pops_max_dif_WBL <- max_dif(df = myt2_all, Subset = "WBL")
pops_max_dif_BH <- max_dif(df = myt2_all, Subset = "BH")
pops_max_dif_GOM <- max_dif(df = myt2_all, Subset = "GOM")
pops_max_dif_BALT <- max_dif(df = myt2_all, Subset = "BALT")
pops_max_dif_SCOT <- max_dif(df = myt2_all, Subset = "SCOT")
pops_max_dif_NORW <- max_dif(df = myt2_all, Subset = "NORW")


## Все то же самое, но выбор калибровочных популяций идет по наиболее различающейся частоте T-морфотипа
pops_max_dif_WBL_T <- max_dif_T(df = myt2_all, Subset = "WBL")
pops_max_dif_BH_T <- max_dif_T(df = myt2_all, Subset = "BH")
pops_max_dif_GOM_T <- max_dif_T(df = myt2_all, Subset = "GOM")
pops_max_dif_BALT_T <- max_dif_T(df = myt2_all, Subset = "BALT")
pops_max_dif_SCOT_T <- max_dif_T(df = myt2_all, Subset = "SCOT")
pops_max_dif_NORW_T <- max_dif_T(df = myt2_all, Subset = "NORW")



pops_max_mix_WBL <- max_mix(df = myt2_all, Subset = "WBL")
pops_max_mix_BH <- max_mix(df = myt2_all, Subset = "BH")
pops_max_mix_GOM <- max_mix(df = myt2_all, Subset = "GOM")
pops_max_mix_BALT <- max_mix(df = myt2_all, Subset = "BALT")
pops_max_mix_SCOT <- max_mix(df = myt2_all, Subset = "SCOT")
pops_max_mix_NORW <- max_mix(df = myt2_all, Subset = "NORW")

## Все то же самое, но выбор калибровочных популяций идет по наиболее смешанных по частоте T-морфотипа

pops_max_mix_WBL_T <- max_mix_T(df = myt2_all, Subset = "WBL")
pops_max_mix_BH_T <- max_mix_T(df = myt2_all, Subset = "BH")
pops_max_mix_GOM_T <- max_mix_T(df = myt2_all, Subset = "GOM")
pops_max_mix_BALT_T <- max_mix_T(df = myt2_all, Subset = "BALT")
pops_max_mix_SCOT_T <- max_mix_T(df = myt2_all, Subset = "SCOT")
pops_max_mix_NORW_T <- max_mix_T(df = myt2_all, Subset = "NORW")






# Бублики для наиболее смешанных популяций
donat_max_mix_WBL <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_WBL, ])
donat_max_mix_BH <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_BH, ])
donat_max_mix_GOM <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_GOM, ])
donat_max_mix_BALT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_BALT, ])

# donat_max_mix_SCOT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_SCOT, ])
donat_max_mix_NORW <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_NORW, ])

donat_max_mix_SCOT <- donat(myt2_all[myt2_all$Subset == "SCOT", ]) #При малом количесвте выборок бублик считаем по всем сборам
# donat_max_mix_NORW <- donat(df = myt2_all[myt2_all$Subset == "NORW", ]) #При малом количесвте выборок бублик считаем по всем сборам





# Бублики для наиболее смешанных популяций при калибровке по T-морфотипу
donat_max_mix_WBL_T <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_WBL_T, ])
donat_max_mix_BH_T <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_BH_T, ])
donat_max_mix_GOM_T <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_GOM_T, ])
donat_max_mix_BALT_T <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_BALT_T, ])

# donat_max_mix_SCOT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_SCOT, ])
donat_max_mix_NORW_T <- donat(df = myt2_all[myt2_all$pop %in% pops_max_mix_NORW_T, ])

donat_max_mix_SCOT_T <- donat(myt2_all[myt2_all$Subset == "SCOT", ]) #При малом количесвте выборок бублик считаем по всем сборам
# donat_max_mix_NORW <- donat(df = myt2_all[myt2_all$Subset == "NORW", ]) #При малом количесвте выборок бублик считаем по всем сборам




# Бублики для наиболее различных по стуртуре популяций
donat_max_dif_WBL <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_WBL, ])
donat_max_dif_BH <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_BH, ])
donat_max_dif_GOM <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_GOM, ])
donat_max_dif_BALT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_BALT, ])

# donat_max_dif_SCOT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_SCOT, ])
donat_max_dif_NORW <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_NORW, ])

donat_max_dif_SCOT <- donat(df = myt2_all[myt2_all$Subset == "SCOT", ]) #При малом количесвте выборок бублик считаем по всем сборам
# donat_max_dif_NORW <- donat(df = myt2_all[myt2_all$Subset == "NORW", ]) #При малом количесвте выборок бублик считаем по всем сборам



# Бублики для наиболее различных по стуртуре популяций при калибровке пр чатоте T-морфотипа
donat_max_dif_WBL_T <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_WBL_T, ])
donat_max_dif_BH_T <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_BH_T, ])
donat_max_dif_GOM_T <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_GOM_T, ])
donat_max_dif_BALT_T <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_BALT_T, ])

# donat_max_dif_SCOT <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_SCOT, ])
donat_max_dif_NORW_T <- donat(df = myt2_all[myt2_all$pop %in% pops_max_dif_NORW_T, ])

donat_max_dif_SCOT_T <- donat(df = myt2_all[myt2_all$Subset == "SCOT", ]) #При малом количесвте выборок бублик считаем по всем сборам
# donat_max_dif_NORW <- donat(df = myt2_all[myt2_all$Subset == "NORW", ]) #При малом количесвте выборок бублик считаем по всем сборам



#Предсказания калькулятора 2 на основе наиболее смешанных популяций
calc2_WBL_T <- calc2(donat_max_mix_WBL_T[1], donat_max_mix_WBL_T[2])
calc2_BH_T <- calc2(donat_max_mix_BH_T[1], donat_max_mix_BH_T[2])
calc2_GOM_T <- calc2(donat_max_mix_GOM_T[1], donat_max_mix_GOM_T[2])
calc2_BALT_T <- calc2(donat_max_mix_BALT_T[1], donat_max_mix_BALT_T[2])
calc2_SCOT_T <- calc2(donat_max_mix_SCOT_T[1], donat_max_mix_SCOT_T[2])
calc2_NORW_T <- calc2(donat_max_mix_NORW_T[1], donat_max_mix_NORW_T[2])


calc2_WBL_T$Subset <- "WBL"
calc2_BH_T$Subset <- "BH"
calc2_GOM_T$Subset <- "GOM"
calc2_BALT_T$Subset <- "BALT"
calc2_SCOT_T$Subset <- "SCOT"
calc2_NORW_T$Subset <- "NORW"

calc2_predictions_T <- rbind(calc2_WBL_T, calc2_BH_T, calc2_GOM_T, calc2_BALT_T, calc2_SCOT_T, calc2_NORW_T)

calc2_predictions_T$Subset <- factor(calc2_predictions_T$Subset, levels = levels(myt2_all$Subset))



#Предсказания калькулятора 1 на основе наиболее различных популяций



calc1_WBL_T <- calc1(donat_max_dif_WBL_T[1], donat_max_dif_WBL_T[2])
calc1_BH_T <- calc1(donat_max_dif_BH_T[1], donat_max_dif_BH_T[2])
calc1_GOM_T <- calc1(donat_max_dif_GOM_T[1], donat_max_dif_GOM_T[2])
calc1_BALT_T <- calc1(donat_max_dif_BALT_T[1], donat_max_dif_BALT_T[2])
calc1_SCOT_T <- calc1(donat_max_dif_SCOT_T[1], donat_max_dif_SCOT_T[2])
calc1_NORW_T <- calc1(donat_max_dif_NORW_T[1], donat_max_dif_NORW_T[2])


calc1_WBL_T$Subset <- "WBL"
calc1_BH_T$Subset <- "BH"
calc1_GOM_T$Subset <- "GOM"
calc1_BALT_T$Subset <- "BALT"
calc1_SCOT_T$Subset <- "SCOT"
calc1_NORW_T$Subset <- "NORW"

calc1_predictions_T <- rbind(calc1_WBL_T, calc1_BH_T, calc1_GOM_T, calc1_BALT_T, calc1_SCOT_T, calc1_NORW_T)

calc1_predictions_T$Subset <- factor(calc1_predictions_T$Subset, levels = levels(myt2_all$Subset))


```




<!-- ```{r} -->

<!-- Pl_mod6_with_initial_data_teor_calc2_T <- Pl_mod6_with_initial_data +  -->
<!--   geom_line(data = calc2_predictions_T, aes(x = freq_MT, y = P_MT_T), color = "red") +  -->
<!--   geom_line(data = calc2_predictions_T, aes(x = freq_MT, y = P_ME_E), color = "blue") -->


<!-- Pl_mod7_with_initial_data_teor_calc1_T <- Pl_mod7_with_initial_data  + -->
<!--   geom_line(data = calc1_predictions_T, aes(x = P_T, y = Ptros), color = "darkgray", size = 1) -->

<!-- ``` -->




<!-- ```{r, fig.height=9} -->
<!-- grid.arrange(Pl_mod7_with_initial_data_teor_calc1_T, Pl_mod8_with_initial_data,  Pl_mod6_with_initial_data_teor_calc2_T, ncol =3)  -->
<!-- ``` -->







```{r}
Eq3 <- function(PT, donat){
  P_T_edu <- donat[2]
  P_T_tros <- donat[1]
  b1 <- 1/(P_T_tros - P_T_edu)
  b0 <- b1*P_T_edu
  
  # predictor <- b1*PT - b0
  # 
  # Ptros <- exp(predictor)/(1 + exp(predictor))  
  
  Ptros = (PT - P_T_edu)/ ((P_T_tros) -  P_T_edu)
  Ptros <- ifelse(Ptros <0 | Ptros >1 , NA, Ptros)
  Ptros
}
  


Eq1 <- function(Ptros, donat){
  P_T_MT <- donat[1]
  P_T_ME <- donat[2]
  P_MT_T <- (P_T_MT * Ptros)/(P_T_MT * Ptros + P_T_ME*(1-Ptros))
  P_MT_T
}


Eq2 <- function(Ptros, donat){
  P_T_MT <- donat[1]
  P_T_ME <- donat[2]
  P_ME_E <- ((1 - P_T_ME) * (1 - Ptros))/(1 - P_T_ME + Ptros * (P_T_ME - P_T_MT))
  P_ME_E
}


  

# Предсказания по уравнениям, для случая, когда в качестве калибровочных выборок берутся максимально различные и мексимально смешанные выборки по частоте M.trossulus 

predict_obs_Eq123 <- function(Set){
df <- myt2_all %>% filter(Subset == Set) %>% group_by(pop) %>% summarise(PT = mean(ind == 1), Ptros_obs = mean(Sp == "M.trossulus")) %>% 
  mutate(Ptros_Eq3 = Eq3(PT, get(paste("donat_max_dif_", Set, sep = "" ))),
         P_MT_T_Eq1 = Eq1(Ptros_Eq3, get(paste("donat_max_mix_", Set, sep = "" ))), 
         P_ME_E_Eq2 = Eq2(Ptros_Eq3, get(paste("donat_max_mix_", Set, sep = "" ))))


df2 <- myt2_all %>% filter(Subset == Set, morph == "T_m") %>% group_by(pop) %>% summarise(P_MT_T_obs = mean(ind == 1 & Sp == "M.trossulus")) 

df3 <- myt2_all %>% filter(Subset == Set, morph == "E_m") %>% group_by(pop) %>% summarise(P_ME_E_obs = mean(ind == 0 & Sp == "M.edulis")) 

dd <- merge(df, df2, all = T)
ddd <- merge(dd, df3, all = T)

df_final <- ddd %>% select(pop, PT, Ptros_obs, P_MT_T_obs, P_ME_E_obs, Ptros_Eq3, P_MT_T_Eq1, P_ME_E_Eq2 )


df_final$max_mix <- 0

df_final$max_dif <- 0

max_dif_pop <- max_dif(df = myt2_all, Subset = Set)
max_mix_pop <- max_mix(df = myt2_all, Subset = Set)

df_final$max_dif [df_final$pop %in% max_dif_pop] <- 1

df_final$max_mix [df_final$pop %in% max_mix_pop] <- 1
df_final$Set = Set

Pl_Eq3 <- ggplot(df_final, aes(y = Ptros_Eq3, x =  Ptros_obs)) + geom_point() + geom_abline() 
Pl_Eq1 <- ggplot(df_final, aes(y = P_MT_T_Eq1, x = P_MT_T_obs )) + geom_point() + geom_abline() 
Pl_Eq2 <- ggplot(df_final, aes(y = P_ME_E_Eq2, x = P_ME_E_obs )) + geom_point() + geom_abline() 


result <- list(df_final, Pl_Eq3, Pl_Eq1, Pl_Eq2)
result
}
  
  





# Предсказания по уравнениям, для случая, когда в качестве калибровочных выборок берутся максимально различные и мексимально смешанные выборки по частоте T-морфотипа 


predict_obs_Eq123_T <- function(Set){
  pop_max_diff <- max_dif_T(df = myt2_all, Subset = Set)
  donat_max_diff <- donat(df = myt2_all[myt2_all$pop %in% pop_max_diff, ])
  
  pop_max_mix <- max_mix_T(df = myt2_all, Subset = Set)
  donat_max_mix <- donat(df = myt2_all[myt2_all$pop %in% pop_max_mix, ])
  
  donat_all <- donat(df = myt2_all[myt2_all$Subset == Set, ])
  
  
  df <- myt2_all %>% filter(Subset == Set) %>% group_by(pop) %>% summarise(PT = mean(ind == 1), Ptros_obs = mean(Sp == "M.trossulus"), N_edu = sum(Sp == "M.edulis"), N_tros = sum(Sp == "M.trossulus"), Set = unique(Subset)) %>% 
  mutate(Ptros_Eq3_diff = Eq3(PT, donat_max_diff),
         Ptros_Eq3_mix = Eq3(PT, donat_max_mix), 
         Ptros_Eq3_all = Eq3(PT, donat_all),
         
         P_MT_T_Eq1_diff_diff = Eq1(Ptros_Eq3_diff, donat_max_diff),
         P_MT_T_Eq1_diff_mix = Eq1(Ptros_Eq3_diff, donat_max_mix),
         P_MT_T_Eq1_diff_all = Eq1(Ptros_Eq3_diff, donat_all),
         
         P_MT_T_Eq1_mix_diff = Eq1(Ptros_Eq3_mix, donat_max_diff),
         P_MT_T_Eq1_mix_mix = Eq1(Ptros_Eq3_mix, donat_max_mix),
         P_MT_T_Eq1_mix_all = Eq1(Ptros_Eq3_mix, donat_all),
         
         P_MT_T_Eq1_all_diff = Eq1(Ptros_Eq3_all, donat_max_diff),
         P_MT_T_Eq1_all_mix = Eq1(Ptros_Eq3_all, donat_max_mix),
         P_MT_T_Eq1_all_all = Eq1(Ptros_Eq3_all, donat_all),
         

         
         P_ME_E_Eq2_diff_diff = Eq2(Ptros_Eq3_diff, donat_max_diff),
         P_ME_E_Eq2_diff_mix = Eq2(Ptros_Eq3_diff, donat_max_mix),
         P_ME_E_Eq2_diff_all = Eq2(Ptros_Eq3_diff, donat_all),
         
         P_ME_E_Eq2_mix_diff = Eq2(Ptros_Eq3_mix, donat_max_diff),
         P_ME_E_Eq2_mix_mix = Eq2(Ptros_Eq3_mix, donat_max_mix),
         P_ME_E_Eq2_mix_all = Eq2(Ptros_Eq3_mix, donat_all),
         
         P_ME_E_Eq2_all_diff = Eq2(Ptros_Eq3_all, donat_max_diff),
         P_ME_E_Eq2_all_mix = Eq2(Ptros_Eq3_all, donat_max_mix),
         P_ME_E_Eq2_all_all = Eq2(Ptros_Eq3_all, donat_all))


df2 <- myt2_all %>% filter(Subset == Set, morph == "T_m") %>% group_by(pop) %>% summarise(P_MT_T_obs = mean(ind == 1 & Sp == "M.trossulus")) 

df3 <- myt2_all %>% filter(Subset == Set, morph == "E_m") %>% group_by(pop) %>% summarise(P_ME_E_obs = mean(ind == 0 & Sp == "M.edulis")) 

dd <- merge(df, df2, all = T)
ddd <- merge(dd, df3, all = T)

df_final <- ddd 


df_final$max_mix <- 0

df_final$max_dif <- 0

max_dif_pop <- max_dif_T(df = myt2_all, Subset = Set)
max_mix_pop <- max_mix_T(df = myt2_all, Subset = Set)

df_final$max_dif [df_final$pop %in% max_dif_pop] <- 1

df_final$max_mix [df_final$pop %in% max_mix_pop] <- 1
df_final$Set = Set
result <- df_final
result
}





WBL <- as.data.frame(predict_obs_Eq123("WBL")[1])
BH <-  as.data.frame(predict_obs_Eq123("BH")[1])
GOM <- as.data.frame(predict_obs_Eq123("GOM")[1])
BALT <- as.data.frame(predict_obs_Eq123("BALT")[1])
NORW <- as.data.frame(predict_obs_Eq123("NORW")[1])


WBL_T <- as.data.frame(predict_obs_Eq123_T("WBL"))
BH_T <-  as.data.frame(predict_obs_Eq123_T("BH"))
GOM_T <- as.data.frame(predict_obs_Eq123_T("GOM"))
BALT_T <- as.data.frame(predict_obs_Eq123_T("BALT"))
NORW_T <- as.data.frame(predict_obs_Eq123_T("NORW"))


all_obs_predict <- rbind(WBL, BH, GOM, BALT, NORW)
all_obs_predict_T <- rbind(WBL_T, BH_T, GOM_T, BALT_T, NORW_T)


```


<br>
<br>
<br>
<br>





```{r, fig.width=10, fig.height=10}
# ggplot(all_obs_predict, aes(x = Ptros_obs, y = Ptros_Eq3, shape = Set)) + geom_point(size = 4) + geom_abline() + theme(legend.position = "bottom") + labs(x = "Ptros Observed", y = "Ptros predicted by Eq3") 

# logist <- function(x)exp(x)/(1+exp(x))
# unlogist <- function(x)exp(x)/(1+exp(x))


 
options(scipen = 10, digits=5)

Pl_Eq3 <- all_obs_predict_T %>%  ggplot(aes(x = Ptros_obs, shape = Set)) + geom_point(size = 3)  + theme(legend.position = "bottom")   + geom_abline()  



Pl_Eq3_diff <- Pl_Eq3 + aes(y = Ptros_Eq3_diff) +  ggtitle(paste("Stat =", all_obs_predict_T %>%  filter(!is.na(Ptros_Eq3_diff)) %>% summarise(Stat =  sum(abs(Ptros_obs - Ptros_Eq3_diff)/(Ptros_obs + Ptros_Eq3_diff))) %>% round(., 4)))+ guides(shape = "none", color = "none") + xlim(0,1) + ylim(0,1)



                                                                                            
Pl_Eq3_mix <- Pl_Eq3 + aes(y = Ptros_Eq3_mix) +  ggtitle(paste("Stat =", all_obs_predict_T %>%  filter(!is.na(Ptros_Eq3_mix)) %>% summarise(Stat =  sum(abs(Ptros_obs - Ptros_Eq3_mix)/(Ptros_obs + Ptros_Eq3_mix))) %>% round(., 4)))+ guides(shape = "none", color = "none") + xlim(0,1) + ylim(0,1)
                                                                                
                                                                                            
Pl_Eq3_all <- Pl_Eq3 + aes(y = Ptros_Eq3_all) +  ggtitle(paste("Stat =", all_obs_predict_T %>%  filter(!is.na(Ptros_Eq3_all)) %>% summarise(Stat =  sum(abs(Ptros_obs - Ptros_Eq3_all)/(Ptros_obs + Ptros_Eq3_all))) %>% round(., 4)))+ guides(shape = "none", color = "none") + xlim(0,1) + ylim(0,1)
              

Set = "WBL"


library(pipeR)

Pl_Eq1_2_diff_diff <- 
  cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_diff_diff, P_ME_E_Eq2_diff_diff) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% 
  ggplot(aes(x = Observed, y = Predicted, color = variable, shape = Set)) + 
  geom_point()  + 
  theme(legend.position = "bottom")   + 
  geom_abline() + 
  ggtitle(paste("Stat =",   cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_diff_diff, P_ME_E_Eq2_diff_diff) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% summarise(Stat = sum( (Predicted - Observed)^2 )) %>% round(3), " diff_diff" ))  + 
  xlim(0,1) + ylim(0,1) + guides (shape = "none", color = "none") + geom_smooth(method = "lm", se = F)





Pl_Eq1_2_diff_mix <- 
  cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_diff_mix, P_ME_E_Eq2_diff_mix) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% 
  ggplot(aes(x = Observed, y = Predicted, color = variable, shape = Set)) + 
  geom_point()  + 
  theme(legend.position = "bottom")   + 
  geom_abline() + 
  ggtitle(paste("Stat =",   cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_diff_mix, P_ME_E_Eq2_diff_mix) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% summarise(Stat = sum( (Predicted - Observed)^2 )) %>% round(3), " diff_mix" ))  + 
  xlim(0,1) + ylim(0,1) + guides (shape = "none", color = "none") + geom_smooth(method = "lm", se = F)





  

Pl_Eq1_2_diff_all <- 
  cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_diff_all, P_ME_E_Eq2_diff_all) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% 
  ggplot(aes(x = Observed, y = Predicted, color = variable, shape = Set)) + 
  geom_point()  + 
  theme(legend.position = "bottom")   + 
  geom_abline() + 
  ggtitle(paste("Stat =",   cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_diff_all, P_ME_E_Eq2_diff_all) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% summarise(Stat = sum( (Predicted - Observed)^2 )) %>% round(3), " diff_all" ))  + 
  xlim(0,1) + ylim(0,1) + guides (shape = "none", color = "none") + geom_smooth(method = "lm", se = F)





Pl_Eq1_2_mix_diff <- 
  cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_mix_diff, P_ME_E_Eq2_mix_diff) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% 
  ggplot(aes(x = Observed, y = Predicted, color = variable, shape = Set)) + 
  geom_point()  + 
  theme(legend.position = "bottom")   + 
  geom_abline() + 
  ggtitle(paste("Stat =",   cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_mix_diff, P_ME_E_Eq2_mix_diff) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% summarise(Stat = sum( (Predicted - Observed)^2 )) %>% round(3), " mix_diff" ))  + 
  xlim(0,1) + ylim(0,1) + guides (shape = "none", color = "none") + geom_smooth(method = "lm", se = F)



Pl_Eq1_2_mix_mix <- 
  cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_mix_mix, P_ME_E_Eq2_mix_mix) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% 
  ggplot(aes(x = Observed, y = Predicted, color = variable, shape = Set)) + 
  geom_point()  + 
  theme(legend.position = "bottom")   + 
  geom_abline() + 
  ggtitle(paste("Stat =",   cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_mix_mix, P_ME_E_Eq2_mix_mix) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% summarise(Stat = sum( (Predicted - Observed)^2 )) %>% round(3), " mix_mix" ))  + 
  xlim(0,1) + ylim(0,1) + guides (shape = "none", color = "none") + geom_smooth(method = "lm", se = F)



Pl_Eq1_2_mix_all <- 
  cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_mix_all, P_ME_E_Eq2_mix_all) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% 
  ggplot(aes(x = Observed, y = Predicted, color = variable, shape = Set)) + 
  geom_point()  + 
  theme(legend.position = "bottom")   + 
  geom_abline() + 
  ggtitle(paste("Stat =",   cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_mix_all, P_ME_E_Eq2_mix_all) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% summarise(Stat = sum( (Predicted - Observed)^2 )) %>% round(3), " mix_all" ))  + 
  xlim(0,1) + ylim(0,1) + guides (shape = "none", color = "none") + geom_smooth(method = "lm", se = F)




Pl_Eq1_2_all_diff <- 
  cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_all_diff, P_ME_E_Eq2_all_diff) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% 
  ggplot(aes(x = Observed, y = Predicted, color = variable, shape = Set)) + 
  geom_point()  + 
  theme(legend.position = "bottom")   + 
  geom_abline() + 
  ggtitle(paste("Stat =",   cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_all_diff, P_ME_E_Eq2_all_diff) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% summarise(Stat = sum( (Predicted - Observed)^2 )) %>% round(3), " all_diff" ))  + 
  xlim(0,1) + ylim(0,1) + guides (shape = "none", color = "none") + geom_smooth(method = "lm", se = F)




Pl_Eq1_2_all_mix <- 
  cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_all_mix, P_ME_E_Eq2_all_mix) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% 
  ggplot(aes(x = Observed, y = Predicted, color = variable, shape = Set)) + 
  geom_point()  + 
  theme(legend.position = "bottom")   + 
  geom_abline() + 
  ggtitle(paste("Stat =",   cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_all_mix, P_ME_E_Eq2_all_mix) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% summarise(Stat = sum( (Predicted - Observed)^2 )) %>% round(3), " all_mix" ))  + 
  xlim(0,1) + ylim(0,1) + guides (shape = "none", color = "none") + geom_smooth(method = "lm", se = F)



Pl_Eq1_2_all_all <- 
  cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_all_all, P_ME_E_Eq2_all_all) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% 
  ggplot(aes(x = Observed, y = Predicted, color = variable, shape = Set)) + 
  geom_point()  + 
  theme(legend.position = "bottom")   + 
  geom_abline() + 
  ggtitle(paste("Stat =",   cbind(all_obs_predict_T %>%  select(P_MT_T_obs, P_ME_E_obs) %>% melt(value.name = "Observed"),all_obs_predict_T %>%  select(P_MT_T_Eq1_all_all, P_ME_E_Eq2_all_all) %>% melt(value.name = "Predicted") %>% select(Predicted))  %>%  filter(!is.na(Predicted)) %>% summarise(Stat = sum( (Predicted - Observed)^2 )) %>% round(3), " all_all" ))  + 
  xlim(0,1) + ylim(0,1) + guides (shape = "none", color = "none") + geom_smooth(method = "lm", se = F)




grid.arrange(Pl_Eq3_diff, Pl_Eq3_mix, Pl_Eq3_all, Pl_Eq1_2_diff_diff, Pl_Eq1_2_diff_mix, Pl_Eq1_2_diff_all, Pl_Eq1_2_mix_diff, Pl_Eq1_2_mix_mix, Pl_Eq1_2_mix_all, Pl_Eq1_2_all_diff, Pl_Eq1_2_all_mix, Pl_Eq1_2_all_all, ncol = 3)



```





Вот исходники можешь покопаться сам
```{r}

options(knitr.kable.NA = '-')

# kable(all_obs_predict,digits = 3, caption = "Calibration on the base of genetic structure")
kable(all_obs_predict_T,digits = 3, caption = "Calibration on the base of T-morphotype frequency")

```


